## Audio Processing

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-23**|**QuarkAudio Technical Report**|Chengwei Liu et.al.|[2512.20151](https://arxiv.org/abs/2512.20151)|null|
|**2025-12-23**|**VALLR-Pin: Dual-Decoding Visual Speech Recognition for Mandarin with Pinyin-Guided LLM Refinement**|Chang Sun et.al.|[2512.20032](https://arxiv.org/abs/2512.20032)|null|
|**2025-12-22**|**From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs**|Alessandro Lucca et.al.|[2512.19161](https://arxiv.org/abs/2512.19161)|null|
|**2025-12-22**|**Enhancing Fully Formatted End-to-End Speech Recognition with Knowledge Distillation via Multi-Codebook Vector Quantization**|Jian You et.al.|[2512.18967](https://arxiv.org/abs/2512.18967)|null|
|**2025-12-21**|**Speaker Recognition -- Wavelet Packet Based Multiresolution Feature Extraction Approach**|Saurabh Bhardwaj et.al.|[2512.18902](https://arxiv.org/abs/2512.18902)|null|
|**2025-12-21**|**Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis**|Pengchao Feng et.al.|[2512.18699](https://arxiv.org/abs/2512.18699)|null|
|**2025-12-20**|**Phoneme-based speech recognition driven by large language models and sampling marginalization**|Te Ma et.al.|[2512.18371](https://arxiv.org/abs/2512.18371)|null|
|**2025-12-20**|**TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition**|Haolong Zheng et.al.|[2512.18263](https://arxiv.org/abs/2512.18263)|null|
|**2025-12-19**|**SAM Audio: Segment Anything in Audio**|Bowen Shi et.al.|[2512.18099](https://arxiv.org/abs/2512.18099)|null|
|**2025-11-27**|**Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset**|Nick Rossenbach et.al.|[2512.17915](https://arxiv.org/abs/2512.17915)|null|
|**2025-12-19**|**Peeking Into The Future For Contextual Biasing**|Ramaneswaran Selvakumar et.al.|[2512.17657](https://arxiv.org/abs/2512.17657)|null|
|**2025-12-19**|**When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems**|Sujal Chondhekar et.al.|[2512.17562](https://arxiv.org/abs/2512.17562)|null|
|**2025-12-19**|**Zero-Shot Recognition of Dysarthric Speech Using Commercial Automatic Speech Recognition and Multimodal Large Language Models**|Ali Alsayegh et.al.|[2512.17474](https://arxiv.org/abs/2512.17474)|null|
|**2025-12-19**|**Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition**|Zahra Rahmani et.al.|[2512.17247](https://arxiv.org/abs/2512.17247)|null|
|**2025-12-18**|**Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains**|Darshil Chauhan et.al.|[2512.16401](https://arxiv.org/abs/2512.16401)|null|
|**2025-12-16**|**ComMark: Covert and Robust Black-Box Model Watermarking with Compressed Samples**|Yunfei Yang et.al.|[2512.15641](https://arxiv.org/abs/2512.15641)|null|
|**2025-12-16**|**Adapting Speech Language Model to Singing Voice Synthesis**|Yiwen Zhao et.al.|[2512.14657](https://arxiv.org/abs/2512.14657)|null|
|**2025-12-16**|**MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation**|Yash Vishe et.al.|[2512.14629](https://arxiv.org/abs/2512.14629)|null|
|**2025-12-16**|**GLM-TTS Technical Report**|Jiayan Cui et.al.|[2512.14291](https://arxiv.org/abs/2512.14291)|null|
|**2025-12-16**|**Scalable Frameworks for Real-World Audio-Visual Speech Recognition**|Sungnyun Kim et.al.|[2512.14083](https://arxiv.org/abs/2512.14083)|null|
|**2025-12-15**|**Reproducing and Dissecting Denoising Language Models for Speech Recognition**|Dorian Koch et.al.|[2512.13576](https://arxiv.org/abs/2512.13576)|null|
|**2025-12-15**|**DisCo-Speech: Controllable Zero-Shot Speech Generation with A Disentangled Speech Codec**|Tao Li et.al.|[2512.13251](https://arxiv.org/abs/2512.13251)|null|
|**2025-12-14**|**BUT Systems for WildSpoof Challenge: SASV in the Wild**|Junyi Peng et.al.|[2512.12851](https://arxiv.org/abs/2512.12851)|null|
|**2025-12-14**|**Procedural Music Generation Systems in Games**|Shangxuan Luo et.al.|[2512.12834](https://arxiv.org/abs/2512.12834)|null|
|**2025-12-14**|**Adaptive Edge-Cloud Inference for Speech-to-Action Systems Using ASR and Large Language Models**|Mohammad Jalili Torkamani et.al.|[2512.12769](https://arxiv.org/abs/2512.12769)|null|
|**2025-12-13**|**System X: A Mobile Voice-Based AI System for EMR Generation and Clinical Decision Support in Low-Resource Maternal Healthcare**|Maryam Mustafa et.al.|[2512.12240](https://arxiv.org/abs/2512.12240)|null|
|**2025-12-13**|**A comparative study of generative models for child voice conversion**|Protima Nomo Sudro et.al.|[2512.12129](https://arxiv.org/abs/2512.12129)|null|
|**2025-12-12**|**All-in-One ASR: Unifying Encoder-Decoder Models of CTC, Attention, and Transducer in Dual-Mode ASR**|Takafumi Moriya et.al.|[2512.11543](https://arxiv.org/abs/2512.11543)|null|
|**2025-12-12**|**PhraseVAE and PhraseLDM: Latent Diffusion for Full-Song Multitrack Symbolic Music Generation**|Longshen Ou et.al.|[2512.11348](https://arxiv.org/abs/2512.11348)|null|
|**2025-12-12**|**The Affective Bridge: Unifying Feature Representations for Speech Deepfake Detection**|Yupei Li et.al.|[2512.11241](https://arxiv.org/abs/2512.11241)|null|
|**2025-12-11**|**The TCG CREST -- RKMVERI Submission for the NCIIPC Startup India AI Grand Challenge**|Nikhil Raghav et.al.|[2512.11009](https://arxiv.org/abs/2512.11009)|null|
|**2025-11-30**|**Benchmarking Automatic Speech Recognition Models for African Languages**|Alvin Nahabwe et.al.|[2512.10968](https://arxiv.org/abs/2512.10968)|null|
|**2025-11-30**|**ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages**|Subham Kumar et.al.|[2512.10967](https://arxiv.org/abs/2512.10967)|null|
|**2025-12-11**|**CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences**|Yiyang Wang et.al.|[2512.10918](https://arxiv.org/abs/2512.10918)|null|
|**2025-12-11**|**TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage**|Elroy Galbraith et.al.|[2512.10741](https://arxiv.org/abs/2512.10741)|null|
|**2025-12-11**|**MR-FlowDPO: Multi-Reward Direct Preference Optimization for Flow-Matching Text-to-Music Generation**|Alon Ziv et.al.|[2512.10264](https://arxiv.org/abs/2512.10264)|null|
|**2025-12-10**|**Robust Speech Activity Detection in the Presence of Singing Voice**|Philipp Grundhuber et.al.|[2512.09713](https://arxiv.org/abs/2512.09713)|null|
|**2025-12-09**|**LG Uplus System with Multi-Speaker IDs and Discriminator-based Sub-Judges for the WildSpoof Challenge**|Jinyoung Park et.al.|[2512.09000](https://arxiv.org/abs/2512.09000)|null|
|**2025-12-02**|**Enhancing Automatic Speech Recognition Through Integrated Noise Detection Architecture**|Karamvir Singh et.al.|[2512.08973](https://arxiv.org/abs/2512.08973)|null|
|**2025-12-09**|**Emovectors: assessing emotional content in jazz improvisations for creativity evaluation**|Anna Jordanous et.al.|[2512.08812](https://arxiv.org/abs/2512.08812)|null|
|**2025-12-08**|**A Simple Method to Enhance Pre-trained Language Models with Speech Tokens for Classification**|Nicolas Calbucura et.al.|[2512.07571](https://arxiv.org/abs/2512.07571)|null|
|**2025-12-08**|**Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data**|Srihari Bandarupalli et.al.|[2512.07277](https://arxiv.org/abs/2512.07277)|null|
|**2025-12-06**|**Sanvaad: A Multimodal Accessibility Framework for ISL Recognition and Voice-Based Interaction**|Kush Revankar et.al.|[2512.06485](https://arxiv.org/abs/2512.06485)|null|
|**2025-12-06**|**Degrading Voice: A Comprehensive Overview of Robust Voice Conversion Through Input Manipulation**|Xining Song et.al.|[2512.06304](https://arxiv.org/abs/2512.06304)|null|
|**2025-12-01**|**KidSpeak: A General Multi-purpose LLM for Kids' Speech Recognition and Screening**|Rohan Sharma et.al.|[2512.05994](https://arxiv.org/abs/2512.05994)|null|
|**2025-11-23**|**SyncVoice: Towards Video Dubbing with Vision-Augmented Pretrained TTS Model**|Kaidi Wang et.al.|[2512.05126](https://arxiv.org/abs/2512.05126)|null|
|**2025-12-04**|**YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases**|Gongyu Chen et.al.|[2512.04793](https://arxiv.org/abs/2512.04793)|null|
|**2025-12-04**|**M3-TTS: Multi-modal DiT Alignment & Mel-latent for Zero-shot High-fidelity Speech Synthesis**|Xiaopeng Wang et.al.|[2512.04720](https://arxiv.org/abs/2512.04720)|null|
|**2025-12-02**|**Comparing Unsupervised and Supervised Semantic Speech Tokens: A Case Study of Child ASR**|Mohan Shi et.al.|[2512.03301](https://arxiv.org/abs/2512.03301)|null|
|**2025-12-02**|**DAWZY: A New Addition to AI powered "Human in the Loop" Music Co-creation**|Aaron C Elkins et.al.|[2512.03289](https://arxiv.org/abs/2512.03289)|null|
|**2025-12-02**|**Bangla Hate Speech Classification with Fine-tuned Transformer Models**|Yalda Keivan Jafari et.al.|[2512.02845](https://arxiv.org/abs/2512.02845)|null|
|**2025-12-01**|**Swivuriso: The South African Next Voices Multilingual Speech Dataset**|Vukosi Marivatee et.al.|[2512.02201](https://arxiv.org/abs/2512.02201)|null|
|**2025-12-01**|**Story2MIDI: Emotionally Aligned Music Generation from Text**|Mohammad Shokri et.al.|[2512.02192](https://arxiv.org/abs/2512.02192)|null|
|**2025-11-18**|**On the Difficulty of Token-Level Modeling of Dysfluency and Fluency Shaping Artifacts**|Kashaf Gulzar et.al.|[2512.02027](https://arxiv.org/abs/2512.02027)|null|
|**2025-12-01**|**MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark**|Yuezhang Peng et.al.|[2512.01603](https://arxiv.org/abs/2512.01603)|null|
|**2025-12-01**|**ZO-ASR: Zeroth-Order Fine-Tuning of Speech Foundation Models without Back-Propagation**|Yuezhang Peng et.al.|[2512.01267](https://arxiv.org/abs/2512.01267)|null|
|**2025-11-29**|**Melody or Machine: Detecting Synthetic Music with Dual-Stream Contrastive Learning**|Arnesh Batra et.al.|[2512.00621](https://arxiv.org/abs/2512.00621)|null|
|**2025-11-28**|**OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion**|Sai Koneru et.al.|[2512.00234](https://arxiv.org/abs/2512.00234)|null|
|**2025-11-27**|**Art2Music: Generating Music for Art Images with Multi-modal Feeling Alignment**|Jiaying Hong et.al.|[2512.00120](https://arxiv.org/abs/2512.00120)|null|
|**2025-11-28**|**Scaling HuBERT for African Languages: From Base to Large and XL**|Antoine Caubrière et.al.|[2511.23370](https://arxiv.org/abs/2511.23370)|null|
|**2025-11-28**|**HPSU: A Benchmark for Human-Level Perception in Real-World Spoken Speech Understanding**|Chen Li et.al.|[2511.23178](https://arxiv.org/abs/2511.23178)|null|
|**2025-11-28**|**Group-Aware Partial Model Merging for Children's Automatic Speech Recognition**|Thomas Rolland et.al.|[2511.23098](https://arxiv.org/abs/2511.23098)|null|
|**2025-11-27**|**Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration**|Kanchon Gharami et.al.|[2511.22769](https://arxiv.org/abs/2511.22769)|null|
|**2025-11-27**|**Do You See What I Say? Generalizable Deepfake Detection based on Visual Speech Recognition**|Maheswar Bora et.al.|[2511.22443](https://arxiv.org/abs/2511.22443)|null|
|**2025-11-27**|**GLA-Grad++: An Improved Griffin-Lim Guided Diffusion Model for Speech Synthesis**|Teysir Baoueb et.al.|[2511.22293](https://arxiv.org/abs/2511.22293)|null|
|**2025-11-16**|**On the Cross-lingual Transferability of Pre-trained wav2vec2-based Models**|Jonatas Grosman et.al.|[2511.21704](https://arxiv.org/abs/2511.21704)|null|
|**2025-11-26**|**ASR Error Correction in Low-Resource Burmese with Alignment-Enhanced Transformers using Phonetic Features**|Ye Bhone Lin et.al.|[2511.21088](https://arxiv.org/abs/2511.21088)|null|
|**2025-11-26**|**CartoonSing: Unifying Human and Nonhuman Timbres in Singing Generation**|Jionghao Han et.al.|[2511.21045](https://arxiv.org/abs/2511.21045)|null|
|**2025-11-26**|**Towards Audio Token Compression in Large Audio Language Models**|Saurabhchand Bhati et.al.|[2511.20973](https://arxiv.org/abs/2511.20973)|null|
|**2025-11-26**|**SingingSDS: A Singing-Capable Spoken Dialogue System for Conversational Roleplay Applications**|Jionghao Han et.al.|[2511.20972](https://arxiv.org/abs/2511.20972)|null|
|**2025-11-25**|**Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition**|Wesley Bian et.al.|[2511.20534](https://arxiv.org/abs/2511.20534)|null|
|**2025-11-25**|**Modular Deep Learning Framework for Assistive Perception: Gaze, Affect, and Speaker Identification**|Akshit Pramod Anchan et.al.|[2511.20474](https://arxiv.org/abs/2511.20474)|null|
|**2025-11-25**|**Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach**|Huu Tuong Tu et.al.|[2511.20107](https://arxiv.org/abs/2511.20107)|null|
|**2025-11-25**|**Continual Audio Deepfake Detection via Universal Adversarial Perturbation**|Wangjie Li et.al.|[2511.19974](https://arxiv.org/abs/2511.19974)|null|
|**2025-11-24**|**Explicit Tonal Tension Conditioning via Dual-Level Beam Search for Symbolic Music Generation**|Maral Ebrahimzadeh et.al.|[2511.19342](https://arxiv.org/abs/2511.19342)|null|
|**2025-11-24**|**Neural Architecture Search for Quantum Autoencoders**|Hibah Agha et.al.|[2511.19246](https://arxiv.org/abs/2511.19246)|null|
|**2025-11-24**|**Context-Aware Whisper for Arabic ASR Under Linguistic Varieties**|Bashar Talafha et.al.|[2511.18774](https://arxiv.org/abs/2511.18774)|null|
|**2025-11-24**|**AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation**|Omar Garib et.al.|[2511.18718](https://arxiv.org/abs/2511.18718)|null|
|**2025-11-23**|**InstructAudio: Unified speech and music generation with natural language instruction**|Chunyu Qiang et.al.|[2511.18487](https://arxiv.org/abs/2511.18487)|null|
|**2025-11-23**|**A Multimodal Conversational Agent for Tabular Data Analysis**|Mohammad Nour Al Awad et.al.|[2511.18405](https://arxiv.org/abs/2511.18405)|null|
|**2025-11-21**|**Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation**|Scott Merrill et.al.|[2511.17813](https://arxiv.org/abs/2511.17813)|null|
|**2025-11-12**|**Speech Recognition Model Improves Text-to-Speech Synthesis using Fine-Grained Reward**|Guansu Wang et.al.|[2511.17555](https://arxiv.org/abs/2511.17555)|null|
|**2025-11-21**|**MusicAIR: A Multimodal AI Music Generation Framework Powered by an Algorithm-Driven Core**|Callie C. Liao et.al.|[2511.17323](https://arxiv.org/abs/2511.17323)|null|
|**2025-11-20**|**Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs**|Wei-Cheng Tseng et.al.|[2511.16639](https://arxiv.org/abs/2511.16639)|null|
|**2025-11-20**|**WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue**|Zachary Ellis et.al.|[2511.16544](https://arxiv.org/abs/2511.16544)|null|
|**2025-11-20**|**SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise**|Rui Sang et.al.|[2511.16114](https://arxiv.org/abs/2511.16114)|null|
|**2025-11-20**|**Train Short, Infer Long: Speech-LLM Enables Zero-Shot Streamable Joint ASR and Diarization on Long Audio**|Mohan Shi et.al.|[2511.16046](https://arxiv.org/abs/2511.16046)|null|
|**2025-11-19**|**LargeSHS: A large-scale dataset of music adaptation**|Chih-Pin Tan et.al.|[2511.15270](https://arxiv.org/abs/2511.15270)|null|
|**2025-11-19**|**Aligning Generative Music AI with Human Preferences: Methods and Challenges**|Dorien Herremans et.al.|[2511.15038](https://arxiv.org/abs/2511.15038)|null|
|**2025-11-06**|**The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech**|Julio Cesar Galdino et.al.|[2511.14779](https://arxiv.org/abs/2511.14779)|null|
|**2025-11-18**|**A Controllable Perceptual Feature Generative Model for Melody Harmonization via Conditional Variational Autoencoder**|Dengyun Huang et.al.|[2511.14600](https://arxiv.org/abs/2511.14600)|null|
|**2025-11-18**|**TTA: Transcribe, Translate and Alignment for Cross-lingual Speech Representation**|Wei Liu et.al.|[2511.14410](https://arxiv.org/abs/2511.14410)|null|
|**2025-11-18**|**AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR**|Gabrial Zencha Ashungafac et.al.|[2511.14255](https://arxiv.org/abs/2511.14255)|null|
|**2025-11-18**|**Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation**|Kumud Tripathi et.al.|[2511.14219](https://arxiv.org/abs/2511.14219)|null|
|**2025-11-17**|**Human-centric Maintenance Process Through Integration of AI, Speech, and AR**|Parul Khanna et.al.|[2511.13918](https://arxiv.org/abs/2511.13918)|null|
|**2025-11-05**|**Emotion Recognition in Multi-Speaker Conversations through Speaker Identification, Knowledge Distillation, and Hierarchical Fusion**|Xiao Li et.al.|[2511.13731](https://arxiv.org/abs/2511.13731)|null|
|**2025-11-17**|**Alpha Divergence Losses for Biometric Verification**|Dimitrios Koutsianos et.al.|[2511.13621](https://arxiv.org/abs/2511.13621)|null|
|**2025-11-17**|**Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets**|Máté Gedeon et.al.|[2511.13529](https://arxiv.org/abs/2511.13529)|null|
|**2025-11-17**|**Spatial Blind Spot: Auditory Motion Perception Deficits in Audio LLMs**|Zhe Sun et.al.|[2511.13273](https://arxiv.org/abs/2511.13273)|null|
|**2025-11-17**|**Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis**|Zaara Zabeen Arpa et.al.|[2511.13159](https://arxiv.org/abs/2511.13159)|null|
|**2025-11-16**|**Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans**|Hongbin Huang et.al.|[2511.12662](https://arxiv.org/abs/2511.12662)|null|
|**2025-11-15**|**VoiceCraft-X: Unifying Multilingual, Voice-Cloning Speech Synthesis and Speech Editing**|Zhisheng Zheng et.al.|[2511.12347](https://arxiv.org/abs/2511.12347)|null|
|**2025-11-15**|**How Far Do SSL Speech Models Listen for Tone? Temporal Focus of Tone Representation under Low-resource Transfer**|Minu Kim et.al.|[2511.12285](https://arxiv.org/abs/2511.12285)|null|
|**2025-11-15**|**Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets**|Huy M. Le et.al.|[2511.12255](https://arxiv.org/abs/2511.12255)|null|
|**2025-11-12**|**Tighter Truncated Rectangular Prism Approximation for RNN Robustness Verification**|Xingqi Lin et.al.|[2511.11699](https://arxiv.org/abs/2511.11699)|null|
|**2025-11-14**|**Speech-Aware Long Context Pruning and Integration for Contextualized Automatic Speech Recognition**|Yiming Rong et.al.|[2511.11139](https://arxiv.org/abs/2511.11139)|null|
|**2025-11-13**|**Curved Worlds, Clear Boundaries: Generalizing Speech Deepfake Detection using Hyperbolic and Spherical Geometry Spaces**|Farhan Sheth et.al.|[2511.10793](https://arxiv.org/abs/2511.10793)|null|
|**2025-11-13**|**TEDxTN: A Three-way Speech Translation Corpus for Code-Switched Tunisian Arabic - English**|Fethi Bougares et.al.|[2511.10780](https://arxiv.org/abs/2511.10780)|null|
|**2025-11-09**|**Towards Fine-Grained Code-Switch Speech Translation with Semantic Space Alignment**|Yan Gao et.al.|[2511.10670](https://arxiv.org/abs/2511.10670)|null|
|**2025-11-13**|**VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction**|Yuhao Wang et.al.|[2511.10232](https://arxiv.org/abs/2511.10232)|null|
|**2025-11-13**|**FabasedVC: Enhancing Voice Conversion with Text Modality Fusion and Phoneme-Level SSL Features**|Wenyu Wang et.al.|[2511.10112](https://arxiv.org/abs/2511.10112)|null|
|**2025-11-13**|**Time-Layer Adaptive Alignment for Speaker Similarity in Flow-Matching Based Zero-Shot TTS**|Haoyu Li et.al.|[2511.09995](https://arxiv.org/abs/2511.09995)|null|
|**2025-11-12**|**Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages**|Omnilingual ASR team et.al.|[2511.09690](https://arxiv.org/abs/2511.09690)|null|
|**2025-11-12**|**Video Echoed in Music: Semantic, Temporal, and Rhythmic Alignment for Video-to-Music Generation**|Xinyi Tong et.al.|[2511.09585](https://arxiv.org/abs/2511.09585)|null|
|**2025-11-12**|**End-to-end Contrastive Language-Speech Pretraining Model For Long-form Spoken Question Answering**|Jiliang Hu et.al.|[2511.09282](https://arxiv.org/abs/2511.09282)|null|
|**2025-11-12**|**Diff-V2M: A Hierarchical Conditional Diffusion Model with Explicit Rhythmic Modeling for Video-to-Music Generation**|Shulei Ji et.al.|[2511.09090](https://arxiv.org/abs/2511.09090)|null|
|**2025-11-12**|**Context-Aware Dynamic Chunking for Streaming Tibetan Speech Recognition**|Chao Wang et.al.|[2511.09085](https://arxiv.org/abs/2511.09085)|null|
|**2025-11-12**|**Towards Effective and Efficient Non-autoregressive decoders for Conformer and LLM-based ASR using Block-based Attention Mask**|Tianzi Wang et.al.|[2511.09084](https://arxiv.org/abs/2511.09084)|null|
|**2025-11-11**|**HQ-SVC: Towards High-Quality Zero-Shot Singing Voice Conversion in Low-Resource Scenarios**|Bingsong Bai et.al.|[2511.08496](https://arxiv.org/abs/2511.08496)|null|
|**2025-11-11**|**Melodia: Training-Free Music Editing Guided by Attention Probing in Diffusion Models**|Yi Yang et.al.|[2511.08252](https://arxiv.org/abs/2511.08252)|null|
|**2025-11-11**|**Quantizing Whisper-small: How design choices affect ASR performance**|Arthur Söhler et.al.|[2511.08093](https://arxiv.org/abs/2511.08093)|null|
|**2025-11-11**|**SpeechJudge: Towards Human-Level Judgment for Speech Naturalness**|Xueyao Zhang et.al.|[2511.07931](https://arxiv.org/abs/2511.07931)|null|
|**2025-11-10**|**Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction**|Hyeryun Park et.al.|[2511.07392](https://arxiv.org/abs/2511.07392)|null|
|**2025-11-10**|**Generating Piano Music with Transformers: A Comparative Study of Scale, Data, and Metrics**|Jonathan Lehmkuhl et.al.|[2511.07268](https://arxiv.org/abs/2511.07268)|null|
|**2025-11-10**|**Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models**|Umberto Cappellazzo et.al.|[2511.07253](https://arxiv.org/abs/2511.07253)|null|
|**2025-11-10**|**Improving Remote Patient Monitoring Systems Using a Fog-based IoT Platform with Speech Recognition**|Marc Jayson Baucas et.al.|[2511.07189](https://arxiv.org/abs/2511.07189)|null|
|**2025-11-10**|**Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation**|Matteo Pettenó et.al.|[2511.07156](https://arxiv.org/abs/2511.07156)|null|
|**2025-11-10**|**Generating Novel and Realistic Speakers for Voice Conversion**|Meiying Melissa Chen et.al.|[2511.07135](https://arxiv.org/abs/2511.07135)|null|
|**2025-11-10**|**On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation**|Matteo Pettenó et.al.|[2511.07118](https://arxiv.org/abs/2511.07118)|null|
|**2025-11-10**|**E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End Speech Synthesis**|Zhisheng Zhang et.al.|[2511.07099](https://arxiv.org/abs/2511.07099)|null|
|**2025-11-10**|**Metric Analysis for Spatial Semantic Segmentation of Sound Scenes**|Mayank Mishra et.al.|[2511.07075](https://arxiv.org/abs/2511.07075)|null|
|**2025-11-10**|**CLiFT-ASR: A Cross-Lingual Fine-Tuning Framework for Low-Resource Taiwanese Hokkien Speech Recognition**|Hung-Yang Sung et.al.|[2511.06860](https://arxiv.org/abs/2511.06860)|null|
|**2025-11-07**|**Persian Musical Instruments Classification Using Polyphonic Data Augmentation**|Diba Hadi Esfangereh et.al.|[2511.05717](https://arxiv.org/abs/2511.05717)|null|
|**2025-11-02**|**Factual and Musical Evaluation Metrics for Music Language Models**|Daniel Chenyu Lin et.al.|[2511.05550](https://arxiv.org/abs/2511.05550)|null|
|**2025-11-06**|**PromptSep: Generative Audio Separation via Multimodal Prompting**|Yutong Wen et.al.|[2511.04623](https://arxiv.org/abs/2511.04623)|null|
|**2025-11-06**|**MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion Transformers**|Ali Boudaghi et.al.|[2511.04376](https://arxiv.org/abs/2511.04376)|null|
|**2025-11-06**|**Robustness of Minimum-Volume Nonnegative Matrix Factorization under an Expanded Sufficiently Scattered Condition**|Giovanni Barbarino et.al.|[2511.04291](https://arxiv.org/abs/2511.04291)|null|
|**2025-11-06**|**CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese**|Dazhong Chen et.al.|[2511.04139](https://arxiv.org/abs/2511.04139)|null|
|**2025-11-06**|**Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms**|Miguel E. Andres et.al.|[2511.04133](https://arxiv.org/abs/2511.04133)|null|
|**2025-11-06**|**WST: Weakly Supervised Transducer for Automatic Speech Recognition**|Dongji Gao et.al.|[2511.04035](https://arxiv.org/abs/2511.04035)|null|
|**2025-11-06**|**Accelerating scientific discovery with the common task framework**|J. Nathan Kutz et.al.|[2511.04001](https://arxiv.org/abs/2511.04001)|null|
|**2025-11-06**|**MIDI-LLM: Adapting Large Language Models for Text-to-MIDI Music Generation**|Shih-Lun Wu et.al.|[2511.03942](https://arxiv.org/abs/2511.03942)|null|
|**2025-11-05**|**SyMuPe: Affective and Controllable Symbolic Music Performance**|Ilya Borovik et.al.|[2511.03425](https://arxiv.org/abs/2511.03425)|null|
|**2025-11-05**|**Seeing What You Say: Expressive Image Generation from Speech**|Jiyoung Lee et.al.|[2511.03423](https://arxiv.org/abs/2511.03423)|null|
|**2025-11-05**|**Open Source State-Of-the-Art Solution for Romanian Speech Recognition**|Gabriel Pirlogeanu et.al.|[2511.03361](https://arxiv.org/abs/2511.03361)|null|
|**2025-11-05**|**TASU: Text-Only Alignment for Speech Understanding**|Jing Peng et.al.|[2511.03310](https://arxiv.org/abs/2511.03310)|null|
|**2025-11-05**|**How to Evaluate Speech Translation with Source-Aware Neural MT Metrics**|Mauro Cettolo et.al.|[2511.03295](https://arxiv.org/abs/2511.03295)|null|
|**2025-11-04**|**An unscented Kalman filter method for real time input-parameter-state estimation**|Marios Impraimakis et.al.|[2511.02717](https://arxiv.org/abs/2511.02717)|null|
|**2025-11-04**|**Augmenting Open-Vocabulary Dysarthric Speech Assessment with Human Perceptual Supervision**|Kaimeng Jia et.al.|[2511.02270](https://arxiv.org/abs/2511.02270)|null|
|**2025-11-04**|**Energy-Efficient Hardware Acceleration of Whisper ASR on a CGLA**|Takuto Ando et.al.|[2511.02269](https://arxiv.org/abs/2511.02269)|null|
|**2025-11-03**|**ADNAC: Audio Denoiser using Neural Audio Codec**|Daniel Jimon et.al.|[2511.01773](https://arxiv.org/abs/2511.01773)|null|
|**2025-11-03**|**SeaLLMs-Audio: Large Audio-Language Models for Southeast Asia**|Chaoqun Liu et.al.|[2511.01670](https://arxiv.org/abs/2511.01670)|null|
|**2025-11-03**|**The Ghost in the Keys: A Disklavier Demo for Human-AI Musical Co-Creativity**|Louis Bradshaw et.al.|[2511.01663](https://arxiv.org/abs/2511.01663)|null|
|**2025-11-02**|**WhisperVC: Target Speaker-Controllable Mandarin Whisper-to-Speech Conversion**|Dong Liu et.al.|[2511.01056](https://arxiv.org/abs/2511.01056)|null|
|**2025-11-02**|**MULTI-Bench: A Multi-Turn Interactive Benchmark for Assessing Emotional Intelligence ability of Spoken Dialogue Models**|Yayue Deng et.al.|[2511.00850](https://arxiv.org/abs/2511.00850)|null|
|**2025-11-02**|**Rhythm in the Air: Vision-based Real-Time Music Generation through Gestures**|Barathi Subramanian et.al.|[2511.00793](https://arxiv.org/abs/2511.00793)|null|
|**2025-11-01**|**More Than A Shortcut: A Hyperbolic Approach To Early-Exit Networks**|Swapnil Bhosale et.al.|[2511.00641](https://arxiv.org/abs/2511.00641)|null|
|**2025-11-01**|**On Improvisation and Open-Endedness: Insights for Experiential AI**|Botao 'Amber' Hu et.al.|[2511.00529](https://arxiv.org/abs/2511.00529)|null|
|**2025-11-01**|**Emotion Detection in Speech Using Lightweight and Transformer-Based Models: A Comparative and Ablation Study**|Lucky Onyekwelu-Udoka et.al.|[2511.00402](https://arxiv.org/abs/2511.00402)|null|
|**2025-10-31**|**NaturalVoices: A Large-Scale, Spontaneous and Emotional Podcast Dataset for Voice Conversion**|Zongyang Du et.al.|[2511.00256](https://arxiv.org/abs/2511.00256)|null|
|**2025-10-31**|**Holographic equation of state matched with hadron gas equation as a tool for the study of the quark-gluon plasma evolution**|A. V. Anufriev et.al.|[2510.27541](https://arxiv.org/abs/2510.27541)|null|
|**2025-10-31**|**Referee: Reference-aware Audiovisual Deepfake Detection**|Hyemin Boo et.al.|[2510.27475](https://arxiv.org/abs/2510.27475)|null|
|**2025-10-31**|**Pairwise and Attribute-Aware Decision Tree-Based Preference Elicitation for Cold-Start Recommendation**|Alireza Gharahighehi et.al.|[2510.27342](https://arxiv.org/abs/2510.27342)|null|
|**2025-10-31**|**Reconstructing Unseen Sentences from Speech-related Biosignals for Open-vocabulary Neural Communication**|Deok-Seon Kim et.al.|[2510.27247](https://arxiv.org/abs/2510.27247)|null|
|**2025-10-31**|**Reference Microphone Selection for Guided Source Separation based on the Normalized L-p Norm**|Anselm Lohmann et.al.|[2510.27198](https://arxiv.org/abs/2510.27198)|null|
|**2025-10-31**|**Expressive Range Characterization of Open Text-to-Audio Models**|Jonathan Morse et.al.|[2510.27102](https://arxiv.org/abs/2510.27102)|null|
|**2025-10-30**|**Are Online Sports Fan Communities Becoming More Offensive? A Quantitative Review of Topics, Trends, and Toxicity of r/PremierLeague**|Muhammad Zeeshan Mazhar et.al.|[2510.27003](https://arxiv.org/abs/2510.27003)|null|
|**2025-10-30**|**Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations**|Jean-Philippe Corbeil et.al.|[2510.26974](https://arxiv.org/abs/2510.26974)|null|
|**2025-10-29**|**Multi-Representation Attention Framework for Underwater Bioacoustic Denoising and Recognition**|Amine Razig et.al.|[2510.26838](https://arxiv.org/abs/2510.26838)|null|
|**2025-10-29**|**Audio-Visual Speech Enhancement In Complex Scenarios With Separation And Dereverberation Joint Modeling**|Jiarong Du et.al.|[2510.26825](https://arxiv.org/abs/2510.26825)|null|
|**2025-10-28**|**Cross-Corpus Validation of Speech Emotion Recognition in Urdu using Domain-Knowledge Acoustic Features**|Unzela Talpur et.al.|[2510.26823](https://arxiv.org/abs/2510.26823)|null|
|**2025-10-28**|**See the Speaker: Crafting High-Resolution Talking Faces from Speech with Prior Guidance and Region Refinement**|Jinting Wang et.al.|[2510.26819](https://arxiv.org/abs/2510.26819)|null|
|**2025-10-28**|**GACA-DiT: Diffusion-based Dance-to-Music Generation with Genre-Adaptive Rhythm and Context-Aware Alignment**|Jinting Wang et.al.|[2510.26818](https://arxiv.org/abs/2510.26818)|null|
|**2025-10-30**|**HMM for short independent sequences: Multiple sequence Baum-Welch application**|Margarita Cabrera-Bean et.al.|[2510.26532](https://arxiv.org/abs/2510.26532)|null|
|**2025-10-30**|**UniTok-Audio: A Unified Audio Generation Framework via Generative Modeling on Discrete Codec Tokens**|Chengwei Liu et.al.|[2510.26372](https://arxiv.org/abs/2510.26372)|**[link](https://github.com/alibaba/unified-audio)**|
|**2025-10-30**|**Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages**|Mérilin Sousa Silva et.al.|[2510.26254](https://arxiv.org/abs/2510.26254)|null|
|**2025-10-29**|**Efficient Vocal Source Separation Through Windowed Sink Attention**|Christodoulos Benetatos et.al.|[2510.25745](https://arxiv.org/abs/2510.25745)|null|
|**2025-10-29**|**Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models**|Harm Lameris et.al.|[2510.25577](https://arxiv.org/abs/2510.25577)|null|
|**2025-10-29**|**Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation**|Yuxiang Mao et.al.|[2510.25234](https://arxiv.org/abs/2510.25234)|null|
|**2025-10-27**|**SFMS-ALR: Script-First Multilingual Speech Synthesis with Adaptive Locale Resolution**|Dharma Teja Donepudi et.al.|[2510.25178](https://arxiv.org/abs/2510.25178)|null|
|**2025-10-29**|**Joint Analysis of Acoustic Scenes and Sound Events Based on Semi-Supervised Training of Sound Events With Partial Labels**|Keisuke Imoto et.al.|[2510.25075](https://arxiv.org/abs/2510.25075)|null|
|**2025-10-29**|**Evaluating Emotion Recognition in Spoken Language Models on Emotionally Incongruent Speech**|Pedro Corrêa et.al.|[2510.25054](https://arxiv.org/abs/2510.25054)|null|
|**2025-10-28**|**POWSM: A Phonetic Open Whisper-Style Speech Foundation Model**|Chin-Jou Li et.al.|[2510.24992](https://arxiv.org/abs/2510.24992)|null|
|**2025-10-28**|**The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems**|Stefano Natangelo et.al.|[2510.24831](https://arxiv.org/abs/2510.24831)|null|
|**2025-10-28**|**Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation**|Inclusion AI et.al.|[2510.24821](https://arxiv.org/abs/2510.24821)|**[link](https://github.com/inclusionAI/Ming)**|
|**2025-10-28**|**BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation**|Raphaël Bagat et.al.|[2510.24570](https://arxiv.org/abs/2510.24570)|null|
|**2025-10-28**|**Levée d'ambiguïtés par grammaires locales**|Eric G. C. Laporte et.al.|[2510.24530](https://arxiv.org/abs/2510.24530)|null|
|**2025-10-28**|**Audio Signal Processing Using Time Domain Mel-Frequency Wavelet Coefficient**|Rinku Sebastian et.al.|[2510.24519](https://arxiv.org/abs/2510.24519)|null|
|**2025-10-28**|**Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes**|Jonas Hein et.al.|[2510.24332](https://arxiv.org/abs/2510.24332)|null|
|**2025-10-28**|**V-SAT: Video Subtitle Annotation Tool**|Arpita Kundu et.al.|[2510.24180](https://arxiv.org/abs/2510.24180)|null|
|**2025-10-28**|**RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects**|Md. Rezuwan Hassan et.al.|[2510.24096](https://arxiv.org/abs/2510.24096)|null|
|**2025-10-27**|**A Neural Model for Contextual Biasing Score Learning and Filtering**|Wanting Huang et.al.|[2510.23849](https://arxiv.org/abs/2510.23849)|null|
|**2025-10-27**|**Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders**|Nathan Paek et.al.|[2510.23802](https://arxiv.org/abs/2510.23802)|null|
|**2025-10-27**|**SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity**|Hanke Xie et.al.|[2510.23541](https://arxiv.org/abs/2510.23541)|null|
|**2025-10-27**|**LibriConvo: Simulating Conversations from Read Literature for ASR and Diarization**|Máté Gedeon et.al.|[2510.23320](https://arxiv.org/abs/2510.23320)|null|
|**2025-10-27**|**Arabic Little STT: Arabic Children Speech Recognition Dataset**|Mouhand Alkadri et.al.|[2510.23319](https://arxiv.org/abs/2510.23319)|null|
|**2025-10-27**|**Are ASR foundation models generalized enough to capture features of regional dialects for low-resource languages?**|Tawsif Tashwar Dipto et.al.|[2510.23252](https://arxiv.org/abs/2510.23252)|null|
|**2025-10-27**|**Treble10: A high-quality dataset for far-field speech recognition, dereverberation, and enhancement**|Sarabeth S. Mullins et.al.|[2510.23141](https://arxiv.org/abs/2510.23141)|null|
|**2025-10-27**|**Adapting Speech Foundation Models with Large Language Models for Unified Speech Recognition**|Jing-Xuan Zhang et.al.|[2510.22961](https://arxiv.org/abs/2510.22961)|null|
|**2025-10-26**|**LRW-Persian: Lip-reading in the Wild Dataset for Persian Language**|Zahra Taghizadeh et.al.|[2510.22716](https://arxiv.org/abs/2510.22716)|null|
|**2025-10-26**|**Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs**|Anand et.al.|[2510.22603](https://arxiv.org/abs/2510.22603)|**[link](https://github.com/umbertocappellazzo/Llama-AVSR)**|
|**2025-10-26**|**UltraVoice: Scaling Fine-Grained Style-Controlled Speech Conversations for Spoken Dialogue Models**|Wenming Tu et.al.|[2510.22588](https://arxiv.org/abs/2510.22588)|**[link](https://github.com/bigai-nlco/UltraVoice.)**|
|**2025-10-26**|**A Sociophonetic Analysis of Racial Bias in Commercial ASR Systems Using the Pacific Northwest English Corpus**|Michael Scott et.al.|[2510.22495](https://arxiv.org/abs/2510.22495)|null|
|**2025-10-26**|**The Tonogenesis Continuum in Tibetan: A Computational Investigation**|Siyu Liang et.al.|[2510.22485](https://arxiv.org/abs/2510.22485)|null|
|**2025-10-25**|**M-CIF: Multi-Scale Alignment For CIF-Based Non-Autoregressive ASR**|Ruixiang Mao et.al.|[2510.22172](https://arxiv.org/abs/2510.22172)|null|
|**2025-10-25**|**Streaming Generation for Music Accompaniment**|Yusong Wu et.al.|[2510.22105](https://arxiv.org/abs/2510.22105)|null|
|**2025-10-23**|**GuitarFlow: Realistic Electric Guitar Synthesis From Tablatures via Flow Matching and Style Transfer**|Jackson Loth et.al.|[2510.21872](https://arxiv.org/abs/2510.21872)|null|
|**2025-10-24**|**StylePitcher: Generating Style-Following and Expressive Pitch Curves for Versatile Singing Tasks**|Jingyue Huang et.al.|[2510.21685](https://arxiv.org/abs/2510.21685)|null|
|**2025-10-23**|**ReFESS-QI: Reference-Free Evaluation For Speech Separation With Joint Quality And Intelligibility Scoring**|Ari Frummer et.al.|[2510.21014](https://arxiv.org/abs/2510.21014)|null|
|**2025-10-21**|**Can large audio language models understand child stuttering speech? speech summarization, and source separation**|Chibuzor Okocha et.al.|[2510.20850](https://arxiv.org/abs/2510.20850)|null|
|**2025-10-23**|**R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice Conversion**|Junjie Zheng et.al.|[2510.20677](https://arxiv.org/abs/2510.20677)|null|
|**2025-10-23**|**Speaking Clearly: A Simplified Whisper-Based Codec for Low-Bitrate Speech Coding**|Xin Zhang et.al.|[2510.20504](https://arxiv.org/abs/2510.20504)|**[link](https://github.com/ZhangXinWhut/SimWhisper-Codec.)**|
|**2025-10-23**|**Vox-Evaluator: Enhancing Stability and Fidelity for Zero-shot TTS with A Multi-Level Evaluator**|Hualei Wang et.al.|[2510.20210](https://arxiv.org/abs/2510.20210)|null|
|**2025-10-23**|**SpeechAgent: An End-to-End Mobile Infrastructure for Speech Impairment Assistance**|Haowei Lou et.al.|[2510.20113](https://arxiv.org/abs/2510.20113)|null|
|**2025-10-22**|**Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition**|Yuu Jinnai et.al.|[2510.19471](https://arxiv.org/abs/2510.19471)|null|
|**2025-10-22**|**FLASH Viterbi: Fast and Adaptive Viterbi Decoding for Modern Data Systems**|Ziheng Deng et.al.|[2510.19301](https://arxiv.org/abs/2510.19301)|null|
|**2025-10-22**|**Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges**|Cheng Huang et.al.|[2510.19144](https://arxiv.org/abs/2510.19144)|null|
|**2025-10-21**|**Steering Autoregressive Music Generation with Recursive Feature Machines**|Daniel Zhao et.al.|[2510.19127](https://arxiv.org/abs/2510.19127)|**[link](https://github.com/astradzhao/music-rfm)**|
|**2025-10-21**|**StutterZero and StutterFormer: End-to-End Speech Conversion for Stuttering Transcription and Correction**|Qianheng Xu et.al.|[2510.18938](https://arxiv.org/abs/2510.18938)|null|
|**2025-10-21**|**RIR-Mega: a large-scale simulated room impulse response dataset for machine learning and room acoustics modeling**|Mandip Goswami et.al.|[2510.18917](https://arxiv.org/abs/2510.18917)|**[link](https://github.com/mandip42/rirmega)**|
|**2025-10-21**|**MLMA: Towards Multilingual ASR With Mamba-based Architectures**|Mohamed Nabih Ali et.al.|[2510.18684](https://arxiv.org/abs/2510.18684)|null|
|**2025-10-21**|**Noise-Conditioned Mixture-of-Experts Framework for Robust Speaker Verification**|Bin Gu et.al.|[2510.18533](https://arxiv.org/abs/2510.18533)|null|
|**2025-10-21**|**A Stage-Wise Learning Strategy with Fixed Anchors for Robust Speaker Verification**|Bin Gu et.al.|[2510.18530](https://arxiv.org/abs/2510.18530)|null|
|**2025-10-20**|**DELULU: Discriminative Embedding Learning Using Latent Units for Speaker-Aware Self-Supervised Speech Foundational Model**|Massa Baali et.al.|[2510.17662](https://arxiv.org/abs/2510.17662)|null|
|**2025-10-19**|**U-Codec: Ultra Low Frame-rate Neural Speech Codec for Fast High-fidelity Speech Generation**|Xusheng Yang et.al.|[2510.16718](https://arxiv.org/abs/2510.16718)|null|
|**2025-10-19**|**Zero- and One-Shot Data Augmentation for Sentence-Level Dysarthric Speech Recognition in Constrained Scenarios**|Shiyao Wang et.al.|[2510.16700](https://arxiv.org/abs/2510.16700)|null|
|**2025-10-18**|**Hallucination Benchmark for Speech Foundation Models**|Alkis Koudounas et.al.|[2510.16567](https://arxiv.org/abs/2510.16567)|null|
|**2025-10-18**|**Interpreting the Dimensions of Speaker Embedding Space**|Mark Huckvale et.al.|[2510.16489](https://arxiv.org/abs/2510.16489)|null|
|**2025-10-18**|**Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment**|Fu-An Chao et.al.|[2510.16387](https://arxiv.org/abs/2510.16387)|null|
|**2025-10-18**|**MuseTok: Symbolic Music Tokenization for Generation and Semantic Understanding**|Jingyue Huang et.al.|[2510.16273](https://arxiv.org/abs/2510.16273)|null|
|**2025-10-17**|**SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling**|Kadri Hacioglu et.al.|[2510.15851](https://arxiv.org/abs/2510.15851)|null|
|**2025-10-17**|**SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models**|Rachmad Vidya Wicaksana Putra et.al.|[2510.15566](https://arxiv.org/abs/2510.15566)|null|
|**2025-10-16**|**RLAIF-SPA: Optimizing LLM-based Emotional Speech Synthesis via RLAIF**|Qing Yang et.al.|[2510.14628](https://arxiv.org/abs/2510.14628)|null|
|**2025-10-16**|**Do Joint Language-Audio Embeddings Encode Perceptual Timbre Semantics?**|Qixin Deng et.al.|[2510.14249](https://arxiv.org/abs/2510.14249)|null|
|**2025-10-15**|**Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks**|Supriti Sinhamahapatra et.al.|[2510.13979](https://arxiv.org/abs/2510.13979)|null|
|**2025-10-15**|**Closing the Gap Between Text and Speech Understanding in LLMs**|Santiago Cuervo et.al.|[2510.13632](https://arxiv.org/abs/2510.13632)|null|
|**2025-10-15**|**UniMoE-Audio: Unified Speech and Music Generation with Dynamic-Capacity MoE**|Zhenyu Liu et.al.|[2510.13344](https://arxiv.org/abs/2510.13344)|**[link](https://github.com/HITsz-TMG/Uni-MoE)**|
|**2025-10-15**|**Two Heads Are Better Than One: Audio-Visual Speech Error Correction with Dual Hypotheses**|Sungnyun Kim et.al.|[2510.13281](https://arxiv.org/abs/2510.13281)|null|
|**2025-10-14**|**Continuous-Token Diffusion for Speaker-Referenced TTS in Multimodal LLMs**|Xinlu He et.al.|[2510.12995](https://arxiv.org/abs/2510.12995)|null|
|**2025-10-14**|**VCTR: A Transformer-Based Model for Non-parallel Voice Conversion**|Maharnab Saikia et.al.|[2510.12964](https://arxiv.org/abs/2510.12964)|null|
|**2025-10-14**|**A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation**|Mohammed Hilal Al-Kharusi et.al.|[2510.12858](https://arxiv.org/abs/2510.12858)|null|
|**2025-10-14**|**Adaptive vector steering: A training-free, layer-wise intervention for hallucination mitigation in large audio and multimodal models**|Tsung-En Lin et.al.|[2510.12851](https://arxiv.org/abs/2510.12851)|null|
|**2025-10-11**|**Automatic Speech Recognition in the Modern Era: Architectures, Training, and Evaluation**|Md. Nayeem et.al.|[2510.12827](https://arxiv.org/abs/2510.12827)|null|
|**2025-10-14**|**Structured Sparsity and Weight-adaptive Pruning for Memory and Compute efficient Whisper models**|Prasenjit K Mudi et.al.|[2510.12666](https://arxiv.org/abs/2510.12666)|null|
|**2025-10-13**|**BridgeCode: A Dual Speech Representation Paradigm for Autoregressive Zero-Shot Text-to-Speech Synthesis**|Jingyuan Xing et.al.|[2510.11646](https://arxiv.org/abs/2510.11646)|null|
|**2025-10-13**|**Perturbation Self-Supervised Representations for Cross-Lingual Emotion TTS: Stage-Wise Modeling of Emotion and Speaker**|Cheng Gong et.al.|[2510.11124](https://arxiv.org/abs/2510.11124)|null|
|**2025-10-13**|**VCB Bench: An Evaluation Benchmark for Audio-Grounded Large Language Model Conversational Agents**|Jiliang Hu et.al.|[2510.11098](https://arxiv.org/abs/2510.11098)|null|
|**2025-10-12**|**ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis**|Mohammad Javad Ranjbar Kalahroodi et.al.|[2510.10774](https://arxiv.org/abs/2510.10774)|null|
|**2025-10-12**|**End-to-end Speech Recognition with similar length speech and text**|Peng Fan et.al.|[2510.10453](https://arxiv.org/abs/2510.10453)|null|
|**2025-10-12**|**MRSAudio: A Large-Scale Multimodal Recorded Spatial Audio Dataset with Refined Annotations**|Wenxiang Guo et.al.|[2510.10396](https://arxiv.org/abs/2510.10396)|null|
|**2025-10-11**|**End-to-end Automatic Speech Recognition and Speech Translation: Integration of Speech Foundational Models and LLMs**|Nam Luu et.al.|[2510.10329](https://arxiv.org/abs/2510.10329)|null|
|**2025-10-11**|**ProGress: Structured Music Generation via Graph Diffusion and Hierarchical Music Analysis**|Stephen Ni-Hahn et.al.|[2510.10249](https://arxiv.org/abs/2510.10249)|null|
|**2025-10-11**|**SyncLipMAE: Contrastive Masked Pretraining for Audio-Visual Talking-Face Representation**|Zeyu Ling et.al.|[2510.10069](https://arxiv.org/abs/2510.10069)|null|
|**2025-10-10**|**Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking**|Mohammad Hossein Sameti et.al.|[2510.09528](https://arxiv.org/abs/2510.09528)|null|
|**2025-10-10**|**WildElder: A Chinese Elderly Speech Dataset from the Wild with Fine-Grained Manual Annotations**|Hui Wang et.al.|[2510.09344](https://arxiv.org/abs/2510.09344)|null|
|**2025-10-10**|**SynthVC: Leveraging Synthetic Data for End-to-End Low Latency Streaming Voice Conversion**|Zhao Guo et.al.|[2510.09245](https://arxiv.org/abs/2510.09245)|null|
|**2025-10-10**|**Effects of automotive microphone frequency response characteristics and noise conditions on speech and ASR quality -- an experimental evaluation**|Michele Buccoli et.al.|[2510.09236](https://arxiv.org/abs/2510.09236)|null|
|**2025-10-10**|**FLToP CTC: Frame-Level Token Pruning via Relative Threshold for Efficient and Memory-Saving Decoding on Diverse Platforms**|Atul Shree et.al.|[2510.09085](https://arxiv.org/abs/2510.09085)|null|
|**2025-10-10**|**O_O-VC: Synthetic Data-Driven One-to-One Alignment for Any-to-Any Voice Conversion**|Huu Tuong Tu et.al.|[2510.09061](https://arxiv.org/abs/2510.09061)|**[link](https://github.com/huutuongtu/OOVC)**|
|**2025-10-08**|**Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization**|Rui Hu et.al.|[2510.08618](https://arxiv.org/abs/2510.08618)|null|
|**2025-10-09**|**MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean Flows**|Guobin Ma et.al.|[2510.08392](https://arxiv.org/abs/2510.08392)|**[link](https://github.com/ASLP-lab/MeanVC)**|
|**2025-10-09**|**DialoSpeech: Dual-Speaker Dialogue Generation with LLM and Flow Matching**|Hanke Xie et.al.|[2510.08373](https://arxiv.org/abs/2510.08373)|null|
|**2025-10-09**|**Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition**|Yi-Cheng Lin et.al.|[2510.08047](https://arxiv.org/abs/2510.08047)|null|
|**2025-10-09**|**IntMeanFlow: Few-step Speech Generation with Integral Velocity Distillation**|Wei Wang et.al.|[2510.07979](https://arxiv.org/abs/2510.07979)|null|
|**2025-10-09**|**VoiceAgentBench: Are Voice Assistants ready for agentic tasks?**|Dhruv Jain et.al.|[2510.07978](https://arxiv.org/abs/2510.07978)|null|
|**2025-10-09**|**Bloodroot: When Watermarking Turns Poisonous For Stealthy Backdoor**|Kuan-Yu Chen et.al.|[2510.07909](https://arxiv.org/abs/2510.07909)|null|
|**2025-10-08**|**How much speech data is necessary for ASR in African languages? An evaluation of data scaling in Kinyarwanda and Kikuyu**|Benjamin Akera et.al.|[2510.07221](https://arxiv.org/abs/2510.07221)|**[link](https://github.com/SunbirdAI/kinyarwanda-whisper-eval)**|
|**2025-10-08**|**Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided Sarcastic Speech Synthesis**|Zhu Li et.al.|[2510.07096](https://arxiv.org/abs/2510.07096)|null|
|**2025-10-08**|**Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation**|Vaibhav Srivastav et.al.|[2510.06961](https://arxiv.org/abs/2510.06961)|null|
|**2025-08-26**|**A Framework for Robust Speaker Verification in Highly Noisy Environments Leveraging Both Noisy and Enhanced Audio**|Adam Katav et.al.|[2508.18913](https://arxiv.org/abs/2508.18913)|null|
|**2025-08-20**|**Improving Resource-Efficient Speech Enhancement via Neural Differentiable DSP Vocoder Refinement**|Heitor R. Guimarães et.al.|[2508.14709](https://arxiv.org/abs/2508.14709)|null|
|**2025-08-18**|**Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis**|Zhu Li et.al.|[2508.13028](https://arxiv.org/abs/2508.13028)|null|
|**2025-08-15**|**EmoSSLSphere: Multilingual Emotional Speech Synthesis with Spherical Vectors and Discrete Speech Tokens**|Joonyong Park et.al.|[2508.11273](https://arxiv.org/abs/2508.11273)|null|
|**2025-08-12**|**Multi-Target Backdoor Attacks Against Speaker Recognition**|Alexandrine Fortier et.al.|[2508.08559](https://arxiv.org/abs/2508.08559)|null|
|**2025-07-23**|**AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer**|Danny D. Leybzon et.al.|[2507.17718](https://arxiv.org/abs/2507.17718)|null|
|**2025-07-23**|**Synthetic Voice Data for Automatic Speech Recognition in African Languages**|Brian DeRenzi et.al.|[2507.17578](https://arxiv.org/abs/2507.17578)|null|
|**2025-07-23**|**BoSS: Beyond-Semantic Speech**|Qing Wang et.al.|[2507.17563](https://arxiv.org/abs/2507.17563)|null|
|**2025-07-23**|**Clustering-based hard negative sampling for supervised contrastive speaker verification**|Piotr Masztalski et.al.|[2507.17540](https://arxiv.org/abs/2507.17540)|null|
|**2025-07-23**|**Application of Whisper in Clinical Practice: the Post-Stroke Speech Assessment during a Naming Task**|Milena Davudova et.al.|[2507.17326](https://arxiv.org/abs/2507.17326)|null|
|**2025-07-23**|**On Temporal Guidance and Iterative Refinement in Audio Source Separation**|Tobias Morocutti et.al.|[2507.17297](https://arxiv.org/abs/2507.17297)|null|
|**2025-07-23**|**Triple X: A LLM-Based Multilingual Speech Recognition System for the INTERSPEECH2025 MLC-SLM Challenge**|Miaomiao Gao et.al.|[2507.17288](https://arxiv.org/abs/2507.17288)|null|
|**2025-07-22**|**SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling**|Yi Guo et.al.|[2507.16884](https://arxiv.org/abs/2507.16884)|null|
|**2025-07-22**|**Step-Audio 2 Technical Report**|Boyong Wu et.al.|[2507.16632](https://arxiv.org/abs/2507.16632)|**[link](https://github.com/stepfun-ai/Step-Audio2)**|
|**2025-07-22**|**An approach to measuring the performance of Automatic Speech Recognition (ASR) models in the context of Large Language Model (LLM) powered applications**|Sujith Pulikodan et.al.|[2507.16456](https://arxiv.org/abs/2507.16456)|null|
|**2025-07-21**|**Beyond Rate Coding: Surrogate Gradients Enable Spike Timing Learning in Spiking Neural Networks**|Ziqiao Yu et.al.|[2507.16043](https://arxiv.org/abs/2507.16043)|null|
|**2025-07-21**|**Mixture to Beamformed Mixture: Leveraging Beamformed Mixture as Weak-Supervision for Speech Enhancement and Noise-Robust ASR**|Zhong-Qiu Wang et.al.|[2507.15229](https://arxiv.org/abs/2507.15229)|null|
|**2025-07-21**|**EchoVoices: Preserving Generational Voices and Memories for Seniors and Children**|Haiying Xu et.al.|[2507.15221](https://arxiv.org/abs/2507.15221)|null|
|**2025-07-21**|**Exploiting Context-dependent Duration Features for Voice Anonymization Attack Systems**|Natalia Tomashenko et.al.|[2507.15214](https://arxiv.org/abs/2507.15214)|null|
|**2025-07-20**|**DMOSpeech 2: Reinforcement Learning for Duration Prediction in Metric-Optimized Speech Synthesis**|Yinghao Aaron Li et.al.|[2507.14988](https://arxiv.org/abs/2507.14988)|**[link](https://github.com/yl4579/DMOSpeech2)**|
|**2025-07-19**|**Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion**|Yu Zhang et.al.|[2507.14534](https://arxiv.org/abs/2507.14534)|**[link](https://github.com/AaronZ345/ConanDemo)**|
|**2025-07-19**|**Adapting Whisper for Lightweight and Efficient Automatic Speech Recognition of Children for On-device Edge Applications**|Satwik Dutta et.al.|[2507.14451](https://arxiv.org/abs/2507.14451)|**[link](https://github.com/SatwikDutta/LiteChildASR)**|
|**2025-07-18**|**Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic**|Lilit Grigoryan et.al.|[2507.13977](https://arxiv.org/abs/2507.13977)|null|
|**2025-07-18**|**Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies**|Carlos Mena et.al.|[2507.13875](https://arxiv.org/abs/2507.13875)|null|
|**2025-07-17**|**A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models**|Kirill Borodin et.al.|[2507.13563](https://arxiv.org/abs/2507.13563)|**[link](https://github.com/mtuciru/balalaika)**|
|**2025-07-17**|**Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder**|Feng Chen et.al.|[2507.13551](https://arxiv.org/abs/2507.13551)|null|
|**2025-07-18**|**Automatically assessing oral narratives of Afrikaans and isiXhosa children**|Retief Louw et.al.|[2507.13205](https://arxiv.org/abs/2507.13205)|null|
|**2025-07-17**|**SHIELD: A Secure and Highly Enhanced Integrated Learning for Robust Deepfake Detection against Adversarial Attacks**|Kutub Uddin et.al.|[2507.13170](https://arxiv.org/abs/2507.13170)|null|
|**2025-07-17**|**NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech**|Maksim Borisov et.al.|[2507.13155](https://arxiv.org/abs/2507.13155)|null|
|**2025-07-17**|**UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets**|Zhichao Sheng et.al.|[2507.12951](https://arxiv.org/abs/2507.12951)|null|
|**2025-07-17**|**Enkidu: Universal Frequential Perturbation for Real-Time Audio Privacy Protection against Voice Deepfakes**|Zhou Feng et.al.|[2507.12932](https://arxiv.org/abs/2507.12932)|null|
|**2025-07-17**|**AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation**|Potsawee Manakul et.al.|[2507.12705](https://arxiv.org/abs/2507.12705)|null|
|**2025-07-17**|**Task-Specific Audio Coding for Machines: Machine-Learned Latent Features Are Codes for That Machine**|Anastasia Kuznetsova et.al.|[2507.12701](https://arxiv.org/abs/2507.12701)|null|
|**2025-07-16**|**Improving Contextual ASR via Multi-grained Fusion with Large Language Models**|Shilin Zhou et.al.|[2507.12252](https://arxiv.org/abs/2507.12252)|null|
|**2025-07-16**|**EME-TTS: Unlocking the Emphasis and Emotion Link in Speech Synthesis**|Haoxun Li et.al.|[2507.12015](https://arxiv.org/abs/2507.12015)|null|
|**2025-07-15**|**Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection**|Ivan Viakhirev et.al.|[2507.11777](https://arxiv.org/abs/2507.11777)|**[link](https://github.com/KORALLLL/AASIST_SCALING.)**|
|**2025-07-15**|**FasTUSS: Faster Task-Aware Unified Source Separation**|Francesco Paissan et.al.|[2507.11435](https://arxiv.org/abs/2507.11435)|null|
|**2025-07-15**|**Towards Reliable Objective Evaluation Metrics for Generative Singing Voice Separation Models**|Paul A. Bereuter et.al.|[2507.11427](https://arxiv.org/abs/2507.11427)|null|
|**2025-07-14**|**WhisperKit: On-device Real-time ASR with Billion-Scale Transformers**|Atila Orhon et.al.|[2507.10860](https://arxiv.org/abs/2507.10860)|null|
|**2025-07-14**|**Supporting SENĆOTEN Language Documentation Efforts with Automatic Speech Recognition**|Mengzhe Geng et.al.|[2507.10827](https://arxiv.org/abs/2507.10827)|null|
|**2025-07-14**|**WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling**|Qihui Yang et.al.|[2507.10534](https://arxiv.org/abs/2507.10534)|null|
|**2025-07-14**|**DQLoRA: A Lightweight Domain-Aware Denoising ASR via Adapter-guided Distillation**|Yiru Yang et.al.|[2507.10313](https://arxiv.org/abs/2507.10313)|null|
|**2025-07-13**|**The DKU System for Multi-Speaker Automatic Speech Recognition in MLC-SLM Challenge**|Yuke Lin et.al.|[2507.09499](https://arxiv.org/abs/2507.09499)|null|
|**2025-07-12**|**Voice Conversion for Lombard Speaking Style with Implicit and Explicit Acoustic Feature Conditioning**|Dominika Woszczyk et.al.|[2507.09310](https://arxiv.org/abs/2507.09310)|null|
|**2025-07-12**|**Can We Really Repurpose Multi-Speaker ASR Corpus for Speaker Diarization?**|Shota Horiguchi et.al.|[2507.09226](https://arxiv.org/abs/2507.09226)|null|
|**2025-07-15**|**Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition**|Bingshen Mu et.al.|[2507.09116](https://arxiv.org/abs/2507.09116)|null|
|**2025-07-11**|**SemAlignVC: Enhancing zero-shot timbre conversion using semantic alignment**|Shivam Mehta et.al.|[2507.09070](https://arxiv.org/abs/2507.09070)|null|
|**2025-07-11**|**The Impact of Automatic Speech Transcription on Speaker Attribution**|Cristina Aggazzotti et.al.|[2507.08660](https://arxiv.org/abs/2507.08660)|null|
|**2025-07-11**|**Unlocking Speech Instruction Data Potential with Query Rewriting**|Yonghua Hei et.al.|[2507.08603](https://arxiv.org/abs/2507.08603)|null|
|**2025-07-11**|**ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual Speech Recognition**|Qingliang Meng et.al.|[2507.08477](https://arxiv.org/abs/2507.08477)|null|
|**2025-07-11**|**Active Learning for Text-to-Speech Synthesis with Informative Sample Collection**|Kentaro Seki et.al.|[2507.08319](https://arxiv.org/abs/2507.08319)|null|
|**2025-07-11**|**RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing**|Yang Xiao et.al.|[2507.08227](https://arxiv.org/abs/2507.08227)|null|
|**2025-07-10**|**DARAS: Dynamic Audio-Room Acoustic Synthesis for Blind Room Impulse Response Estimation**|Chunxi Wang et.al.|[2507.08135](https://arxiv.org/abs/2507.08135)|null|
|**2025-07-10**|**Modèle physique variationnel pour l'estimation de réponses impulsionnelles de salles**|Louis Lalay et.al.|[2507.08051](https://arxiv.org/abs/2507.08051)|null|
|**2025-07-10**|**Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition Models**|Chen Feng et.al.|[2507.07877](https://arxiv.org/abs/2507.07877)|null|
|**2025-07-10**|**SecureSpeech: Prompt-based Speaker and Content Protection**|Belinda Soh Hui Hui et.al.|[2507.07799](https://arxiv.org/abs/2507.07799)|null|
|**2025-07-10**|**Code-Switching in End-to-End Automatic Speech Recognition: A Systematic Literature Review**|Maha Tufail Agro et.al.|[2507.07741](https://arxiv.org/abs/2507.07741)|null|
|**2025-07-08**|**Deep Feed-Forward Neural Network for Bangla Isolated Speech Recognition**|Dipayan Bhadra et.al.|[2507.07068](https://arxiv.org/abs/2507.07068)|null|
|**2025-07-09**|**Speech Tokenizer is Key to Consistent Representation**|Wonjin Jung et.al.|[2507.06802](https://arxiv.org/abs/2507.06802)|null|
|**2025-07-09**|**Exploring State-Space-Model based Language Model in Music Generation**|Wei-Jaw Lee et.al.|[2507.06674](https://arxiv.org/abs/2507.06674)|null|
|**2025-07-09**|**Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents**|Zackary Rackauckas et.al.|[2507.06483](https://arxiv.org/abs/2507.06483)|null|
|**2025-07-08**|**Speech Quality Assessment Model Based on Mixture of Experts: System-Level Performance Enhancement and Utterance-Level Challenge Analysis**|Xintong Hu et.al.|[2507.06116](https://arxiv.org/abs/2507.06116)|null|
|**2025-07-08**|**VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis**|Alexandre Symeonidis-Herzig et.al.|[2507.06060](https://arxiv.org/abs/2507.06060)|null|
|**2025-07-08**|**MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation**|Fathinah Izzati et.al.|[2507.05894](https://arxiv.org/abs/2507.05894)|null|
|**2025-07-08**|**How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures**|Tanvina Patel et.al.|[2507.05885](https://arxiv.org/abs/2507.05885)|null|
|**2025-07-08**|**ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark**|He Wang et.al.|[2507.05727](https://arxiv.org/abs/2507.05727)|null|
|**2025-07-08**|**Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition**|Zijin Gu et.al.|[2507.05724](https://arxiv.org/abs/2507.05724)|null|
|**2025-07-07**|**EXPOTION: Facial Expression and Motion Control for Multimodal Music Generation**|Fathinah Izzati et.al.|[2507.04955](https://arxiv.org/abs/2507.04955)|null|
|**2025-07-07**|**Adaptive Slimming for Scalable and Efficient Speech Enhancement**|Riccardo Miccini et.al.|[2507.04879](https://arxiv.org/abs/2507.04879)|null|
|**2025-07-07**|**Fast-VGAN: Lightweight Voice Conversion with Explicit Control of F0 and Duration Parameters**|Mathilde Abrassart et.al.|[2507.04817](https://arxiv.org/abs/2507.04817)|null|
|**2025-07-07**|**Multi-Step Prediction and Control of Hierarchical Emotion Distribution in Text-to-Speech Synthesis**|Sho Inoue et.al.|[2507.04598](https://arxiv.org/abs/2507.04598)|null|
|**2025-07-06**|**TTS-CtrlNet: Time varying emotion aligned text-to-speech generation with ControlNet**|Jaeseok Jeong et.al.|[2507.04349](https://arxiv.org/abs/2507.04349)|null|
|**2025-07-05**|**Prosody Labeling with Phoneme-BERT and Speech Foundation Models**|Tomoki Koriyama et.al.|[2507.03912](https://arxiv.org/abs/2507.03912)|null|
|**2025-07-04**|**Improving Low-Resource Dialect Classification Using Retrieval-based Voice Conversion**|Lea Fischbach et.al.|[2507.03641](https://arxiv.org/abs/2507.03641)|null|
|**2025-07-04**|**MusGO: A Community-Driven Framework For Assessing Openness in Music-Generative AI**|Roser Batlle-Roca et.al.|[2507.03599](https://arxiv.org/abs/2507.03599)|null|
|**2025-07-08**|**SHNU Multilingual Conversational Speech Recognition System for INTERSPEECH 2025 MLC-SLM Challenge**|Yuxiang Mei et.al.|[2507.03343](https://arxiv.org/abs/2507.03343)|null|
|**2025-07-03**|**DeepGesture: A conversational gesture synthesis system based on emotions and semantics**|Thanh Hoang-Minh et.al.|[2507.03147](https://arxiv.org/abs/2507.03147)|null|
|**2025-07-03**|**Multi-agent Auditory Scene Analysis**|Caleb Rascon et.al.|[2507.02755](https://arxiv.org/abs/2507.02755)|null|
|**2025-07-03**|**Open-Source System for Multilingual Translation and Cloned Speech Synthesis**|Mateo Cámara et.al.|[2507.02530](https://arxiv.org/abs/2507.02530)|null|
|**2025-07-03**|**A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages**|Sumaya Ahmed Salihs et.al.|[2507.02428](https://arxiv.org/abs/2507.02428)|null|
|**2025-07-03**|**Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability**|Mark Atta Mensah et.al.|[2507.02407](https://arxiv.org/abs/2507.02407)|null|
|**2025-07-02**|**Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis**|Marc-André Carbonneau et.al.|[2507.02176](https://arxiv.org/abs/2507.02176)|null|
|**2025-07-02**|**Pronunciation Editing for Finnish Speech using Phonetic Posteriorgrams**|Zirui Li et.al.|[2507.02115](https://arxiv.org/abs/2507.02115)|null|
|**2025-07-02**|**Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla**|Md Sazzadul Islam Ridoy et.al.|[2507.01931](https://arxiv.org/abs/2507.01931)|null|
|**2025-07-02**|**First Steps Towards Voice Anonymization for Code-Switching Speech**|Sarina Meyer et.al.|[2507.01765](https://arxiv.org/abs/2507.01765)|null|
|**2025-07-02**|**PERTINENCE: Input-based Opportunistic Neural Network Dynamic Execution**|Omkar Shende et.al.|[2507.01695](https://arxiv.org/abs/2507.01695)|null|
|**2025-07-02**|**Voice Conversion for Likability Control via Automated Rating of Speech Synthesis Corpora**|Hitoshi Suda et.al.|[2507.01356](https://arxiv.org/abs/2507.01356)|null|
|**2025-07-02**|**Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation**|Andrei Jelea et.al.|[2507.01347](https://arxiv.org/abs/2507.01347)|null|
|**2025-07-02**|**AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance**|Vishakha Lall et.al.|[2507.01274](https://arxiv.org/abs/2507.01274)|null|
|**2025-07-01**|**MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement**|Nikolai Lund Kühne et.al.|[2507.00966](https://arxiv.org/abs/2507.00966)|null|
|**2025-07-02**|**Multi-interaction TTS toward professional recording reproduction**|Hiroki Kanagawa et.al.|[2507.00808](https://arxiv.org/abs/2507.00808)|null|
|**2025-07-01**|**Rectifying Magnitude Neglect in Linear Attention**|Qihang Fan et.al.|[2507.00698](https://arxiv.org/abs/2507.00698)|null|
|**2025-07-01**|**Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding**|Duc Cao-Dinh et.al.|[2507.00669](https://arxiv.org/abs/2507.00669)|null|
|**2025-06-29**|**You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties**|Paige Tuttösí et.al.|[2506.23367](https://arxiv.org/abs/2506.23367)|null|
|**2025-06-29**|**The Florence Price Art Song Dataset and Piano Accompaniment Generator**|Tao-Tao He et.al.|[2506.23130](https://arxiv.org/abs/2506.23130)|null|
|**2025-06-29**|**TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure**|Qi He et.al.|[2506.23094](https://arxiv.org/abs/2506.23094)|null|
|**2025-06-29**|**Research on Comprehensive Classroom Evaluation System Based on Multiple AI Models**|Cong Xie et.al.|[2506.23079](https://arxiv.org/abs/2506.23079)|null|
|**2025-06-28**|**Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions**|Duygu Altinok et.al.|[2506.22858](https://arxiv.org/abs/2506.22858)|null|
|**2025-06-28**|**Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization**|Duygu Altinok et.al.|[2506.22846](https://arxiv.org/abs/2506.22846)|null|
|**2025-06-28**|**A Self-Training Approach for Whisper to Enhance Long Dysarthric Speech Recognition**|Shiyao Wang et.al.|[2506.22810](https://arxiv.org/abs/2506.22810)|null|
|**2025-06-27**|**Speaker Targeting via Self-Speaker Adaptation for Multi-talker ASR**|Weiqing Wang et.al.|[2506.22646](https://arxiv.org/abs/2506.22646)|null|
|**2025-06-27**|**Cross-lingual Data Selection Using Clip-level Acoustic Similarity for Enhancing Low-resource Automatic Speech Recognition**|Shunsuke Mitsumori et.al.|[2506.22194](https://arxiv.org/abs/2506.22194)|null|
|**2025-06-27**|**SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition**|Muhammad Umar Farooq et.al.|[2506.22143](https://arxiv.org/abs/2506.22143)|null|
|**2025-06-27**|**Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration**|Noora Sassali et.al.|[2506.22116](https://arxiv.org/abs/2506.22116)|null|
|**2025-06-27**|**Robust and Efficient Autoregressive Speech Synthesis with Dynamic Chunk-wise Prediction Policy**|Bohan Li et.al.|[2506.22023](https://arxiv.org/abs/2506.22023)|null|
|**2025-06-27**|**Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit**|Kartheek Kumar Reddy Nareddy et.al.|[2506.21990](https://arxiv.org/abs/2506.21990)|null|
|**2025-06-26**|**Exploring Adapter Design Tradeoffs for Low Resource Music Generation**|Atharva Mehta et.al.|[2506.21298](https://arxiv.org/abs/2506.21298)|null|
|**2025-06-26**|**A Multi-Stage Framework for Multimodal Controllable Speech Synthesis**|Rui Niu et.al.|[2506.20945](https://arxiv.org/abs/2506.20945)|null|
|**2025-06-25**|**Multimodal Representation Learning and Fusion**|Qihang Jin et.al.|[2506.20494](https://arxiv.org/abs/2506.20494)|null|
|**2025-06-25**|**Lightweight Target-Speaker-Based Overlap Transcription for Practical Streaming ASR**|Aleš Pražák et.al.|[2506.20288](https://arxiv.org/abs/2506.20288)|null|
|**2025-06-24**|**Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR**|Martin Ratajczak et.al.|[2506.19761](https://arxiv.org/abs/2506.19761)|null|
|**2025-06-23**|**A Fourier Explanation of AI-music Artifacts**|Darius Afchar et.al.|[2506.19108](https://arxiv.org/abs/2506.19108)|null|
|**2025-06-23**|**Benchmarking Music Generation Models and Metrics via Human Preference Studies**|Florian Grötschla et.al.|[2506.19085](https://arxiv.org/abs/2506.19085)|null|
|**2025-06-23**|**Let Your Video Listen to Your Music!**|Xinyu Zhang et.al.|[2506.18881](https://arxiv.org/abs/2506.18881)|null|
|**2025-06-24**|**MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners**|Fang-Duo Tsai et.al.|[2506.18729](https://arxiv.org/abs/2506.18729)|**[link](https://github.com/fundwotsai2001/MuseControlLite)**|
|**2025-06-23**|**Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition**|Christian Huber et.al.|[2506.18703](https://arxiv.org/abs/2506.18703)|null|
|**2025-06-23**|**Evaluating Multichannel Speech Enhancement Algorithms at the Phoneme Scale Across Genders**|Nasser-Eddine Monir et.al.|[2506.18691](https://arxiv.org/abs/2506.18691)|null|
|**2025-06-23**|**End-to-End Spoken Grammatical Error Correction**|Mengjie Qian et.al.|[2506.18532](https://arxiv.org/abs/2506.18532)|null|
|**2025-06-23**|**AI-Generated Song Detection via Lyrics Transcripts**|Markus Frohmann et.al.|[2506.18488](https://arxiv.org/abs/2506.18488)|null|
|**2025-06-23**|**Selecting N-lowest scores for training MOS prediction models**|Yuto Kondo et.al.|[2506.18326](https://arxiv.org/abs/2506.18326)|null|
|**2025-06-23**|**Large-Scale Training Data Attribution for Music Generative Models via Unlearning**|Woosung Choi et.al.|[2506.18312](https://arxiv.org/abs/2506.18312)|null|
|**2025-06-23**|**Rethinking Mean Opinion Scores in Speech Quality Assessment: Aggregation through Quantized Distribution Fitting**|Yuto Kondo et.al.|[2506.18307](https://arxiv.org/abs/2506.18307)|null|
|**2025-06-23**|**JIS: A Speech Corpus of Japanese Idol Speakers with Various Speaking Styles**|Yuto Kondo et.al.|[2506.18296](https://arxiv.org/abs/2506.18296)|null|
|**2025-06-20**|**Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025**|Dominik Macháček et.al.|[2506.17077](https://arxiv.org/abs/2506.17077)|null|
|**2025-06-20**|**Instituto de Telecomunicações at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning**|Giuseppe Attanasio et.al.|[2506.17019](https://arxiv.org/abs/2506.17019)|null|
|**2025-06-20**|**State-Space Models in Efficient Whispered and Multi-dialect Speech Recognition**|Aref Farhadipour et.al.|[2506.16969](https://arxiv.org/abs/2506.16969)|null|
|**2025-06-20**|**Hybrid-Sep: Language-queried audio source separation via pre-trained Model Fusion and Adversarial Diffusion Training**|Jianyuan Feng et.al.|[2506.16833](https://arxiv.org/abs/2506.16833)|null|
|**2025-06-20**|**RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching**|Hyun Joon Park et.al.|[2506.16741](https://arxiv.org/abs/2506.16741)|**[link](https://github.com/naver-ai/RapFlow-TTS)**|
|**2025-06-20**|**LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization**|Daejin Jo et.al.|[2506.16738](https://arxiv.org/abs/2506.16738)|null|
|**2025-06-20**|**V-CASS: Vision-context-aware Expressive Speech Synthesis for Enhancing User Understanding of Videos**|Qixin Wang et.al.|[2506.16716](https://arxiv.org/abs/2506.16716)|null|
|**2025-06-19**|**Weight Factorization and Centralization for Continual Learning in Speech Recognition**|Enes Yavuz Ugan et.al.|[2506.16574](https://arxiv.org/abs/2506.16574)|null|
|**2025-06-19**|**Automatic Speech Recognition Biases in Newcastle English: an Error Analysis**|Dana Serditova et.al.|[2506.16558](https://arxiv.org/abs/2506.16558)|null|
|**2025-06-19**|**InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems**|Kexin Huang et.al.|[2506.16381](https://arxiv.org/abs/2506.16381)|**[link](https://github.com/kexinhuang19/instructttseval)**|
|**2025-06-18**|**Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models**|Teysir Baoueb et.al.|[2506.15530](https://arxiv.org/abs/2506.15530)|null|
|**2025-06-18**|**Exploiting Music Source Separation for Automatic Lyrics Transcription with Whisper**|Jaza Syed et.al.|[2506.15514](https://arxiv.org/abs/2506.15514)|**[link](https://github.com/jaza-syed/mss-alt)**|
|**2025-06-18**|**Foundation of Affective Computing and Interaction**|Changzeng Fu et.al.|[2506.15497](https://arxiv.org/abs/2506.15497)|null|
|**2025-06-18**|**An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW**|Prateek Mehta et.al.|[2506.15029](https://arxiv.org/abs/2506.15029)|null|
|**2025-06-17**|**A Comparative Evaluation of Deep Learning Models for Speech Enhancement in Real-World Noisy Environments**|Md Jahangir Alam Khondkar et.al.|[2506.15000](https://arxiv.org/abs/2506.15000)|**[link](https://github.com/jahangirkhondkar/dl_speechenhancementtoolkit)**|
|**2025-06-17**|**Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition**|Jiamin Xie et.al.|[2506.14973](https://arxiv.org/abs/2506.14973)|null|
|**2025-06-17**|**Unifying Streaming and Non-streaming Zipformer-based ASR**|Bidisha Sharma et.al.|[2506.14434](https://arxiv.org/abs/2506.14434)|null|
|**2025-06-17**|**Investigation of Zero-shot Text-to-Speech Models for Enhancing Short-Utterance Speaker Verification**|Yiyang Zhao et.al.|[2506.14226](https://arxiv.org/abs/2506.14226)|null|
|**2025-06-17**|**Improving Practical Aspects of End-to-End Multi-Talker Speech Recognition for Online and Offline Scenarios**|Aswin Shanmugam Subramanian et.al.|[2506.14204](https://arxiv.org/abs/2506.14204)|null|
|**2025-06-17**|**AsyncSwitch: Asynchronous Text-Speech Adaptation for Code-Switched ASR**|Tuan Nguyen et.al.|[2506.14190](https://arxiv.org/abs/2506.14190)|null|
|**2025-06-17**|**Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models**|Tuan Dat Phuong et.al.|[2506.14153](https://arxiv.org/abs/2506.14153)|null|
|**2025-06-16**|**Qwen vs. Gemma Integration with Whisper: A Comparative Study in Multilingual SpeechLLM Systems**|Tuan Nguyen et.al.|[2506.13596](https://arxiv.org/abs/2506.13596)|null|
|**2025-06-16**|**From Flat to Feeling: A Feasibility and Impact Study on Dynamic Facial Emotions in AI-Generated Avatars**|Pegah Salehi et.al.|[2506.13477](https://arxiv.org/abs/2506.13477)|null|
|**2025-06-16**|**BUT System for the MLC-SLM Challenge**|Alexander Polok et.al.|[2506.13414](https://arxiv.org/abs/2506.13414)|**[link](https://github.com/BUTSpeechFIT/TS-ASR-Whisper)**|
|**2025-06-16**|**Bi-directional Context-Enhanced Speech Large Language Models for Multilingual Conversational ASR**|Yizhou Peng et.al.|[2506.13396](https://arxiv.org/abs/2506.13396)|null|
|**2025-06-16**|**NTU Speechlab LLM-Based Multilingual ASR System for Interspeech MLC-SLM Challenge 2025**|Yizhou Peng et.al.|[2506.13339](https://arxiv.org/abs/2506.13339)|null|
|**2025-06-16**|**Seewo's Submission to MLC-SLM: Lessons learned from Speech Reasoning Language Models**|Bo Li et.al.|[2506.13300](https://arxiv.org/abs/2506.13300)|null|
|**2025-06-16**|**Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV**|Christian Zhou-Zheng et.al.|[2506.13001](https://arxiv.org/abs/2506.13001)|**[link](https://github.com/christianazinn/MIDI-RWKV.)**|
|**2025-06-15**|**SC-SOT: Conditioning the Decoder on Diarized Speaker Information for End-to-End Overlapped Speech Recognition**|Yuta Hirano et.al.|[2506.12672](https://arxiv.org/abs/2506.12672)|null|
|**2025-06-14**|**Video-Guided Text-to-Music Generation Using Public Domain Movie Collections**|Haven Kim et.al.|[2506.12573](https://arxiv.org/abs/2506.12573)|null|
|**2025-06-14**|**Mitigating Non-Target Speaker Bias in Guided Speaker Embedding**|Shota Horiguchi et.al.|[2506.12500](https://arxiv.org/abs/2506.12500)|null|
|**2025-06-13**|**Enabling automatic transcription of child-centered audio recordings from real-world environments**|Daniil Kocharov et.al.|[2506.11747](https://arxiv.org/abs/2506.11747)|null|
|**2025-06-13**|**Lightweight and Robust Multi-Channel End-to-End Speech Recognition with Spherical Harmonic Transform**|Xiangzhu Kong et.al.|[2506.11630](https://arxiv.org/abs/2506.11630)|null|
|**2025-06-13**|**(SimPhon Speech Test): A Data-Driven Method for In Silico Design and Validation of a Phonetically Balanced Speech Test**|Stefan Bleeck et.al.|[2506.11620](https://arxiv.org/abs/2506.11620)|null|
|**2025-06-13**|**Machine Unlearning for Robust DNNs: Attribution-Guided Partitioning and Neuron Pruning in Noisy Environments**|Deliang Jin et.al.|[2506.11615](https://arxiv.org/abs/2506.11615)|null|
|**2025-06-12**|**Advances in Small-Footprint Keyword Spotting: A Comprehensive Review of Efficient Models and Algorithms**|Soumen Garai et.al.|[2506.11169](https://arxiv.org/abs/2506.11169)|null|
|**2025-06-12**|**Improving Named Entity Transcription with Contextual LLM-based Revision**|Viet Anh Trinh et.al.|[2506.10779](https://arxiv.org/abs/2506.10779)|null|
|**2025-06-12**|**BNMusic: Blending Environmental Noises into Personalized Music**|Chi Zuo et.al.|[2506.10754](https://arxiv.org/abs/2506.10754)|null|
|**2025-06-12**|**FairASR: Fair Audio Contrastive Learning for Automatic Speech Recognition**|Jongsuk Kim et.al.|[2506.10747](https://arxiv.org/abs/2506.10747)|null|
|**2025-06-12**|**Joint ASR and Speaker Role Tagging with Serialized Output Training**|Anfeng Xu et.al.|[2506.10349](https://arxiv.org/abs/2506.10349)|null|
|**2025-06-12**|**RT-VC: Real-Time Zero-Shot Voice Conversion with Speech Articulatory Coding**|Yisi Liu et.al.|[2506.10289](https://arxiv.org/abs/2506.10289)|null|
|**2025-06-11**|**Fine-Grained control over Music Generation with Activation Steering**|Dipanshu Panda et.al.|[2506.10225](https://arxiv.org/abs/2506.10225)|null|
|**2025-06-11**|**UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching**|Neta Glazer et.al.|[2506.09874](https://arxiv.org/abs/2506.09874)|null|
|**2025-06-11**|**Regularizing Learnable Feature Extraction for Automatic Speech Recognition**|Peter Vieting et.al.|[2506.09804](https://arxiv.org/abs/2506.09804)|null|
|**2025-06-11**|**Training-Free Voice Conversion with Factorized Optimal Transport**|Alexander Lobashev et.al.|[2506.09709](https://arxiv.org/abs/2506.09709)|**[link](https://github.com/alobashev/mkl-vc)**|
|**2025-06-11**|**You Are What You Say: Exploiting Linguistic Content for VoicePrivacy Attacks**|Ünal Ege Gaznepoglu et.al.|[2506.09521](https://arxiv.org/abs/2506.09521)|null|
|**2025-06-11**|**OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary**|Yui Sudo et.al.|[2506.09448](https://arxiv.org/abs/2506.09448)|null|
|**2025-06-11**|**CoLMbo: Speaker Language Model for Descriptive Profiling**|Massa Baali et.al.|[2506.09375](https://arxiv.org/abs/2506.09375)|null|
|**2025-06-11**|**OmniDRCA: Parallel Speech-Text Foundation Model via Dual-Resolution Speech Representations and Contrastive Alignment**|Chao-Hong Tan et.al.|[2506.09349](https://arxiv.org/abs/2506.09349)|null|
|**2025-06-10**|**SimClass: A Classroom Speech Dataset Generated via Game Engine Simulation For Automatic Speech Recognition Research**|Ahmed Adel Attia et.al.|[2506.09206](https://arxiv.org/abs/2506.09206)|null|
|**2025-06-10**|**FROST-EMA: Finnish and Russian Oral Speech Dataset of Electromagnetic Articulography Measurements with L1, L2 and Imitated L2 Accents**|Satu Hopponen et.al.|[2506.08981](https://arxiv.org/abs/2506.08981)|null|
|**2025-06-10**|**Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model**|Ailin Huang et.al.|[2506.08967](https://arxiv.org/abs/2506.08967)|null|
|**2025-06-09**|**Uncovering the Functional Roles of Nonlinearity in Memory**|Manuel Brenner et.al.|[2506.07919](https://arxiv.org/abs/2506.07919)|null|
|**2025-06-09**|**Unified Semi-Supervised Pipeline for Automatic Speech Recognition**|Nune Tadevosyan et.al.|[2506.07659](https://arxiv.org/abs/2506.07659)|null|
|**2025-06-09**|**Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation**|Rui Hu et.al.|[2506.07646](https://arxiv.org/abs/2506.07646)|null|
|**2025-06-09**|**SongBloom: Coherent Song Generation via Interleaved Autoregressive Sketching and Diffusion Refinement**|Chenyu Yang et.al.|[2506.07634](https://arxiv.org/abs/2506.07634)|**[link](https://github.com/Cypress-Yang/SongBloom)**|
|**2025-06-09**|**Bayesian Learning for Domain-Invariant Speaker Verification and Anti-Spoofing**|Jin Li et.al.|[2506.07536](https://arxiv.org/abs/2506.07536)|null|
|**2025-06-09**|**LeVo: High-Quality Song Generation with Multi-Preference Alignment**|Shun Lei et.al.|[2506.07520](https://arxiv.org/abs/2506.07520)|**[link](https://github.com/tencent-ailab/songgeneration)**|
|**2025-06-09**|**Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition**|Asahi Sakuma et.al.|[2506.07515](https://arxiv.org/abs/2506.07515)|null|
|**2025-06-09**|**DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction**|Solee Im et.al.|[2506.07510](https://arxiv.org/abs/2506.07510)|null|
|**2025-06-09**|**Towards Energy-Efficient and Low-Latency Voice-Controlled Smart Homes: A Proposal for Offline Speech Recognition and IoT Integration**|Peng Huang et.al.|[2506.07494](https://arxiv.org/abs/2506.07494)|null|
|**2025-06-08**|**Speech Recognition on TV Series with Video-guided Post-Correction**|Haoyuan Yang et.al.|[2506.07323](https://arxiv.org/abs/2506.07323)|null|
|**2025-06-06**|**Lightweight Prompt Biasing for Contextualized End-to-End ASR Systems**|Bo Ren et.al.|[2506.06252](https://arxiv.org/abs/2506.06252)|null|
|**2025-06-06**|**Phonetically-Augmented Discriminative Rescoring for Voice Search Error Correction**|Christophe Van Gysel et.al.|[2506.06117](https://arxiv.org/abs/2506.06117)|null|
|**2025-06-06**|**CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition**|Yun-Shao Tsai et.al.|[2506.06071](https://arxiv.org/abs/2506.06071)|null|
|**2025-06-06**|**Diarization-Aware Multi-Speaker Automatic Speech Recognition via Large Language Models**|Yuke Lin et.al.|[2506.05796](https://arxiv.org/abs/2506.05796)|null|
|**2025-06-06**|**Bridging the Modality Gap: Softly Discretizing Audio Representation for LLM-based Automatic Speech Recognition**|Mu Yang et.al.|[2506.05706](https://arxiv.org/abs/2506.05706)|null|
|**2025-06-06**|**Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning**|Yangui Fang et.al.|[2506.05671](https://arxiv.org/abs/2506.05671)|null|
|**2025-06-05**|**Improving AI-generated music with user-guided training**|Vishwa Mohan Singh et.al.|[2506.04852](https://arxiv.org/abs/2506.04852)|null|
|**2025-06-05**|**LLM-based phoneme-to-grapheme for phoneme-based speech recognition**|Te Ma et.al.|[2506.04711](https://arxiv.org/abs/2506.04711)|null|
|**2025-06-05**|**ViCocktail: Automated Multi-Modal Data Collection for Vietnamese Audio-Visual Speech Recognition**|Thai-Binh Nguyen et.al.|[2506.04635](https://arxiv.org/abs/2506.04635)|null|
|**2025-06-05**|**LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models**|Wen Ding et.al.|[2506.04586](https://arxiv.org/abs/2506.04586)|null|
|**2025-06-04**|**French Listening Tests for the Assessment of Intelligibility, Quality, and Identity of Body-Conducted Speech Enhancement**|Thomas Joubaud et.al.|[2506.04495](https://arxiv.org/abs/2506.04495)|null|
|**2025-06-04**|**Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent Robustness in Low-Resource ASR**|Zheng-Xin Yong et.al.|[2506.04364](https://arxiv.org/abs/2506.04364)|null|
|**2025-06-04**|**HiFiTTS-2: A Large-Scale High Bandwidth Speech Dataset**|Ryan Langman et.al.|[2506.04152](https://arxiv.org/abs/2506.04152)|null|
|**2025-06-04**|**A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions**|Chung-Chun Wang et.al.|[2506.04077](https://arxiv.org/abs/2506.04077)|null|
|**2025-06-04**|**Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive Voice Conversion**|Seymanur Akti et.al.|[2506.04013](https://arxiv.org/abs/2506.04013)|null|
|**2025-06-04**|**MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition**|Yinfeng Xia et.al.|[2506.03722](https://arxiv.org/abs/2506.03722)|null|
|**2025-06-04**|**Comparative Analysis of Fast and High-Fidelity Neural Vocoders for Low-Latency Streaming Synthesis in Resource-Constrained Environments**|Reo Yoneyama et.al.|[2506.03554](https://arxiv.org/abs/2506.03554)|null|
|**2025-06-04**|**Local Equivariance Error-Based Metrics for Evaluating Sampling-Frequency-Independent Property of Neural Network**|Kanami Imamura et.al.|[2506.03550](https://arxiv.org/abs/2506.03550)|null|
|**2025-06-03**|**Controllable Text-to-Speech Synthesis with Masked-Autoencoded Style-Rich Representation**|Yongqi Wang et.al.|[2506.02997](https://arxiv.org/abs/2506.02997)|null|
|**2025-06-03**|**A Multi-Dialectal Dataset for German Dialect ASR and Dialect-to-Standard Speech Translation**|Verena Blaschke et.al.|[2506.02894](https://arxiv.org/abs/2506.02894)|**[link](https://github.com/mainlp/betthupferl)**|
|**2025-06-03**|**CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech**|Helin Wang et.al.|[2506.02863](https://arxiv.org/abs/2506.02863)|**[link](https://github.com/WangHelin1997/CapSpeech)**|
|**2025-06-05**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al.|[2506.02858](https://arxiv.org/abs/2506.02858)|null|
|**2025-06-03**|**On the influence of language similarity in non-target speaker verification trials**|Paul M. Reuter et.al.|[2506.02777](https://arxiv.org/abs/2506.02777)|null|
|**2025-06-03**|**Prompt-Unseen-Emotion: Zero-shot Expressive Speech Synthesis with Prompt-LLM Contextual Knowledge for Mixed Emotions**|Xiaoxue Gao et.al.|[2506.02742](https://arxiv.org/abs/2506.02742)|null|
|**2025-06-03**|**Overcoming Data Scarcity in Multi-Dialectal Arabic ASR via Whisper Fine-Tuning**|Ömer Tarik Özyilmaz et.al.|[2506.02627](https://arxiv.org/abs/2506.02627)|null|
|**2025-06-03**|**On the Language and Gender Biases in PSTN, VoIP and Neural Audio Codecs**|Kemal Altwlkany et.al.|[2506.02545](https://arxiv.org/abs/2506.02545)|null|
|**2025-06-03**|**DnR-nonverbal: Cinematic Audio Source Separation Dataset Containing Non-Verbal Sounds**|Takuya Hasumi et.al.|[2506.02499](https://arxiv.org/abs/2506.02499)|null|
|**2025-06-03**|**SOVA-Bench: Benchmarking the Speech Conversation Ability for LLM-based Voice Assistant**|Yixuan Hou et.al.|[2506.02457](https://arxiv.org/abs/2506.02457)|null|
|**2025-05-30**|**Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach**|Nick Rossenbach et.al.|[2505.24721](https://arxiv.org/abs/2505.24721)|null|
|**2025-05-30**|**Voice Conversion Improves Cross-Domain Robustness for Spoken Arabic Dialect Identification**|Badr M. Abdullah et.al.|[2505.24713](https://arxiv.org/abs/2505.24713)|**[link](https://github.com/badrex/arabic-dialect-identification)**|
|**2025-06-02**|**MSDA: Combining Pseudo-labeling and Self-Supervision for Unsupervised Domain Adaptation in ASR**|Dimitrios Damianos et.al.|[2505.24656](https://arxiv.org/abs/2505.24656)|null|
|**2025-05-30**|**Pretraining Multi-Speaker Identification for Neural Speaker Diarization**|Shota Horiguchi et.al.|[2505.24545](https://arxiv.org/abs/2505.24545)|null|
|**2025-05-30**|**SuPseudo: A Pseudo-supervised Learning Method for Neural Speech Enhancement in Far-field Speech Recognition**|Longjie Luo et.al.|[2505.24450](https://arxiv.org/abs/2505.24450)|null|
|**2025-05-30**|**Pseudo Labels-based Neural Speech Enhancement for the AVSR Task in the MISP-Meeting Challenge**|Longjie Luo et.al.|[2505.24446](https://arxiv.org/abs/2505.24446)|null|
|**2025-05-30**|**Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction**|Yangui Fang et.al.|[2505.24347](https://arxiv.org/abs/2505.24347)|null|
|**2025-05-30**|**When Humans Growl and Birds Speak: High-Fidelity Voice Conversion from Human to Animal and Designed Sounds**|Minsu Kang et.al.|[2505.24336](https://arxiv.org/abs/2505.24336)|null|
|**2025-05-30**|**A Perception-Based L2 Speech Intelligibility Indicator: Leveraging a Rater's Shadowing and Sequence-to-sequence Voice Conversion**|Haopeng Geng et.al.|[2505.24304](https://arxiv.org/abs/2505.24304)|null|
|**2025-05-30**|**Discl-VC: Disentangled Discrete Tokens and In-Context Learning for Controllable Zero-Shot Voice Conversion**|Kaidi Wang et.al.|[2505.24291](https://arxiv.org/abs/2505.24291)|null|
|**2025-05-29**|**Prompting Whisper for Improved Verbatim Transcription and End-to-end Miscue Detection**|Griffin Dietz Smith et.al.|[2505.23627](https://arxiv.org/abs/2505.23627)|null|
|**2025-05-29**|**ZeroSep: Separate Anything in Audio with Zero Training**|Chao Huang et.al.|[2505.23625](https://arxiv.org/abs/2505.23625)|**[link](https://github.com/WikiChao/ZeroSep)**|
|**2025-05-29**|**MGE-LDM: Joint Latent Diffusion for Simultaneous Music Generation and Source Extraction**|Yunkee Chae et.al.|[2505.23305](https://arxiv.org/abs/2505.23305)|null|
|**2025-05-29**|**Contextualized Automatic Speech Recognition with Dynamic Vocabulary Prediction and Activation**|Zhennan Lin et.al.|[2505.23077](https://arxiv.org/abs/2505.23077)|null|
|**2025-05-29**|**AISHELL-5: The First Open-Source In-Car Multi-Channel Multi-Speaker Speech Dataset for Automatic Speech Diarization and Recognition**|Yuhang Dai et.al.|[2505.23036](https://arxiv.org/abs/2505.23036)|**[link](https://github.com/daiyvhang/aishell-5)**|
|**2025-05-28**|**BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models**|Susan Liang et.al.|[2505.22865](https://arxiv.org/abs/2505.22865)|null|
|**2025-05-28**|**NGPU-LM: GPU-Accelerated N-Gram Language Model for Context-Biasing in Greedy ASR Decoding**|Vladimir Bataev et.al.|[2505.22857](https://arxiv.org/abs/2505.22857)|null|
|**2025-05-28**|**Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition**|Yuan Tseng et.al.|[2505.22251](https://arxiv.org/abs/2505.22251)|null|
|**2025-05-28**|**Advancing Hearing Assessment: An ASR-Based Frequency-Specific Speech Test for Diagnosing Presbycusis**|Stefan Bleeck et.al.|[2505.22231](https://arxiv.org/abs/2505.22231)|null|
|**2025-05-28**|**On-the-fly Routing for Zero-shot MoE Speaker Adaptation of Speech Foundation Models for Dysarthric Speech Recognition**|Shujie HU et.al.|[2505.22072](https://arxiv.org/abs/2505.22072)|null|
|**2025-05-28**|**Weakly Supervised Data Refinement and Flexible Sequence Compression for Efficient Thai LLM-based ASR**|Mingchen Shao et.al.|[2505.22063](https://arxiv.org/abs/2505.22063)|null|
|**2025-05-28**|**Overlap-Adaptive Hybrid Speaker Diarization and ASR-Aware Observation Addition for MISP 2025 Challenge**|Shangkun Huang et.al.|[2505.22013](https://arxiv.org/abs/2505.22013)|null|
|**2025-05-28**|**Leveraging LLM for Stuttering Speech: A Unified Architecture Bridging Recognition and Event Detection**|Shangkun Huang et.al.|[2505.22005](https://arxiv.org/abs/2505.22005)|null|
|**2025-05-27**|**GMU Systems for the IWSLT 2025 Low-Resource Speech Translation Shared Task**|Chutong Meng et.al.|[2505.21781](https://arxiv.org/abs/2505.21781)|null|
|**2025-05-27**|**VoxAging: Continuously Tracking Speaker Aging with a Large-Scale Longitudinal Dataset in English and Mandarin**|Zhiqi Ai et.al.|[2505.21445](https://arxiv.org/abs/2505.21445)|null|
|**2025-05-27**|**Towards One-bit ASR: Extremely Low-bit Conformer Quantization Using Co-training and Stochastic Precision**|Zhaoqing Li et.al.|[2505.21245](https://arxiv.org/abs/2505.21245)|null|
|**2025-05-27**|**PSRB: A Comprehensive Benchmark for Evaluating Persian ASR Systems**|Nima Sedghiyeh et.al.|[2505.21230](https://arxiv.org/abs/2505.21230)|null|
|**2025-05-27**|**Topological Deep Learning for Speech Data**|Zhiwang Yu et.al.|[2505.21173](https://arxiv.org/abs/2505.21173)|null|
|**2025-05-27**|**Leveraging LLM and Self-Supervised Training Models for Speech Recognition in Chinese Dialects: A Comparative Analysis**|Tianyi Xu et.al.|[2505.21138](https://arxiv.org/abs/2505.21138)|null|
|**2025-05-27**|**Text-Queried Audio Source Separation via Hierarchical Modeling**|Xinlei Yin et.al.|[2505.21025](https://arxiv.org/abs/2505.21025)|null|
|**2025-05-27**|**VibE-SVC: Vibrato Extraction with High-frequency F0 Contour for Singing Voice Conversion**|Joon-Seung Choi et.al.|[2505.20794](https://arxiv.org/abs/2505.20794)|null|
|**2025-05-27**|**REWIND: Speech Time Reversal for Enhancing Speaker Representations in Diffusion-based Voice Conversion**|Ishan D. Biyani et.al.|[2505.20756](https://arxiv.org/abs/2505.20756)|null|
|**2025-05-27**|**PromptEVC: Controllable Emotional Voice Conversion with Natural Language Prompts**|Tianhua Qi et.al.|[2505.20678](https://arxiv.org/abs/2505.20678)|null|
|**2025-05-27**|**Towards Pretraining Robust ASR Foundation Model with Acoustic-Aware Data Augmentation**|Dancheng Liu et.al.|[2505.20606](https://arxiv.org/abs/2505.20606)|null|
|**2025-05-26**|**Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks**|Chang Liu et.al.|[2505.20038](https://arxiv.org/abs/2505.20038)|null|
|**2025-05-26**|**Mixture of LoRA Experts for Low-Resourced Multi-Accent Automatic Speech Recognition**|Raphaël Bagat et.al.|[2505.20006](https://arxiv.org/abs/2505.20006)|null|
|**2025-05-26**|**Novel Loss-Enhanced Universal Adversarial Patches for Sustainable Speaker Privacy**|Elvir Karimov et.al.|[2505.19951](https://arxiv.org/abs/2505.19951)|null|
|**2025-05-26**|**DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech**|Deok-Hyeon Cho et.al.|[2505.19687](https://arxiv.org/abs/2505.19687)|null|
|**2025-05-26**|**KIT's Low-resource Speech Translation Systems for IWSLT2025: System Enhancement with Synthetic Data and Model Regularization**|Zhaolin Li et.al.|[2505.19679](https://arxiv.org/abs/2505.19679)|null|
|**2025-05-26**|**Zero-Shot Streaming Text to Speech Synthesis with Transducer and Auto-Regressive Modeling**|Haiyang Sun et.al.|[2505.19669](https://arxiv.org/abs/2505.19669)|null|
|**2025-05-26**|**Languages in Multilingual Speech Foundation Models Align Both Phonetically and Semantically**|Ryan Soh-Eun Shim et.al.|[2505.19606](https://arxiv.org/abs/2505.19606)|null|
|**2025-05-26**|**Training-Free Multi-Step Audio Source Separation**|Yongyi Zang et.al.|[2505.19534](https://arxiv.org/abs/2505.19534)|null|
|**2025-05-26**|**Beyond Manual Transcripts: The Potential of Automated Speech Recognition Errors in Improving Alzheimer's Disease Detection**|Yin-Long Liu et.al.|[2505.19448](https://arxiv.org/abs/2505.19448)|null|
|**2025-05-26**|**GSA-TTS : Toward Zero-Shot Speech Synthesis based on Gradual Style Adaptor**|Seokgi Lee et.al.|[2505.19384](https://arxiv.org/abs/2505.19384)|null|
|**2025-05-23**|**Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities**|Ziwei Zhou et.al.|[2505.17862](https://arxiv.org/abs/2505.17862)|**[link](https://github.com/lliar-liar/daily-omni)**|
|**2025-05-23**|**CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training**|Zhihao Du et.al.|[2505.17589](https://arxiv.org/abs/2505.17589)|null|
|**2025-05-23**|**Private kNN-VC: Interpretable Anonymization of Converted Speech**|Carlos Franzreb et.al.|[2505.17584](https://arxiv.org/abs/2505.17584)|**[link](https://github.com/carlosfranzreb/private_knnvc)**|
|**2025-05-23**|**Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition**|Leonora Vesterbacka et.al.|[2505.17538](https://arxiv.org/abs/2505.17538)|null|
|**2025-05-23**|**Speechless: Speech Instruction Training Without Speech for Low Resource Languages**|Alan Dao et.al.|[2505.17417](https://arxiv.org/abs/2505.17417)|**[link](https://github.com/menloresearch/ichigo)**|
|**2025-05-23**|**LLM-based Generative Error Correction for Rare Words with Synthetic Data and Phonetic Context**|Natsuo Yamashita et.al.|[2505.17410](https://arxiv.org/abs/2505.17410)|null|
|**2025-05-23**|**An End-to-End Approach for Child Reading Assessment in the Xhosa Language**|Sergio Chevtchenko et.al.|[2505.17371](https://arxiv.org/abs/2505.17371)|null|
|**2025-05-22**|**An Effective Training Framework for Light-Weight Automatic Speech Recognition Models**|Abdul Hannan et.al.|[2505.16991](https://arxiv.org/abs/2505.16991)|null|
|**2025-05-22**|**From Tens of Hours to Tens of Thousands: Scaling Back-Translation for Speech Recognition**|Tianduo Wang et.al.|[2505.16972](https://arxiv.org/abs/2505.16972)|**[link](https://github.com/tianduowang/speech-bt)**|
|**2025-05-23**|**EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion**|Advait Joglekar et.al.|[2505.16691](https://arxiv.org/abs/2505.16691)|**[link](https://github.com/ez-vc/ez-vc)**|
|**2025-05-22**|**SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding**|Sushant Gautam et.al.|[2505.16630](https://arxiv.org/abs/2505.16630)|**[link](https://github.com/simula/SoccerChat)**|
|**2025-05-22**|**HPP-Voice: A Large-Scale Evaluation of Speech Embeddings for Multi-Phenotypic Classification**|David Krongauz et.al.|[2505.16490](https://arxiv.org/abs/2505.16490)|null|
|**2025-05-22**|**X-ARES: A Comprehensive Framework for Assessing Audio Encoder Performance**|Junbo Zhang et.al.|[2505.16369](https://arxiv.org/abs/2505.16369)|**[link](https://github.com/jimbozhang/xares)**|
|**2025-05-22**|**Large Language Models based ASR Error Correction for Child Conversations**|Anfeng Xu et.al.|[2505.16212](https://arxiv.org/abs/2505.16212)|null|
|**2025-05-22**|**Differentiable K-means for Fully-optimized Discrete Token-based ASR**|Kentaro Onda et.al.|[2505.16207](https://arxiv.org/abs/2505.16207)|null|
|**2025-05-22**|**Prosodically Enhanced Foreign Accent Simulation by Discrete Token-based Resynthesis Only with Native Speech Corpora**|Kentaro Onda et.al.|[2505.16191](https://arxiv.org/abs/2505.16191)|null|
|**2025-05-22**|**Selective Invocation for Multilingual ASR: A Cost-effective Approach Adapting to Speech Recognition Difficulty**|Hongfei Xue et.al.|[2505.16168](https://arxiv.org/abs/2505.16168)|null|
|**2025-05-21**|**MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech Paralinguistic and Affect Labeling**|Cheng Yifan et.al.|[2505.15772](https://arxiv.org/abs/2505.15772)|null|
|**2025-05-21**|**Word Level Timestamp Generation for Automatic Speech Recognition and Translation**|Ke Hu et.al.|[2505.15646](https://arxiv.org/abs/2505.15646)|null|
|**2025-05-21**|**Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes**|Zixun Guo et.al.|[2505.15559](https://arxiv.org/abs/2505.15559)|null|
|**2025-05-21**|**Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models**|Zirui Song et.al.|[2505.15406](https://arxiv.org/abs/2505.15406)|**[link](https://github.com/mbzuai-nlp/audiojailbreak)**|
|**2025-05-21**|**Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via In-Context Learning**|Junchuan Zhao et.al.|[2505.15402](https://arxiv.org/abs/2505.15402)|null|
|**2025-05-21**|**Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding**|Zijian Lin et.al.|[2505.15380](https://arxiv.org/abs/2505.15380)|null|
|**2025-05-21**|**Voice-ENHANCE: Speech Restoration using a Diffusion-based Voice Conversion Framework**|Kyungguen Byun et.al.|[2505.15254](https://arxiv.org/abs/2505.15254)|null|
|**2025-05-20**|**In-Context Learning Boosts Speech Recognition via Human-like Adaptation to Speakers and Language Varieties**|Nathan Roll et.al.|[2505.14887](https://arxiv.org/abs/2505.14887)|**[link](https://github.com/Nathan-Roll1/ASR-Adaptation)**|
|**2025-05-20**|**Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages**|Chin-Jou Li et.al.|[2505.14874](https://arxiv.org/abs/2505.14874)|null|
|**2025-05-20**|**Vox-Profile: A Speech Foundation Model Benchmark for Characterizing Diverse Speaker and Speech Traits**|Tiantian Feng et.al.|[2505.14648](https://arxiv.org/abs/2505.14648)|**[link](https://github.com/tiantiaf0627/vox-profile-release)**|
|**2025-05-20**|**Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference**|Tomer Gafni et.al.|[2505.14638](https://arxiv.org/abs/2505.14638)|null|
|**2025-05-20**|**SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification**|Theo Lepage et.al.|[2505.14561](https://arxiv.org/abs/2505.14561)|null|
|**2025-05-20**|**Pairwise Evaluation of Accent Similarity in Speech Synthesis**|Jinzuomu Zhong et.al.|[2505.14410](https://arxiv.org/abs/2505.14410)|null|
|**2025-05-20**|**PersonaTAB: Predicting Personality Traits using Textual, Acoustic, and Behavioral Cues in Fully-Duplex Speech Dialogs**|Sho Inoue et.al.|[2505.14356](https://arxiv.org/abs/2505.14356)|null|
|**2025-05-20**|**FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation**|Yutong Liu et.al.|[2505.14351](https://arxiv.org/abs/2505.14351)|null|
|**2025-05-20**|**Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach**|Umberto Cappellazzo et.al.|[2505.14336](https://arxiv.org/abs/2505.14336)|null|
|**2025-05-20**|**HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing**|Shamsuddeen Hassan Muhammad et.al.|[2505.14311](https://arxiv.org/abs/2505.14311)|null|
|**2025-05-20**|**Source Verification for Speech Deepfakes**|Viola Negroni et.al.|[2505.14188](https://arxiv.org/abs/2505.14188)|null|
|**2025-05-20**|**The Multimodal Information Based Speech Processing (MISP) 2025 Challenge: Audio-Visual Diarization and Recognition**|Ming Gao et.al.|[2505.13971](https://arxiv.org/abs/2505.13971)|null|
|**2025-05-19**|**Granary: Speech Recognition and Translation Dataset in 25 European Languages**|Nithin Rao Koluguri et.al.|[2505.13404](https://arxiv.org/abs/2505.13404)|null|
|**2025-05-19**|**Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space**|Zhengrui Ma et.al.|[2505.13181](https://arxiv.org/abs/2505.13181)|**[link](https://github.com/ictnlp/sled-tts)**|
|**2025-05-19**|**Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR**|Xugang Lu et.al.|[2505.13079](https://arxiv.org/abs/2505.13079)|null|
|**2025-05-19**|**KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025**|Sai Koneru et.al.|[2505.13036](https://arxiv.org/abs/2505.13036)|**[link](https://github.com/MaikeZuefle/contr-pretraining)**|
|**2025-05-19**|**Personalized Fine-Tuning with Controllable Synthetic Speech from LLM-Generated Transcripts for Dysarthric Speech Recognition**|Dominik Wagner et.al.|[2505.12991](https://arxiv.org/abs/2505.12991)|null|
|**2025-05-19**|**Calm-Whisper: Reduce Whisper Hallucination On Non-Speech By Calming Crazy Heads Down**|Yingzhi Wang et.al.|[2505.12969](https://arxiv.org/abs/2505.12969)|null|
|**2025-05-19**|**Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio**|Jongmin Jung et.al.|[2505.12863](https://arxiv.org/abs/2505.12863)|null|
|**2025-05-19**|**OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching**|Hieu-Nghia Huynh-Nguyen et.al.|[2505.12800](https://arxiv.org/abs/2505.12800)|null|
|**2025-05-19**|**RoVo: Robust Voice Protection Against Unauthorized Speech Synthesis with Embedding-Level Perturbations**|Seungmin Kim et.al.|[2505.12686](https://arxiv.org/abs/2505.12686)|null|
|**2025-05-19**|**Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment**|Abhinaba Roy et.al.|[2505.12669](https://arxiv.org/abs/2505.12669)|**[link](https://github.com/amaai-lab/t2m-inferalign)**|
|**2025-05-16**|**LipDiffuser: Lip-to-Speech Generation with Conditional Diffusion Models**|Danilo de Oliveira et.al.|[2505.11391](https://arxiv.org/abs/2505.11391)|null|
|**2025-05-16**|**LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors**|Rao Ma et.al.|[2505.11352](https://arxiv.org/abs/2505.11352)|null|
|**2025-05-16**|**Survey of End-to-End Multi-Speaker Automatic Speech Recognition for Monaural Audio**|Xinlu He et.al.|[2505.10975](https://arxiv.org/abs/2505.10975)|null|
|**2025-05-16**|**Multi-Stage Speaker Diarization for Noisy Classrooms**|Ali Sartaz Khan et.al.|[2505.10879](https://arxiv.org/abs/2505.10879)|null|
|**2025-05-15**|**UDDETTS: Unifying Discrete and Dimensional Emotions for Controllable Emotional Text-to-Speech**|Jiaxuan Liu et.al.|[2505.10599](https://arxiv.org/abs/2505.10599)|null|
|**2025-05-15**|**Inclusivity of AI Speech in Healthcare: A Decade Look Back**|Retno Larasati et.al.|[2505.10596](https://arxiv.org/abs/2505.10596)|null|
|**2025-05-15**|**Quantized Approximate Signal Processing (QASP): Towards Homomorphic Encryption for audio**|Tu Duyen Nguyen et.al.|[2505.10500](https://arxiv.org/abs/2505.10500)|null|
|**2025-05-14**|**GlobalMood: A cross-cultural benchmark for music emotion recognition**|Harin Lee et.al.|[2505.09539](https://arxiv.org/abs/2505.09539)|null|
|**2025-05-14**|**SingNet: Towards a Large-Scale, Diverse, and In-the-Wild Singing Voice Dataset**|Yicheng Gu et.al.|[2505.09325](https://arxiv.org/abs/2505.09325)|null|
|**2025-05-14**|**DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis**|Zeeshan Ahmad et.al.|[2505.09091](https://arxiv.org/abs/2505.09091)|null|
|**2025-05-13**|**Inference Attacks for X-Vector Speaker Anonymization**|Luke Bauer et.al.|[2505.08978](https://arxiv.org/abs/2505.08978)|null|
|**2025-05-13**|**Investigating self-supervised features for expressive, multilingual voice conversion**|Álvaro Martín-Cortinas et.al.|[2505.08278](https://arxiv.org/abs/2505.08278)|null|
|**2025-05-13**|**Not that Groove: Zero-Shot Symbolic Music Editing**|Li Zhang et.al.|[2505.08203](https://arxiv.org/abs/2505.08203)|null|
|**2025-05-12**|**Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications**|Biel Tura Vecino et.al.|[2505.07701](https://arxiv.org/abs/2505.07701)|null|
|**2025-05-12**|**Full simulation on the dynamics of auditory synaptic fusion: Strong clustering of calcium channel might be the origin of the coherent release in the auditory hair cells**|Jaeyun Yoo et.al.|[2505.07273](https://arxiv.org/abs/2505.07273)|null|
|**2025-05-09**|**Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients**|Jinsheng Yuan et.al.|[2505.06335](https://arxiv.org/abs/2505.06335)|null|
|**2025-05-08**|**Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations**|Linrong Pan et.al.|[2505.05056](https://arxiv.org/abs/2505.05056)|null|
|**2025-05-08**|**A Multi-Agent AI Framework for Immersive Audiobook Production through Spatial Audio and Neural Narration**|Shaja Arul Selvamani et.al.|[2505.04885](https://arxiv.org/abs/2505.04885)|null|
|**2025-05-07**|**Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond**|Jessie Richter-Powell et.al.|[2505.04621](https://arxiv.org/abs/2505.04621)|null|
|**2025-05-07**|**SwinLip: An Efficient Visual Speech Encoder for Lip Reading Using Swin Transformer**|Young-Hu Park et.al.|[2505.04394](https://arxiv.org/abs/2505.04394)|null|
|**2025-05-07**|**Discrete Optimal Transport and Voice Conversion**|Anton Selitskiy et.al.|[2505.04382](https://arxiv.org/abs/2505.04382)|null|
|**2025-05-07**|**Robust Speech Recognition with Schrödinger Bridge-Based Speech Enhancement**|Rauf Nasretdinov et.al.|[2505.04237](https://arxiv.org/abs/2505.04237)|null|
|**2025-05-06**|**VITA-Audio: Fast Interleaved Cross-Modal Token Generation for Efficient Large Speech-Language Model**|Zuwei Long et.al.|[2505.03739](https://arxiv.org/abs/2505.03739)|**[link](https://github.com/vita-mllm/vita-audio)**|
|**2025-05-06**|**Fairness of Automatic Speech Recognition in Cleft Lip and Palate Speech**|Susmita Bhattacharjee et.al.|[2505.03697](https://arxiv.org/abs/2505.03697)|null|
|**2025-05-06**|**Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation**|Jincheng Zhang et.al.|[2505.03314](https://arxiv.org/abs/2505.03314)|**[link](https://github.com/jinchengzhanggg/proffusion)**|
|**2025-05-06**|**SepALM: Audio Language Models Are Error Correctors for Robust Speech Separation**|Zhaoxi Mu et.al.|[2505.03273](https://arxiv.org/abs/2505.03273)|null|
|**2025-05-06**|**SonicRAG : High Fidelity Sound Effects Synthesis Based on Retrival Augmented Generation**|Yu-Ren Guo et.al.|[2505.03244](https://arxiv.org/abs/2505.03244)|null|
|**2025-05-06**|**MGFF-TDNN: A Multi-Granularity Feature Fusion TDNN Model with Depth-Wise Separable Module for Speaker Verification**|Ya Li et.al.|[2505.03228](https://arxiv.org/abs/2505.03228)|**[link](https://github.com/leia404/MGFF-TDNN)**|
|**2025-05-06**|**CoGenAV: Versatile Audio-Visual Representation Learning via Contrastive-Generative Synchronization**|Detao Bai et.al.|[2505.03186](https://arxiv.org/abs/2505.03186)|null|
|**2025-05-05**|**Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play**|Yemin Shi et.al.|[2505.02707](https://arxiv.org/abs/2505.02707)|**[link](https://github.com/maitrix-org/voila)**|
|**2025-05-05**|**LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis**|Qingkai Fang et.al.|[2505.02625](https://arxiv.org/abs/2505.02625)|**[link](https://github.com/ictnlp/llama-omni2)**|
|**2025-05-04**|**Transforming faces into video stories -- VideoFace2.0**|Branko Brkljač et.al.|[2505.02060](https://arxiv.org/abs/2505.02060)|null|
|**2025-05-04**|**A Synergistic Framework of Nonlinear Acoustic Computing and Reinforcement Learning for Real-World Human-Robot Interaction**|Xiaoliang Chen et.al.|[2505.01998](https://arxiv.org/abs/2505.01998)|null|
|**2025-05-02**|**Transfer Learning-Based Deep Residual Learning for Speech Recognition in Clean and Noisy Environments**|Noussaiba Djeffal et.al.|[2505.01632](https://arxiv.org/abs/2505.01632)|null|
|**2025-05-01**|**Scaling On-Device GPU Inference for Large Generative Models**|Jiuqiang Tang et.al.|[2505.00232](https://arxiv.org/abs/2505.00232)|null|
|**2025-04-30**|**BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition**|Paige Tuttösí et.al.|[2505.00059](https://arxiv.org/abs/2505.00059)|**[link](https://github.com/myHaiven/data-collection)**|
|**2025-04-30**|**From Aesthetics to Human Preferences: Comparative Perspectives of Evaluating Text-to-Music Systems**|Huan Zhang et.al.|[2504.21815](https://arxiv.org/abs/2504.21815)|null|
|**2025-04-30**|**Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction**|Máté Gedeon et.al.|[2504.21372](https://arxiv.org/abs/2504.21372)|null|
|**2025-04-29**|**AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation**|Jeongsoo Choi et.al.|[2504.20629](https://arxiv.org/abs/2504.20629)|null|
|**2025-05-02**|**Towards Flow-Matching-based TTS without Classifier-Free Guidance**|Yuzhe Liang et.al.|[2504.20334](https://arxiv.org/abs/2504.20334)|null|
|**2025-04-28**|**A Comprehensive Part-of-Speech Tagging to Standardize Central-Kurdish Language: A Research Guide for Kurdish Natural Language Processing Tasks**|Shadan Shukr Sabr et.al.|[2504.19645](https://arxiv.org/abs/2504.19645)|null|
|**2025-04-27**|**Generative Adversarial Network based Voice Conversion: Techniques, Challenges, and Recent Advancements**|Sandipan Dhar et.al.|[2504.19197](https://arxiv.org/abs/2504.19197)|null|
|**2025-04-25**|**Kimi-Audio Technical Report**|KimiTeam et.al.|[2504.18425](https://arxiv.org/abs/2504.18425)|**[link](https://github.com/MoonshotAI/Kimi-Audio.)**|
|**2025-04-28**|**Augmenting Captions with Emotional Cues: An AR Interface for Real-Time Accessible Communication**|Sunday David Ubur et.al.|[2504.17171](https://arxiv.org/abs/2504.17171)|null|
|**2025-04-23**|**SMART: Tuning a symbolic music generation system with an audio domain aesthetic reward**|Nicolas Jonason et.al.|[2504.16839](https://arxiv.org/abs/2504.16839)|null|
|**2025-04-22**|**TinyML for Speech Recognition**|Andrew Barovic et.al.|[2504.16213](https://arxiv.org/abs/2504.16213)|null|
|**2025-04-22**|**LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale**|Joya Chen et.al.|[2504.16030](https://arxiv.org/abs/2504.16030)|**[link](https://github.com/showlab/livecc)**|
|**2025-04-22**|**Quantifying Source Speaker Leakage in One-to-One Voice Conversion**|Scott Wellington et.al.|[2504.15822](https://arxiv.org/abs/2504.15822)|null|
|**2025-04-22**|**Development and evaluation of a deep learning algorithm for German word recognition from lip movements**|Dinh Nam Pham et.al.|[2504.15792](https://arxiv.org/abs/2504.15792)|null|
|**2025-04-22**|**FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning**|Ju Yeon Kang et.al.|[2504.15663](https://arxiv.org/abs/2504.15663)|null|
|**2025-04-22**|**A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models**|Gengxian Cao et.al.|[2504.15552](https://arxiv.org/abs/2504.15552)|null|
|**2025-04-21**|**Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides**|Jinghua Zhao et.al.|[2504.15066](https://arxiv.org/abs/2504.15066)|null|
|**2025-04-21**|**SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation**|Yue Li et.al.|[2504.15035](https://arxiv.org/abs/2504.15035)|null|
|**2025-04-21**|**Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues**|Rui Ribeiro et.al.|[2504.14963](https://arxiv.org/abs/2504.14963)|null|
|**2025-04-21**|**StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models**|Yeona Hong et.al.|[2504.14915](https://arxiv.org/abs/2504.14915)|null|
|**2025-04-20**|**DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue**|Xiang Li et.al.|[2504.14482](https://arxiv.org/abs/2504.14482)|**[link](https://github.com/uirlx/dialogueagents)**|
|**2025-04-19**|**The First VoicePrivacy Attacker Challenge**|Natalia Tomashenko et.al.|[2504.14183](https://arxiv.org/abs/2504.14183)|null|
|**2025-04-18**|**Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion**|Sandipan Dhar et.al.|[2504.13791](https://arxiv.org/abs/2504.13791)|null|
|**2025-04-18**|**MusFlow: Multimodal Music Generation via Conditional Flow Matching**|Jiahao Song et.al.|[2504.13535](https://arxiv.org/abs/2504.13535)|null|
|**2025-04-17**|**Acoustic to Articulatory Inversion of Speech; Data Driven Approaches, Challenges, Applications, and Future Scope**|Leena G Pillai et.al.|[2504.13308](https://arxiv.org/abs/2504.13308)|null|
|**2025-04-16**|**Dysarthria Normalization via Local Lie Group Transformations for Robust ASR**|Mikhail Osipov et.al.|[2504.12279](https://arxiv.org/abs/2504.12279)|null|
|**2025-04-16**|**Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning**|Mahmoud Salhab et.al.|[2504.12254](https://arxiv.org/abs/2504.12254)|null|
|**2025-04-16**|**Voice Conversion with Diverse Intonation using Conditional Variational Auto-Encoder**|Soobin Suh et.al.|[2504.12005](https://arxiv.org/abs/2504.12005)|null|
|**2025-04-15**|**Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Human-like Audiobook Generation**|Yan Rong et.al.|[2504.11002](https://arxiv.org/abs/2504.11002)|null|
|**2025-04-15**|**Real-Time Word-Level Temporal Segmentation in Streaming Speech Recognition**|Naoto Nishida et.al.|[2504.10849](https://arxiv.org/abs/2504.10849)|null|
|**2025-04-15**|**Generalized Audio Deepfake Detection Using Frame-level Latent Information Entropy**|Botao Zhao et.al.|[2504.10819](https://arxiv.org/abs/2504.10819)|null|
|**2025-04-14**|**Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis**|Yifan Yang et.al.|[2504.10352](https://arxiv.org/abs/2504.10352)|null|
|**2025-04-14**|**AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis**|Dan Luo et.al.|[2504.10309](https://arxiv.org/abs/2504.10309)|null|
|**2025-04-14**|**SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis**|Zhisheng Zhang et.al.|[2504.09839](https://arxiv.org/abs/2504.09839)|**[link](https://github.com/wxzyd123/safespeech)**|
|**2025-04-12**|**AMNet: An Acoustic Model Network for Enhanced Mandarin Speech Synthesis**|Yubing Cao et.al.|[2504.09225](https://arxiv.org/abs/2504.09225)|null|
|**2025-04-11**|**Spatial Audio Processing with Large Language Model on Wearable Devices**|Ayushi Mishra et.al.|[2504.08907](https://arxiv.org/abs/2504.08907)|null|
|**2025-04-11**|**Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion**|Na Li et.al.|[2504.08524](https://arxiv.org/abs/2504.08524)|null|
|**2025-04-10**|**From Speech to Summary: A Comprehensive Survey of Speech Summarization**|Fabian Retkowski et.al.|[2504.08024](https://arxiv.org/abs/2504.08024)|null|
|**2025-04-10**|**Empowering Global Voices: A Data-Efficient, Phoneme-Tone Adaptive Approach to High-Fidelity Speech Synthesis**|Yizhong Geng et.al.|[2504.07858](https://arxiv.org/abs/2504.07858)|null|
|**2025-04-10**|**SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified Flow**|Kaidi Wang et.al.|[2504.07776](https://arxiv.org/abs/2504.07776)|null|
|**2025-04-10**|**Extending Visual Dynamics for Video-to-Music Generation**|Xiaohao Liu et.al.|[2504.07594](https://arxiv.org/abs/2504.07594)|null|
|**2025-04-09**|**Visual-Aware Speech Recognition for Noisy Scenarios**|Lakshmipathi Balaji et.al.|[2504.07229](https://arxiv.org/abs/2504.07229)|null|
|**2025-04-09**|**RNN-Transducer-based Losses for Speech Recognition on Noisy Targets**|Vladimir Bataev et.al.|[2504.06963](https://arxiv.org/abs/2504.06963)|null|
|**2025-04-08**|**AVENet: Disentangling Features by Approximating Average Features for Voice Conversion**|Wenyu Wang et.al.|[2504.05833](https://arxiv.org/abs/2504.05833)|null|
|**2025-04-08**|**kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive Synthesis and Concatenation Smoothness Optimization**|Keren Shao et.al.|[2504.05686](https://arxiv.org/abs/2504.05686)|null|
|**2025-04-07**|**Of All StrIPEs: Investigating Structure-informed Positional Encoding for Efficient Music Generation**|Manvi Agarwal et.al.|[2504.05364](https://arxiv.org/abs/2504.05364)|null|
|**2025-04-07**|**DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation**|Xinglin Lyu et.al.|[2504.05122](https://arxiv.org/abs/2504.05122)|null|
|**2025-04-06**|**Trainable Adaptive Score Normalization for Automatic Speaker Verification**|Jeong-Hwan Choi et.al.|[2504.04512](https://arxiv.org/abs/2504.04512)|null|
|**2025-04-06**|**Public speech recognition transcripts as a configuring parameter**|Damien Rudaz et.al.|[2504.04488](https://arxiv.org/abs/2504.04488)|null|
|**2025-04-06**|**Activation Patching for Interpretable Steering in Music Generation**|Simone Facchiano et.al.|[2504.04479](https://arxiv.org/abs/2504.04479)|null|
|**2025-04-08**|**LoopGen: Training-Free Loopable Music Generation**|Davide Marincione et.al.|[2504.04466](https://arxiv.org/abs/2504.04466)|null|
|**2025-04-06**|**Selective Masking Adversarial Attack on Automatic Speech Recognition Systems**|Zheng Fang et.al.|[2504.04394](https://arxiv.org/abs/2504.04394)|null|
|**2025-04-04**|**An Efficient GPU-based Implementation for Noise Robust Sound Source Localization**|Zirui Lin et.al.|[2504.03373](https://arxiv.org/abs/2504.03373)|null|
|**2025-04-04**|**A Human Digital Twin Architecture for Knowledge-based Interactions and Context-Aware Conversations**|Abdul Mannan Mohammed et.al.|[2504.03147](https://arxiv.org/abs/2504.03147)|null|
|**2025-04-03**|**LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech Recognition in Tunisian Arabic Dialect**|Hedi Naouara et.al.|[2504.02604](https://arxiv.org/abs/2504.02604)|null|
|**2025-04-03**|**Deep learning for music generation. Four approaches and their comparative evaluation**|Razvan Paroiu et.al.|[2504.02586](https://arxiv.org/abs/2504.02586)|null|
|**2025-04-03**|**F5R-TTS: Improving Flow Matching based Text-to-Speech with Group Relative Policy Optimization**|Xiaohui Sun et.al.|[2504.02407](https://arxiv.org/abs/2504.02407)|null|
|**2025-04-03**|**VoiceCraft-Dub: Automated Video Dubbing with Neural Codec Language Models**|Kim Sung-Bin et.al.|[2504.02386](https://arxiv.org/abs/2504.02386)|null|
|**2025-04-02**|**Chain of Correction for Full-text Speech Recognition with Large Language Models**|Zhiyuan Tang et.al.|[2504.01519](https://arxiv.org/abs/2504.01519)|null|
|**2025-04-01**|**Whispering Under the Eaves: Protecting User Privacy Against Commercial and LLM-powered Automatic Speech Recognition Systems**|Weifei Jin et.al.|[2504.00858](https://arxiv.org/abs/2504.00858)|**[link](https://github.com/WeifeiJin/AudioShield)**|
|**2025-04-01**|**A Survey on Music Generation from Single-Modal, Cross-Modal, and Multi-Modal Perspectives: Data, Methods, and Challenges**|Shuyu Li et.al.|[2504.00837](https://arxiv.org/abs/2504.00837)|null|
|**2025-03-31**|**Can Diffusion Models Disentangle? A Theoretical Perspective**|Liming Wang et.al.|[2504.00220](https://arxiv.org/abs/2504.00220)|null|
|**2025-03-31**|**SVLA: A Unified Speech-Vision-Language Assistant with Multimodal Reasoning and Speech Generation**|Ngoc Dung Huynh et.al.|[2503.24164](https://arxiv.org/abs/2503.24164)|null|
|**2025-04-02**|**TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection**|Zhiming Ma et.al.|[2503.24115](https://arxiv.org/abs/2503.24115)|**[link](https://github.com/jimmyma99/teleantifraud)**|
|**2025-03-31**|**SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to Accelerate Your Speech-LLM Development**|Minghan Wang et.al.|[2503.23848](https://arxiv.org/abs/2503.23848)|**[link](https://github.com/yuriak/SpeechDialogueFactory)**|
|**2025-03-30**|**The Impact of Code-switched Synthetic Data Quality is Task Dependent: Insights from MT and ASR**|Injy Hamed et.al.|[2503.23576](https://arxiv.org/abs/2503.23576)|null|
|**2025-03-30**|**Whisper-LM: Improving ASR Models with Language Models for Low-Resource Languages**|Xabier de Zuazo et.al.|[2503.23542](https://arxiv.org/abs/2503.23542)|**[link](https://github.com/hitz-zentroa/whisper-lm)**|
|**2025-03-30**|**Scaling Auditory Cognition via Test-Time Compute in Audio Language Models**|Ting Dang et.al.|[2503.23395](https://arxiv.org/abs/2503.23395)|null|
|**2025-03-29**|**SupertonicTTS: Towards Highly Scalable and Efficient Text-to-Speech System**|Hyeongju Kim et.al.|[2503.23108](https://arxiv.org/abs/2503.23108)|null|
|**2025-03-28**|**Enhancing Dance-to-Music Generation via Negative Conditioning Latent Diffusion Model**|Changchang Sun et.al.|[2503.22138](https://arxiv.org/abs/2503.22138)|null|
|**2025-03-27**|**VALLR: Visual ASR Language Model for Lip Reading**|Marshall Thomas et.al.|[2503.21408](https://arxiv.org/abs/2503.21408)|null|
|**2025-03-27**|**A 71.2- $μ$ W Speech Recognition Accelerator with Recurrent Spiking Neural Network**|Chih-Chyau Yang et.al.|[2503.21337](https://arxiv.org/abs/2503.21337)|null|
|**2025-03-27**|**Vision-to-Music Generation: A Survey**|Zhaokai Wang et.al.|[2503.21254](https://arxiv.org/abs/2503.21254)|**[link](https://github.com/wzk1015/awesome-vision-to-music-generation)**|
|**2025-03-26**|**Improving Speech Recognition Accuracy Using Custom Language Models with the Vosk Toolkit**|Aniket Abhishek Soni et.al.|[2503.21025](https://arxiv.org/abs/2503.21025)|null|
|**2025-03-26**|**Text-Driven Voice Conversion via Latent State-Space Modeling**|Wen Li et.al.|[2503.20999](https://arxiv.org/abs/2503.20999)|null|
|**2025-03-26**|**FinAudio: A Benchmark for Audio Large Language Models in Financial Applications**|Yupeng Cao et.al.|[2503.20990](https://arxiv.org/abs/2503.20990)|null|
|**2025-03-26**|**Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages**|Yangyang Meng et.al.|[2503.20212](https://arxiv.org/abs/2503.20212)|**[link](https://github.com/dataoceanai/dolphin)**|
|**2025-03-25**|**Contextual Metric Meta-Evaluation by Measuring Local Metric Accuracy**|Athiya Deviyani et.al.|[2503.19828](https://arxiv.org/abs/2503.19828)|null|
|**2025-03-25**|**Analyzable Chain-of-Musical-Thought Prompting for High-Fidelity Music Generation**|Max W. Y. Lam et.al.|[2503.19611](https://arxiv.org/abs/2503.19611)|null|
|**2025-03-25**|**Boosting the Transferability of Audio Adversarial Examples with Acoustic Representation Optimization**|Weifei Jin et.al.|[2503.19591](https://arxiv.org/abs/2503.19591)|null|
|**2025-03-25**|**Design of Seamless Multi-modal Interaction Framework for Intelligent Virtual Agents in Wearable Mixed Reality Environment**|Ghazanfar Ali et.al.|[2503.19334](https://arxiv.org/abs/2503.19334)|null|
|**2025-03-22**|**A Survey on Structured State Space Sequence (S4) Models**|Shriyank Somvanshi et.al.|[2503.18970](https://arxiv.org/abs/2503.18970)|**[link](https://github.com/gauravfs-14/awesome-mamba)**|
|**2025-03-24**|**Towards Responsible AI Music: an Investigation of Trustworthy Features for Creative Systems**|Jacopo de Berardinis et.al.|[2503.18814](https://arxiv.org/abs/2503.18814)|null|
|**2025-03-24**|**Whispering in Amharic: Fine-tuning Whisper for Low-resource Language**|Dawit Ketema Gete et.al.|[2503.18485](https://arxiv.org/abs/2503.18485)|null|
|**2025-03-23**|**Elevating Robust Multi-Talker ASR by Decoupling Speaker Separation and Speech Recognition**|Yufeng Yang et.al.|[2503.17886](https://arxiv.org/abs/2503.17886)|null|
|**2025-03-22**|**LZMidi: Compression-Based Symbolic Music Generation**|Connor Ding et.al.|[2503.17654](https://arxiv.org/abs/2503.17654)|null|
|**2025-03-21**|**Your voice is your voice: Supporting Self-expression through Speech Generation and LLMs in Augmented and Alternative Communication**|Yiwen Xu et.al.|[2503.17479](https://arxiv.org/abs/2503.17479)|null|
|**2025-03-21**|**From Faces to Voices: Learning Hierarchical Representations for High-quality Video-to-Speech**|Ji-Hoon Kim et.al.|[2503.16956](https://arxiv.org/abs/2503.16956)|null|
|**2025-03-20**|**CAARMA: Class Augmentation with Adversarial Mixup Regularization**|Massa Baali et.al.|[2503.16718](https://arxiv.org/abs/2503.16718)|null|
|**2025-03-20**|**WaveFM: A High-Fidelity and Efficient Vocoder Based on Flow Matching**|Tianze Luo et.al.|[2503.16689](https://arxiv.org/abs/2503.16689)|null|
|**2025-03-20**|**SeniorTalk: A Chinese Conversation Dataset with Rich Annotations for Super-Aged Seniors**|Yang Chen et.al.|[2503.16578](https://arxiv.org/abs/2503.16578)|null|
|**2025-03-19**|**A Comprehensive Survey on Architectural Advances in Deep CNNs: Challenges, Applications, and Emerging Research Directions**|Saddam Hussain Khan et.al.|[2503.16546](https://arxiv.org/abs/2503.16546)|null|
|**2025-03-19**|**Evaluating ASR Confidence Scores for Automated Error Detection in User-Assisted Correction Interfaces**|Korbinian Kuhn et.al.|[2503.15124](https://arxiv.org/abs/2503.15124)|null|
|**2025-03-19**|**Communication Access Real-Time Translation Through Collaborative Correction of Automatic Speech Recognition**|Korbinian Kuhn et.al.|[2503.15120](https://arxiv.org/abs/2503.15120)|null|
|**2025-03-19**|**MoonCast: High-Quality Zero-Shot Podcast Generation**|Zeqian Ju et.al.|[2503.14345](https://arxiv.org/abs/2503.14345)|**[link](https://github.com/jzq2000/mooncast)**|
|**2025-03-18**|**InnerSelf: Designing Self-Deepfaked Voice for Emotional Well-being**|Guang Dai et.al.|[2503.14257](https://arxiv.org/abs/2503.14257)|null|
|**2025-03-17**|**Halving transcription time: A fast, user-friendly and GDPR-compliant workflow to create AI-assisted transcripts for content analysis**|Jakob Sponholz et.al.|[2503.13031](https://arxiv.org/abs/2503.13031)|null|
|**2025-03-14**|**MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens**|Jeong Hun Yeo et.al.|[2503.11315](https://arxiv.org/abs/2503.11315)|**[link](https://github.com/JeongHun0716/MMS-LLaMA)**|
|**2025-03-13**|**AudioX: Diffusion Transformer for Anything-to-Audio Generation**|Zeyue Tian et.al.|[2503.10522](https://arxiv.org/abs/2503.10522)|**[link](https://github.com/ZeyueT/AudioX)**|
|**2025-03-13**|**Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings**|Jakaria Islam Emon et.al.|[2503.10446](https://arxiv.org/abs/2503.10446)|**[link](https://github.com/jakariaemon/WSI)**|
|**2025-03-14**|**Proceedings of the ISCA/ITG Workshop on Diversity in Large Speech and Language Models**|Sebastian Möller et.al.|[2503.10298](https://arxiv.org/abs/2503.10298)|null|
|**2025-03-12**|**ValSub: Subsampling Validation Data to Mitigate Forgetting during ASR Personalization**|Haaris Mehmood et.al.|[2503.09906](https://arxiv.org/abs/2503.09906)|null|
|**2025-03-12**|**Quantization for OpenAI's Whisper Models: A Comparative Analysis**|Allison Andreyev et.al.|[2503.09905](https://arxiv.org/abs/2503.09905)|**[link](https://github.com/allisonandreyev/WhisperQuantization)**|
|**2025-03-12**|**Everything Can Be Described in Words: A Simple Unified Multi-Modal Framework with Semantic and Temporal Alignment**|Xiaowei Bi et.al.|[2503.09081](https://arxiv.org/abs/2503.09081)|null|
|**2025-03-11**|**An Exhaustive Evaluation of TTS- and VC-based Data Augmentation for ASR**|Sewade Ogun et.al.|[2503.08954](https://arxiv.org/abs/2503.08954)|null|
|**2025-03-11**|**YuE: Scaling Open Foundation Models for Long-Form Music Generation**|Ruibin Yuan et.al.|[2503.08638](https://arxiv.org/abs/2503.08638)|**[link](https://github.com/multimodal-art-projection/yue)**|
|**2025-03-11**|**Prompt2LVideos: Exploring Prompts for Understanding Long-Form Multimodal Videos**|Soumya Shamarao Jahagirdar et.al.|[2503.08335](https://arxiv.org/abs/2503.08335)|null|
|**2025-03-11**|**FilmComposer: LLM-Driven Music Production for Silent Film Clips**|Zhifeng Xie et.al.|[2503.08147](https://arxiv.org/abs/2503.08147)|**[link](https://github.com/Apple-jun/FilmComposer)**|
|**2025-03-11**|**Boundary Regression for Leitmotif Detection in Music Audio**|Sihun Lee et.al.|[2503.07977](https://arxiv.org/abs/2503.07977)|null|
|**2025-03-10**|**Building English ASR model with regional language support**|Purvi Agrawal et.al.|[2503.07522](https://arxiv.org/abs/2503.07522)|null|
|**2025-03-10**|**Impact of Microphone Array Mismatches to Learning-based Replay Speech Detection**|Michael Neri et.al.|[2503.07357](https://arxiv.org/abs/2503.07357)|null|
|**2025-03-10**|**Automatic Speech Recognition for Non-Native English: Accuracy and Disfluency Handling**|Michael McGuire et.al.|[2503.06924](https://arxiv.org/abs/2503.06924)|null|
|**2025-03-09**|**Adaptive Audio-Visual Speech Recognition via Matryoshka-Based Multimodal LLMs**|Umberto Cappellazzo et.al.|[2503.06362](https://arxiv.org/abs/2503.06362)|null|
|**2025-03-08**|**Zero-AVSR: Zero-Shot Audio-Visual Speech Recognition with LLMs by Learning Language-Agnostic Speech Representations**|Jeong Hun Yeo et.al.|[2503.06273](https://arxiv.org/abs/2503.06273)|**[link](https://github.com/JeongHun0716/zero-avsr)**|
|**2025-03-08**|**A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A Field Experiment**|Koji Inoue et.al.|[2503.06241](https://arxiv.org/abs/2503.06241)|null|
|**2025-03-07**|**DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility**|Yifan Liu et.al.|[2503.05223](https://arxiv.org/abs/2503.05223)|null|
|**2025-03-06**|**From Voice to Safety: Language AI Powered Pilot-ATC Communication Understanding for Airport Surface Movement Collision Risk Assessment**|Yutian Pang et.al.|[2503.04974](https://arxiv.org/abs/2503.04974)|null|
|**2025-03-04**|**Normalization through Fine-tuning: Understanding Wav2vec 2.0 Embeddings for Phonetic Analysis**|Yiming Wang et.al.|[2503.04814](https://arxiv.org/abs/2503.04814)|null|
|**2025-03-06**|**LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM**|Sambal Shikhar et.al.|[2503.04724](https://arxiv.org/abs/2503.04724)|**[link](https://github.com/mbzuai-oryx/LLMVoX)**|
|**2025-03-06**|**Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning**|Lucas Block Medin et.al.|[2503.04710](https://arxiv.org/abs/2503.04710)|null|
|**2025-03-05**|**Good practices for evaluation of synthesized speech**|Erica Cooper et.al.|[2503.03250](https://arxiv.org/abs/2503.03250)|null|
|**2025-03-03**|**Fine-Tuning Whisper for Inclusive Prosodic Stress Analysis**|Samuel S. Sohn et.al.|[2503.02907](https://arxiv.org/abs/2503.02907)|null|
|**2025-03-04**|**Go Beyond Your Means: Unlearning with Per-Sample Gradient Orthogonalization**|Aviv Shamsian et.al.|[2503.02312](https://arxiv.org/abs/2503.02312)|null|
|**2025-03-05**|**Pruning Deep Neural Networks via a Combination of the Marchenko-Pastur Distribution and Regularization**|Leonid Berlyand et.al.|[2503.01922](https://arxiv.org/abs/2503.01922)|null|
|**2025-03-03**|**Augmenting Online Meetings with Context-Aware Real-time Music Generation**|Haruki Suzawa et.al.|[2503.01354](https://arxiv.org/abs/2503.01354)|null|
|**2025-03-03**|**Voice Cloning for Dysarthric Speech Synthesis: Addressing Data Scarcity in Speech-Language Pathology**|Birger Moell et.al.|[2503.01266](https://arxiv.org/abs/2503.01266)|null|
|**2025-03-03**|**DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion**|Ziqian Ning et.al.|[2503.01183](https://arxiv.org/abs/2503.01183)|**[link](https://github.com/ASLP-lab/DiffRhythm)**|
|**2025-03-02**|**Unveiling Biases while Embracing Sustainability: Assessing the Dual Challenges of Automatic Speech Recognition Systems**|Ajinkya Kulkarni et.al.|[2503.00907](https://arxiv.org/abs/2503.00907)|null|
|**2025-03-02**|**UniWav: Towards Unified Pre-training for Speech Representation Learning and Generation**|Alexander H. Liu et.al.|[2503.00733](https://arxiv.org/abs/2503.00733)|null|
|**2025-03-01**|**PodAgent: A Comprehensive Framework for Podcast Generation**|Yujia Xiao et.al.|[2503.00455](https://arxiv.org/abs/2503.00455)|**[link](https://github.com/yujxx/PodAgent)**|
|**2025-02-28**|**InspireMusic: Integrating Super Resolution and Large Language Model for High-Fidelity Long-Form Music Generation**|Chong Zhang et.al.|[2503.00084](https://arxiv.org/abs/2503.00084)|**[link](https://github.com/FunAudioLLM/InspireMusic.)**|
|**2025-02-27**|**LiteASR: Efficient Automatic Speech Recognition with Low-Rank Approximation**|Keisuke Kamahori et.al.|[2502.20583](https://arxiv.org/abs/2502.20583)|**[link](https://github.com/efeslab/liteasr)**|
|**2025-02-27**|**Adapting Automatic Speech Recognition for Accented Air Traffic Control Communications**|Marcus Yu Zhe Wee et.al.|[2502.20311](https://arxiv.org/abs/2502.20311)|null|
|**2025-02-27**|**CleanMel: Mel-Spectrogram Enhancement for Improving Both Speech Quality and ASR**|Nian Shao et.al.|[2502.20040](https://arxiv.org/abs/2502.20040)|**[link](https://github.com/Audio-WestlakeU/CleanMel)**|
|**2025-02-27**|**DiffCSS: Diverse and Expressive Conversational Speech Synthesis with Diffusion Models**|Weihao wu et.al.|[2502.19924](https://arxiv.org/abs/2502.19924)|null|
|**2025-02-26**|**Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis**|Ziyue Jiang et.al.|[2502.18924](https://arxiv.org/abs/2502.18924)|null|
|**2025-02-26**|**CS-Dialogue: A 104-Hour Dataset of Spontaneous Mandarin-English Code-Switching Dialogues for Speech Recognition**|Jiaming Zhou et.al.|[2502.18913](https://arxiv.org/abs/2502.18913)|null|
|**2025-02-25**|**Exploring Gender Disparities in Automatic Speech Recognition Technology**|Hend ElGhazaly et.al.|[2502.18434](https://arxiv.org/abs/2502.18434)|null|
|**2025-02-27**|**NotaGen: Advancing Musicality in Symbolic Music Generation with Large Language Model Training Paradigms**|Yashan Wang et.al.|[2502.18008](https://arxiv.org/abs/2502.18008)|null|
|**2025-02-25**|**Silent Speech Sentence Recognition with Six-Axis Accelerometers using Conformer and CTC Algorithm**|Yudong Xie et.al.|[2502.17829](https://arxiv.org/abs/2502.17829)|null|
|**2025-02-26**|**Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation**|Qiuming Zhao et.al.|[2502.17380](https://arxiv.org/abs/2502.17380)|null|
|**2025-02-24**|**Improving the Inclusivity of Dutch Speech Recognition by Fine-tuning Whisper on the JASMIN-CGN Corpus**|Golshid Shekoufandeh et.al.|[2502.17284](https://arxiv.org/abs/2502.17284)|null|
|**2025-02-24**|**Balancing Speech Understanding and Generation Using Continual Pre-training for Codec-based Speech LLM**|Jiatong Shi et.al.|[2502.16897](https://arxiv.org/abs/2502.16897)|null|
|**2025-02-22**|**Understanding Zero-shot Rare Word Recognition Improvements Through LLM Integration**|Haoxuan Wang et.al.|[2502.16142](https://arxiv.org/abs/2502.16142)|null|
|**2025-02-21**|**The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages**|Jenalea Rajab et.al.|[2502.15916](https://arxiv.org/abs/2502.15916)|null|
|**2025-02-21**|**Retrieval-Augmented Speech Recognition Approach for Domain Challenges**|Peng Shen et.al.|[2502.15264](https://arxiv.org/abs/2502.15264)|null|
|**2025-02-21**|**Enhancing Speech Large Language Models with Prompt-Aware Mixture of Audio Encoders**|Weiqiao Shan et.al.|[2502.15178](https://arxiv.org/abs/2502.15178)|null|
|**2025-02-21**|**Improving Streaming Speech Recognition With Time-Shifted Contextual Attention And Dynamic Right Context Masking**|Khanh Le et.al.|[2502.15158](https://arxiv.org/abs/2502.15158)|null|
|**2025-02-20**|**WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models**|Yifu Chen et.al.|[2502.14727](https://arxiv.org/abs/2502.14727)|null|
|**2025-02-20**|**SegAug: CTC-Aligned Segmented Augmentation For Robust RNN-Transducer Based Speech Recognition**|Khanh Le et.al.|[2502.14685](https://arxiv.org/abs/2502.14685)|null|
|**2025-02-20**|**Moshi Moshi? A Model Selection Hijacking Adversarial Attack**|Riccardo Petrucci et.al.|[2502.14586](https://arxiv.org/abs/2502.14586)|null|
|**2025-02-19**|**On the application of Visibility Graphs in the Spectral Domain for Speaker Recognition**|Hernan Bocaccio et.al.|[2502.14110](https://arxiv.org/abs/2502.14110)|null|
|**2025-02-18**|**Gesture-Aware Zero-Shot Speech Recognition for Patients with Language Disorders**|Seungbae Kim et.al.|[2502.13983](https://arxiv.org/abs/2502.13983)|null|
|**2025-02-19**|**Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks**|Ori Shapira et.al.|[2502.13645](https://arxiv.org/abs/2502.13645)|**[link](https://github.com/OriShapira/ENDow)**|
|**2025-02-21**|**VLAS: Vision-Language-Action Model With Speech Instructions For Customized Robot Manipulation**|Wei Zhao et.al.|[2502.13508](https://arxiv.org/abs/2502.13508)|**[link](https://github.com/whichwhichgone/VLAS)**|
|**2025-02-19**|**Adopting Whisper for Confidence Estimation**|Vaibhav Aggarwal et.al.|[2502.13446](https://arxiv.org/abs/2502.13446)|null|
|**2025-02-18**|**AV-Flow: Transforming Text to Audio-Visual Human-like Interactions**|Aggelina Chatziagapi et.al.|[2502.13133](https://arxiv.org/abs/2502.13133)|null|
|**2025-02-18**|**Neuro-oscillatory models of cortical speech processing**|Olesia Dogonasheva et.al.|[2502.12935](https://arxiv.org/abs/2502.12935)|null|
|**2025-02-18**|**High-Fidelity Music Vocoder using Neural Audio Codecs**|Luca A. Lanzendörfer et.al.|[2502.12759](https://arxiv.org/abs/2502.12759)|null|
|**2025-02-18**|**Playing with Voices: Tabletop Role-Playing Game Recordings as a Diarization Challenge**|Lian Remme et.al.|[2502.12714](https://arxiv.org/abs/2502.12714)|null|
|**2025-02-18**|**A Comprehensive Survey on Generative AI for Video-to-Music Generation**|Shulei Ji et.al.|[2502.12489](https://arxiv.org/abs/2502.12489)|null|
|**2025-02-18**|**Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models**|Hanin Atwany et.al.|[2502.12414](https://arxiv.org/abs/2502.12414)|null|
|**2025-02-18**|**On the Robust Approximation of ASR Metrics**|Abdul Waheed et.al.|[2502.12408](https://arxiv.org/abs/2502.12408)|null|
|**2025-02-17**|**A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond**|Shreya Shukla et.al.|[2502.12048](https://arxiv.org/abs/2502.12048)|null|
|**2025-02-17**|**NaturalL2S: End-to-End High-quality Multispeaker Lip-to-Speech Synthesis with Differential Digital Signal Processing**|Yifan Liang et.al.|[2502.12002](https://arxiv.org/abs/2502.12002)|null|
|**2025-02-17**|**Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration**|Yan Zhang et.al.|[2502.11720](https://arxiv.org/abs/2502.11720)|null|
|**2025-02-17**|**Training-Free Guidance Beyond Differentiability: Scalable Path Steering with Tree Search in Diffusion and Flow Models**|Yingqing Guo et.al.|[2502.11420](https://arxiv.org/abs/2502.11420)|null|
|**2025-02-16**|**FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching**|Hui Wang et.al.|[2502.11128](https://arxiv.org/abs/2502.11128)|null|
|**2025-02-16**|**In Situ Optimization of an Optoelectronic Reservoir Computer with Digital Delayed Feedback**|Fyodor Morozko et.al.|[2502.11126](https://arxiv.org/abs/2502.11126)|null|
|**2025-02-16**|**DuplexMamba: Enhancing Real-time Speech Conversations with Duplex and Streaming Capabilities**|Xiangyu Lu et.al.|[2502.11123](https://arxiv.org/abs/2502.11123)|null|
|**2025-02-14**|**Enhancing Age-Related Robustness in Children Speaker Verification**|Vishwas M. Shetty et.al.|[2502.10511](https://arxiv.org/abs/2502.10511)|null|
|**2025-02-14**|**OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models**|William Chen et.al.|[2502.10373](https://arxiv.org/abs/2502.10373)|null|
|**2025-02-14**|**VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking Effect**|Qingyuan Fei et.al.|[2502.10329](https://arxiv.org/abs/2502.10329)|null|
|**2025-02-14**|**Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries**|Serkan Sulun et.al.|[2502.10154](https://arxiv.org/abs/2502.10154)|null|
|**2025-02-14**|**MTLM: an Innovative Language Model Training Paradigm for ASR**|Qingliang Meng et.al.|[2502.10058](https://arxiv.org/abs/2502.10058)|null|
|**2025-02-14**|**A Preliminary Exploration with GPT-4o Voice Mode**|Yu-Xiang Lin et.al.|[2502.09940](https://arxiv.org/abs/2502.09940)|null|
|**2025-02-14**|**Microphone Array Geometry Independent Multi-Talker Distant ASR: NTT System for the DASR Task of the CHiME-8 Challenge**|Naoyuki Kamo et.al.|[2502.09859](https://arxiv.org/abs/2502.09859)|null|
|**2025-02-13**|**SyntheticPop: Attacking Speaker Verification Systems With Synthetic VoicePops**|Eshaq Jamdar et.al.|[2502.09553](https://arxiv.org/abs/2502.09553)|null|
|**2025-02-13**|**Shortcut Learning Susceptibility in Vision Classifiers**|Pirzada Suhail et.al.|[2502.09150](https://arxiv.org/abs/2502.09150)|null|
|**2025-02-13**|**Quantum Approaches for Dysphonia Assessment in Small Speech Datasets**|Ha Tran et.al.|[2502.08968](https://arxiv.org/abs/2502.08968)|null|
|**2025-02-13**|**TokenSynth: A Token-based Neural Synthesizer for Instrument Cloning and Text-to-Instrument**|Kyungsu Kim et.al.|[2502.08939](https://arxiv.org/abs/2502.08939)|**[link](https://github.com/kyungsukim42/tokensynth)**|
|**2025-02-13**|**ASVspoof 5: Design, Collection and Validation of Resources for Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech**|Xin Wang et.al.|[2502.08857](https://arxiv.org/abs/2502.08857)|null|
|**2025-02-12**|**Causal Analysis of ASR Errors for Children: Quantifying the Impact of Physiological, Cognitive, and Extrinsic Factors**|Vishwanath Pratap Singh et.al.|[2502.08587](https://arxiv.org/abs/2502.08587)|null|
|**2025-02-11**|**LoRP-TTS: Low-Rank Personalized Text-To-Speech**|Łukasz Bondaruk et.al.|[2502.07562](https://arxiv.org/abs/2502.07562)|null|
|**2025-02-12**|**Music for All: Exploring Multicultural Representations in Music Generation Models**|Atharva Mehta et.al.|[2502.07328](https://arxiv.org/abs/2502.07328)|**[link](https://github.com/atharva20038/music4all)**|
|**2025-02-11**|**Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement**|Xueyao Zhang et.al.|[2502.07243](https://arxiv.org/abs/2502.07243)|null|
|**2025-02-11**|**VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification**|Pengyu Wang et.al.|[2502.07205](https://arxiv.org/abs/2502.07205)|**[link](https://github.com/Audio-WestlakeU/VINP)**|
|**2025-02-10**|**A Comparative Study of ASR Implementations in Resource-Constrained Wireless Sensor Networks for Real-Time Voice Communication**|Qutaiba I. Ali et.al.|[2502.06969](https://arxiv.org/abs/2502.06969)|null|
|**2025-02-10**|**Automatic Identification of Samples in Hip-Hop Music via Multi-Loss Training and an Artificial Dataset**|Huw Cheston et.al.|[2502.06364](https://arxiv.org/abs/2502.06364)|null|
|**2025-02-09**|**Speech to Speech Translation with Translatotron: A State of the Art Review**|Jules R. Kala et.al.|[2502.05980](https://arxiv.org/abs/2502.05980)|null|
|**2025-02-09**|**Audio-Visual Representation Learning via Knowledge Distillation from Speech Foundation Models**|Jing-Xuan Zhang et.al.|[2502.05766](https://arxiv.org/abs/2502.05766)|null|
|**2025-02-09**|**Non-invasive electromyographic speech neuroprosthesis: a geometric perspective**|Harshavardhana T. Gowda et.al.|[2502.05762](https://arxiv.org/abs/2502.05762)|null|
|**2025-02-09**|**BnTTS: Few-Shot Speaker Adaptation in Low-Resource Setting**|Mohammad Jahid Ibna Basher et.al.|[2502.05729](https://arxiv.org/abs/2502.05729)|null|
|**2025-02-08**|**Gender Bias in Instruction-Guided Speech Synthesis Models**|Chun-Yi Kuan et.al.|[2502.05649](https://arxiv.org/abs/2502.05649)|null|
|**2025-02-08**|**Enhancing Expressive Voice Conversion with Discrete Pitch-Conditioned Flow Matching Model**|Jialong Zuo et.al.|[2502.05471](https://arxiv.org/abs/2502.05471)|null|
|**2025-02-07**|**Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance**|Reihaneh Amooie et.al.|[2502.04883](https://arxiv.org/abs/2502.04883)|null|
|**2025-02-07**|**Lightweight Operations for Visual Speech Recognition**|Iason Ioannis Panagos et.al.|[2502.04834](https://arxiv.org/abs/2502.04834)|null|
|**2025-02-07**|**Singing Voice Conversion with Accompaniment Using Self-Supervised Representation-Based Melody Features**|Wei Chen et.al.|[2502.04722](https://arxiv.org/abs/2502.04722)|null|
|**2025-02-06**|**ImprovNet: Generating Controllable Musical Improvisations with Iterative Corruption Refinement**|Keshav Bhandari et.al.|[2502.04522](https://arxiv.org/abs/2502.04522)|**[link](https://github.com/keshavbhandari/improvnet.)**|
|**2025-02-06**|**GenVC: Self-Supervised Zero-Shot Voice Conversion**|Zexin Cai et.al.|[2502.04519](https://arxiv.org/abs/2502.04519)|null|
|**2025-02-06**|**FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks**|Luca Della Libera et.al.|[2502.04465](https://arxiv.org/abs/2502.04465)|**[link](https://github.com/lucadellalib/focalcodec)**|
|**2025-02-06**|**Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis**|Zhen Ye et.al.|[2502.04128](https://arxiv.org/abs/2502.04128)|**[link](https://github.com/zhenye234/LLaSA_training)**|
|**2025-02-06**|**Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond**|Mardhiyah Sanni et.al.|[2502.03945](https://arxiv.org/abs/2502.03945)|null|
|**2025-02-06**|**Rule-Based Modeling of Low-Dimensional Data with PCA and Binary Particle Swarm Optimization (BPSO) in ANFIS**|Afnan Al-Ali et.al.|[2502.03895](https://arxiv.org/abs/2502.03895)|null|
|**2025-02-05**|**Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality**|Shiyi Tan et.al.|[2502.03381](https://arxiv.org/abs/2502.03381)|null|
|**2025-02-05**|**Leveraging Broadcast Media Subtitle Transcripts for Automatic Speech Recognition and Subtitling**|Jakob Poncelet et.al.|[2502.03212](https://arxiv.org/abs/2502.03212)|**[link](https://github.com/nelfproject/NeLF_Transcription_ASR)**|
|**2025-02-05**|**Metis: A Foundation Speech Generation Model with Masked Generative Pre-training**|Yuancheng Wang et.al.|[2502.03128](https://arxiv.org/abs/2502.03128)|null|
|**2025-02-04**|**Developing multilingual speech synthesis system for Ojibwe, Mi'kmaq, and Maliseet**|Shenran Wang et.al.|[2502.02703](https://arxiv.org/abs/2502.02703)|null|
|**2025-02-03**|**CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition**|Martijn Bartelds et.al.|[2502.01777](https://arxiv.org/abs/2502.01777)|null|
|**2025-02-03**|**Adapter-Based Multi-Agent AVSR Extension for Pre-Trained ASR Models**|Christopher Simic et.al.|[2502.01709](https://arxiv.org/abs/2502.01709)|null|
|**2025-02-03**|**A Differentiable Alignment Framework for Sequence-to-Sequence Modeling via Optimal Transport**|Yacouba Kaloga et.al.|[2502.01588](https://arxiv.org/abs/2502.01588)|null|
|**2025-02-03**|**mWhisper-Flamingo for Multilingual Audio-Visual Noise-Robust Speech Recognition**|Andrew Rouditchenko et.al.|[2502.01547](https://arxiv.org/abs/2502.01547)|**[link](https://github.com/roudimit/whisper-flamingo)**|
|**2025-02-03**|**Gradient Norm-based Fine-Tuning for Backdoor Defense in Automatic Speech Recognition**|Nanjun Zhou et.al.|[2502.01152](https://arxiv.org/abs/2502.01152)|null|
|**2025-02-03**|**Continuous Autoregressive Modeling with Stochastic Monotonic Alignment for Speech Synthesis**|Weiwei Lin et.al.|[2502.01084](https://arxiv.org/abs/2502.01084)|null|
|**2025-02-01**|**Data-Driven Mispronunciation Pattern Discovery for Robust Speech Recognition**|Anna Seo Gyeong Choi et.al.|[2502.00583](https://arxiv.org/abs/2502.00583)|null|
|**2025-02-01**|**Evaluation of End-to-End Continuous Spanish Lipreading in Different Data Conditions**|David Gimeno-Gómez et.al.|[2502.00464](https://arxiv.org/abs/2502.00464)|null|
|**2025-02-01**|**Sagalee: an Open Source Automatic Speech Recognition Dataset for Oromo Language**|Turi Abu et.al.|[2502.00421](https://arxiv.org/abs/2502.00421)|**[link](https://github.com/turinaf/sagalee)**|
|**2025-02-01**|**When End-to-End is Overkill: Rethinking Cascaded Speech-to-Text Translation**|Anna Min et.al.|[2502.00377](https://arxiv.org/abs/2502.00377)|null|
|**2025-02-03**|**SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions**|Dominik Wagner et.al.|[2501.19377](https://arxiv.org/abs/2501.19377)|null|
|**2025-01-31**|**Language Bias in Self-Supervised Learning For Automatic Speech Recognition**|Edward Storey et.al.|[2501.19321](https://arxiv.org/abs/2501.19321)|null|
|**2025-02-03**|**DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition**|Wonjun Lee et.al.|[2501.19010](https://arxiv.org/abs/2501.19010)|null|
|**2025-01-30**|**AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment**|Yuqin Cao et.al.|[2501.18314](https://arxiv.org/abs/2501.18314)|null|
|**2025-01-29**|**Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling**|Theo Lepage et.al.|[2501.17772](https://arxiv.org/abs/2501.17772)|null|
|**2025-01-29**|**Cross-lingual Embedding Clustering for Hierarchical Softmax in Low-Resource Multilingual Speech Recognition**|Zhengdong Yang et.al.|[2501.17615](https://arxiv.org/abs/2501.17615)|null|
|**2025-01-29**|**VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching**|Ha-Yeong Choi et.al.|[2501.17612](https://arxiv.org/abs/2501.17612)|null|
|**2025-01-28**|**Compact Neural TTS Voices for Accessibility**|Kunal Jain et.al.|[2501.17332](https://arxiv.org/abs/2501.17332)|null|
|**2025-01-28**|**RDMM: Fine-Tuned LLM Models for On-Device Robotic Decision Making with Enhanced Contextual Awareness in Specific Domains**|Shady Nasrat et.al.|[2501.16899](https://arxiv.org/abs/2501.16899)|**[link](https://github.com/shadynasrat/rdmm)**|
|**2025-01-28**|**AVE Speech Dataset: A Comprehensive Benchmark for Multi-Modal Speech Recognition Integrating Audio, Visual, and Electromyographic Signals**|Dongliang Zhou et.al.|[2501.16780](https://arxiv.org/abs/2501.16780)|null|
|**2025-01-28**|**SCDiar: a streaming diarization system based on speaker change detection and speech recognition**|Naijun Zheng et.al.|[2501.16641](https://arxiv.org/abs/2501.16641)|null|
|**2025-01-27**|**UniPET-SPK: A Unified Framework for Parameter-Efficient Tuning of Pre-trained Speech Models for Robust Speaker Verification**|Mufan Sang et.al.|[2501.16542](https://arxiv.org/abs/2501.16542)|null|
|**2025-01-27**|**Optimized Self-supervised Training with BEST-RQ for Speech Recognition**|Ilja Baumann et.al.|[2501.16131](https://arxiv.org/abs/2501.16131)|null|
|**2025-01-27**|**Classification Error Bound for Low Bayes Error Conditions in Machine Learning**|Zijian Yang et.al.|[2501.15977](https://arxiv.org/abs/2501.15977)|null|
|**2025-01-26**|**Stepback: Enhanced Disentanglement for Voice Conversion via Multi-Task Learning**|Qian Yang et.al.|[2501.15613](https://arxiv.org/abs/2501.15613)|null|
|**2025-01-26**|**End-to-End Target Speaker Speech Recognition Using Context-Aware Attention Mechanisms for Challenging Enrollment Scenario**|Mohsen Ghane et.al.|[2501.15466](https://arxiv.org/abs/2501.15466)|null|
|**2025-01-26**|**Overview of the Amphion Toolkit (v0.2)**|Jiaqi Li et.al.|[2501.15442](https://arxiv.org/abs/2501.15442)|**[link](https://github.com/open-mmlab/amphion)**|
|**2025-01-25**|**The Multicultural Medical Assistant: Can LLMs Improve Medical ASR Errors Across Borders?**|Ayo Adedeji et.al.|[2501.15310](https://arxiv.org/abs/2501.15310)|null|
|**2025-01-25**|**Music Generation using Human-In-The-Loop Reinforcement Learning**|Aju Ani Justus et.al.|[2501.15304](https://arxiv.org/abs/2501.15304)|null|
|**2025-01-25**|**Speech Translation Refinement using Large Language Models**|Huaixia Dou et.al.|[2501.15090](https://arxiv.org/abs/2501.15090)|**[link](https://github.com/world1tree/SpeechTranslationRefinement)**|
|**2025-01-25**|**Robust Cross-Etiology and Speaker-Independent Dysarthric Speech Recognition**|Satwinder Singh et.al.|[2501.14994](https://arxiv.org/abs/2501.14994)|null|
|**2025-01-27**|**Diffusion based Text-to-Music Generation with Global and Local Text based Conditioning**|Jisi Zhang et.al.|[2501.14680](https://arxiv.org/abs/2501.14680)|null|
|**2025-01-24**|**FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration**|Kai-Tuo Xu et.al.|[2501.14350](https://arxiv.org/abs/2501.14350)|**[link](https://github.com/FireRedTeam/FireRedASR.)**|
|**2025-01-24**|**Characteristic-Specific Partial Fine-Tuning for Efficient Emotion and Speaker Adaptation in Codec Language Text-to-Speech Models**|Tianrui Wang et.al.|[2501.14273](https://arxiv.org/abs/2501.14273)|null|
|**2025-01-24**|**Generalizable Audio Deepfake Detection via Latent Space Refinement and Augmentation**|Wen Huang et.al.|[2501.14240](https://arxiv.org/abs/2501.14240)|null|
|**2025-01-24**|**LoCoML: A Framework for Real-World ML Inference Pipelines**|Kritin Maddireddy et.al.|[2501.14165](https://arxiv.org/abs/2501.14165)|null|
|**2025-01-23**|**Integrating Persian Lip Reading in Surena-V Humanoid Robot for Human-Robot Interaction**|Ali Farshian Abbasi et.al.|[2501.13996](https://arxiv.org/abs/2501.13996)|null|
|**2025-01-23**|**Predicting Compact Phrasal Rewrites with Large Language Models for ASR Post Editing**|Hao Zhang et.al.|[2501.13831](https://arxiv.org/abs/2501.13831)|null|
|**2025-01-23**|**Learning-based A Posteriori Speech Presence Probability Estimation and Applications**|Shuai Tao et.al.|[2501.13642](https://arxiv.org/abs/2501.13642)|null|
|**2025-01-23**|**DQ-Data2vec: Decoupling Quantization for Multilingual Speech Recognition**|Qijie Shao et.al.|[2501.13497](https://arxiv.org/abs/2501.13497)|null|
|**2025-01-23**|**Generative Data Augmentation Challenge: Zero-Shot Speech Synthesis for Personalized Speech Enhancement**|Jae-Sung Bae et.al.|[2501.13372](https://arxiv.org/abs/2501.13372)|null|
|**2025-01-23**|**OSUM: Advancing Open Speech Understanding Models with Limited Resources in Academia**|Xuelong Geng et.al.|[2501.13306](https://arxiv.org/abs/2501.13306)|**[link](https://github.com/aslp-lab/osum)**|
|**2025-01-22**|**Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions**|Yan Ru Pei et.al.|[2501.13230](https://arxiv.org/abs/2501.13230)|**[link](https://github.com/Brainchip-Inc/Centaurus)**|
|**2025-01-22**|**FlanEC: Exploring Flan-T5 for Post-ASR Error Correction**|Moreno La Quatra et.al.|[2501.12979](https://arxiv.org/abs/2501.12979)|**[link](https://github.com/morenolaquatra/flanec)**|
|**2025-01-21**|**A Domain Adaptation Framework for Speech Recognition Systems with Only Synthetic data**|Minh Tran et.al.|[2501.12501](https://arxiv.org/abs/2501.12501)|null|
|**2025-01-21**|**DOTA-ME-CS: Daily Oriented Text Audio-Mandarin English-Code Switching Dataset**|Yupei Li et.al.|[2501.12122](https://arxiv.org/abs/2501.12122)|null|
|**2025-01-20**|**Investigation of Whisper ASR Hallucinations Induced by Non-Speech Audio**|Mateusz Barański et.al.|[2501.11378](https://arxiv.org/abs/2501.11378)|null|
|**2025-01-20**|**SEF-PNet: Speaker Encoder-Free Personalized Speech Enhancement with Local and Global Contexts Aggregation**|Ziling Huang et.al.|[2501.11274](https://arxiv.org/abs/2501.11274)|null|
|**2025-01-19**|**Enhancing Neural Spoken Language Recognition: An Exploration with Multilingual Datasets**|Or Haim Anidjar et.al.|[2501.11065](https://arxiv.org/abs/2501.11065)|null|
|**2025-01-18**|**A Benchmark of French ASR Systems Based on Error Severity**|Antoine Tholly et.al.|[2501.10879](https://arxiv.org/abs/2501.10879)|null|
|**2025-01-18**|**GEC-RAG: Improving Generative Error Correction via Retrieval-Augmented Generation for Automatic Speech Recognition Systems**|Amin Robatian et.al.|[2501.10734](https://arxiv.org/abs/2501.10734)|null|
|**2025-01-17**|**Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR**|Karl El Hajal et.al.|[2501.10256](https://arxiv.org/abs/2501.10256)|null|
|**2025-01-17**|**Automatic Speech Recognition for Sanskrit with Transfer Learning**|Bidit Sadhukhan et.al.|[2501.10024](https://arxiv.org/abs/2501.10024)|null|
|**2025-01-17**|**GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions**|Heda Zuo et.al.|[2501.09972](https://arxiv.org/abs/2501.09972)|null|
|**2025-01-21**|**PIER: A Novel Metric for Evaluating What Matters in Code-Switching**|Enes Yavuz Ugan et.al.|[2501.09512](https://arxiv.org/abs/2501.09512)|**[link](https://github.com/enesyugan/pier-codeswitching-evaluation)**|
|**2025-01-16**|**Teaching Wav2Vec2 the Language of the Brain**|Tobias Fiedler et.al.|[2501.09459](https://arxiv.org/abs/2501.09459)|**[link](https://github.com/tfiedlerdev/wav2vec2forbrain)**|
|**2025-01-16**|**Delayed Fusion: Integrating Large Language Models into First-Pass Decoding in End-to-end Speech Recognition**|Takaaki Hori et.al.|[2501.09258](https://arxiv.org/abs/2501.09258)|null|
|**2025-01-17**|**persoDA: Personalized Data Augmentation for Personalized ASR**|Pablo Peso Parada et.al.|[2501.09113](https://arxiv.org/abs/2501.09113)|null|
|**2025-01-15**|**A Non-autoregressive Model for Joint STT and TTS**|Vishal Sunder et.al.|[2501.09104](https://arxiv.org/abs/2501.09104)|null|
|**2025-01-13**|**Discrimination loss vs. SRT: A model-based approach towards harmonizing speech test interpretations**|Mareike Buhl et.al.|[2501.08921](https://arxiv.org/abs/2501.08921)|null|
|**2025-01-15**|**XMusic: Towards a Generalized and Controllable Symbolic Music Generation Framework**|Sida Tian et.al.|[2501.08809](https://arxiv.org/abs/2501.08809)|null|
|**2025-01-15**|**Speech Synthesis along Perceptual Voice Quality Dimensions**|Frederik Rautenberg et.al.|[2501.08791](https://arxiv.org/abs/2501.08791)|null|
|**2025-01-15**|**Adaptive Data Augmentation with NaturalSpeech3 for Far-field Speaker Verification**|Li Zhang et.al.|[2501.08691](https://arxiv.org/abs/2501.08691)|null|
|**2025-01-15**|**Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom**|Melissa Torgbi et.al.|[2501.08502](https://arxiv.org/abs/2501.08502)|null|
|**2025-01-14**|**Selective Attention Merging for low resource tasks: A case study of Child ASR**|Natarajan Balaji Shankar et.al.|[2501.08468](https://arxiv.org/abs/2501.08468)|**[link](https://github.com/balaji1312/sa_merging)**|
|**2025-01-14**|**Loudspeaker Beamforming to Enhance Speech Recognition Performance of Voice Driven Applications**|Dimme de Groot et.al.|[2501.08104](https://arxiv.org/abs/2501.08104)|null|
|**2025-01-13**|**Exploring the encoding of linguistic representations in the Fully-Connected Layer of generative CNNs for Speech**|Bruno Ferenc Šegedin et.al.|[2501.07726](https://arxiv.org/abs/2501.07726)|null|
|**2025-01-13**|**Joint Automatic Speech Recognition And Structure Learning For Better Speech Understanding**|Jiliang Hu et.al.|[2501.07329](https://arxiv.org/abs/2501.07329)|null|
|**2025-01-13**|**Audio-CoT: Exploring Chain-of-Thought Reasoning in Large Audio Language Model**|Ziyang Ma et.al.|[2501.07246](https://arxiv.org/abs/2501.07246)|null|
|**2025-01-13**|**AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR**|The Chuong Chu et.al.|[2501.07102](https://arxiv.org/abs/2501.07102)|null|
|**2025-01-11**|**Discrete Speech Unit Extraction via Independent Component Analysis**|Tomohiko Nakamura et.al.|[2501.06562](https://arxiv.org/abs/2501.06562)|**[link](https://github.com/tomohikonakamura/ica_dsu_espnet)**|
|**2025-01-11**|**A Survey on Spoken Italian Datasets and Corpora**|Marco Giordano et.al.|[2501.06557](https://arxiv.org/abs/2501.06557)|null|
|**2025-01-11**|**Speech Recognition for Automatically Assessing Afrikaans and isiXhosa Preschool Oral Narratives**|Christiaan Jacobs et.al.|[2501.06478](https://arxiv.org/abs/2501.06478)|null|
|**2025-01-11**|**Retrieval-Augmented Dialogue Knowledge Aggregation for Expressive Conversational Speech Synthesis**|Rui Liu et.al.|[2501.06467](https://arxiv.org/abs/2501.06467)|null|
|**2025-01-10**|**TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer**|Vladimir Bataev et.al.|[2501.06320](https://arxiv.org/abs/2501.06320)|null|
|**2025-01-10**|**Contextual ASR Error Handling with LLMs Augmentation for Goal-Oriented Conversational AI**|Yuya Asano et.al.|[2501.06129](https://arxiv.org/abs/2501.06129)|null|
|**2025-01-10**|**Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding**|Fabian David Schmidt et.al.|[2501.06117](https://arxiv.org/abs/2501.06117)|**[link](https://github.com/fdschmidt93/fleurs-slu)**|
|**2025-01-10**|**Benchmarking Rotary Position Embeddings for Automatic Speech Recognition**|Shucong Zhang et.al.|[2501.06051](https://arxiv.org/abs/2501.06051)|null|
|**2025-01-10**|**Comparing Self-Supervised Learning Models Pre-Trained on Human Speech and Animal Vocalizations for Bioacoustics Processing**|Eklavya Sarkar et.al.|[2501.05987](https://arxiv.org/abs/2501.05987)|**[link](https://github.com/idiap/ssl-human-animal)**|
|**2025-01-10**|**Low-Resource Text-to-Speech Synthesis Using Noise-Augmented Training of ForwardTacotron**|Kishor Kayyar Lakshminarayana et.al.|[2501.05976](https://arxiv.org/abs/2501.05976)|null|
|**2025-01-10**|**Universal-2-TF: Robust All-Neural Text Formatting for ASR**|Yash Khare et.al.|[2501.05948](https://arxiv.org/abs/2501.05948)|null|
|**2025-01-10**|**ExPO: Explainable Phonetic Trait-Oriented Network for Speaker Verification**|Yi Ma et.al.|[2501.05729](https://arxiv.org/abs/2501.05729)|**[link](https://github.com/mmmmayi/expo)**|
|**2025-01-09**|**FreeSVC: Towards Zero-shot Multilingual Singing Voice Conversion**|Alef Iury Siqueira Ferreira et.al.|[2501.05586](https://arxiv.org/abs/2501.05586)|**[link](https://github.com/freds0/free-svc)**|
|**2025-01-09**|**Probing Speaker-specific Features in Speaker Representations**|Aemon Yat Fei Chiu et.al.|[2501.05310](https://arxiv.org/abs/2501.05310)|null|
|**2025-01-09**|**DiffAttack: Diffusion-based Timbre-reserved Adversarial Attack in Speaker Identification**|Qing Wang et.al.|[2501.05127](https://arxiv.org/abs/2501.05127)|null|
|**2025-01-09**|**JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for Conversational Speech Synthesis**|Jun-Hyeok Cha et.al.|[2501.04904](https://arxiv.org/abs/2501.04904)|null|
|**2025-01-08**|**FleSpeech: Flexibly Controllable Speech Generation with Various Prompts**|Hanzhao Li et.al.|[2501.04644](https://arxiv.org/abs/2501.04644)|null|
|**2025-01-09**|**OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis**|Run Luo et.al.|[2501.04561](https://arxiv.org/abs/2501.04561)|null|
|**2025-01-09**|**Right Label Context in End-to-End Training of Time-Synchronous ASR Models**|Tina Raissi et.al.|[2501.04521](https://arxiv.org/abs/2501.04521)|null|
|**2025-01-08**|**PolInterviews -- A Dataset of German Politician Public Broadcast Interviews**|Lukas Birkenmaier et.al.|[2501.04484](https://arxiv.org/abs/2501.04484)|null|
|**2025-01-08**|**ZSVC: Zero-shot Style Voice Conversion with Disentangled Latent Diffusion Models and Adversarial Training**|Xinfa Zhu et.al.|[2501.04416](https://arxiv.org/abs/2501.04416)|null|
|**2025-01-08**|**Phone-purity Guided Discrete Tokens for Dysarthric Speech Recognition**|Huimeng Wang et.al.|[2501.04379](https://arxiv.org/abs/2501.04379)|null|
|**2025-01-08**|**DrawSpeech: Expressive Speech Synthesis Using Prosodic Sketches as Control Conditions**|Weidong Chen et.al.|[2501.04256](https://arxiv.org/abs/2501.04256)|null|
|**2025-01-08**|**LipGen: Viseme-Guided Lip Video Generation for Enhancing Visual Speech Recognition**|Bowen Hao et.al.|[2501.04204](https://arxiv.org/abs/2501.04204)|null|
|**2025-01-07**|**Spectral-Aware Low-Rank Adaptation for Speaker Verification**|Zhe Li et.al.|[2501.03829](https://arxiv.org/abs/2501.03829)|**[link](https://github.com/lizhepolyu/SpectralFT.)**|
|**2025-01-07**|**NeuroIncept Decoder for High-Fidelity Speech Reconstruction from Neural Activity**|Owais Mujtaba Khanday et.al.|[2501.03757](https://arxiv.org/abs/2501.03757)|null|
|**2025-01-07**|**Universal Speaker Embedding Free Target Speaker Extraction and Personal Voice Activity Detection**|Bang Zeng et.al.|[2501.03612](https://arxiv.org/abs/2501.03612)|null|
|**2025-01-07**|**Towards a Generalizable Speech Marker for Parkinson's Disease Diagnosis**|Maksim Siniukov et.al.|[2501.03581](https://arxiv.org/abs/2501.03581)|null|
|**2025-01-07**|**Deep Learning for Pathological Speech: A Survey**|Shakeel A. Sheikh et.al.|[2501.03536](https://arxiv.org/abs/2501.03536)|null|
|**2025-01-02**|**FaceSpeak: Expressive and High-Quality Speech Synthesis from Human Portraits of Different Styles**|Tian-Hao Zhang et.al.|[2501.03181](https://arxiv.org/abs/2501.03181)|null|
|**2025-01-06**|**SYKI-SVC: Advancing Singing Voice Conversion with Post-Processing Innovations and an Open-Source Professional Testset**|Yiquan Zhou et.al.|[2501.02953](https://arxiv.org/abs/2501.02953)|null|
|**2025-01-07**|**Samba-ASR: State-Of-The-Art Speech Recognition Leveraging Structured State-Space Models**|Syed Abdul Gaffar Shakhadri et.al.|[2501.02832](https://arxiv.org/abs/2501.02832)|null|
|**2025-01-05**|**Reducing the Gap Between Pretrained Speech Enhancement and Recognition Models Using a Real Speech-Trained Bridging Module**|Zhongjian Cui et.al.|[2501.02452](https://arxiv.org/abs/2501.02452)|null|
|**2025-01-03**|**Improving Transducer-Based Spoken Language Understanding with Self-Conditioned CTC and Knowledge Transfer**|Vishal Sunder et.al.|[2501.01936](https://arxiv.org/abs/2501.01936)|null|
|**2025-01-03**|**CycleFlow: Leveraging Cycle Consistency in Flow Matching for Speaker Style Adaptation**|Ziqi Liang et.al.|[2501.01861](https://arxiv.org/abs/2501.01861)|null|
|**2025-01-03**|**MusicGen-Stem: Multi-stem music generation and edition through autoregressive modeling**|Simon Rouard et.al.|[2501.01757](https://arxiv.org/abs/2501.01757)|null|
|**2025-01-03**|**Controlling your Attributes in Voice**|Xuyuan Li et.al.|[2501.01674](https://arxiv.org/abs/2501.01674)|null|
|**2025-01-03**|**AdaptVC: High Quality Voice Conversion with Adaptive Learning**|Jaehun Kim et.al.|[2501.01347](https://arxiv.org/abs/2501.01347)|null|
|**2025-01-02**|**Advancing Singlish Understanding: Bridging the Gap with Datasets and Multimodal Models**|Bin Wang et.al.|[2501.01034](https://arxiv.org/abs/2501.01034)|**[link](https://github.com/AudioLLMs/Singlish)**|
|**2025-01-01**|**Incremental Dialogue Management: Survey, Discussion, and Implications for HRI**|Casey Kennington et.al.|[2501.00953](https://arxiv.org/abs/2501.00953)|null|
|**2025-01-01**|**Large Language Models Are Read/Write Policy-Makers for Simultaneous Generation**|Shoutao Guo et.al.|[2501.00868](https://arxiv.org/abs/2501.00868)|**[link](https://github.com/ictnlp/LSG)**|
|**2025-01-01**|**Automatic Text Pronunciation Correlation Generation and Application for Contextual Biasing**|Gaofeng Cheng et.al.|[2501.00804](https://arxiv.org/abs/2501.00804)|null|
|**2024-12-31**|**Fotheidil: an Automatic Transcription System for the Irish Language**|Liam Lonergan et.al.|[2501.00509](https://arxiv.org/abs/2501.00509)|null|
|**2024-12-31**|**Unrolled Creative Adversarial Network For Generating Novel Musical Pieces**|Pratik Nag et.al.|[2501.00452](https://arxiv.org/abs/2501.00452)|null|
|**2024-12-31**|**Whisper Turns Stronger: Augmenting Wav2Vec 2.0 for Superior ASR in Low-Resource Languages**|Or Haim Anidjar et.al.|[2501.00425](https://arxiv.org/abs/2501.00425)|null|
|**2024-12-30**|**Takeaways from Applying LLM Capabilities to Multiple Conversational Avatars in a VR Pilot Study**|Mykola Maslych et.al.|[2501.00168](https://arxiv.org/abs/2501.00168)|null|
|**2024-12-30**|**DiCoW: Diarization-Conditioned Whisper for Target Speaker Automatic Speech Recognition**|Alexander Polok et.al.|[2501.00114](https://arxiv.org/abs/2501.00114)|null|
|**2024-12-29**|**EmoReg: Directional Latent Vector Modeling for Emotional Intensity Regularization in Diffusion-based Voice Conversion**|Ashishkumar Gudmalwar et.al.|[2412.20359](https://arxiv.org/abs/2412.20359)|null|
|**2024-12-28**|**Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting**|Wooseok Han et.al.|[2412.20155](https://arxiv.org/abs/2412.20155)|null|
|**2024-12-28**|**CrossSpeech++: Cross-lingual Speech Synthesis with Decoupled Language and Speaker Generation**|Ji-Hoon Kim et.al.|[2412.20048](https://arxiv.org/abs/2412.20048)|null|
|**2024-12-27**|**Enhancing Whisper's Accuracy and Speed for Indian Languages through Prompt-Tuning and Tokenization**|Kumud Tripathi et.al.|[2412.19785](https://arxiv.org/abs/2412.19785)|null|
|**2024-12-26**|**Towards a Single ASR Model That Generalizes to Disordered Speech**|Jimmy Tobin et.al.|[2412.19315](https://arxiv.org/abs/2412.19315)|null|
|**2024-12-26**|**VoiceDiT: Dual-Condition Diffusion Transformer for Environment-Aware Speech Synthesis**|Jaemin Jung et.al.|[2412.19259](https://arxiv.org/abs/2412.19259)|null|
|**2024-12-26**|**Attacking Voice Anonymization Systems with Augmented Feature and Speaker Identity Difference**|Yanzhe Zhang et.al.|[2412.19068](https://arxiv.org/abs/2412.19068)|null|
|**2024-12-26**|**Enhancing Audiovisual Speech Recognition through Bifocal Preference Optimization**|Yihan Wu et.al.|[2412.19005](https://arxiv.org/abs/2412.19005)|**[link](https://github.com/espnet/espnet)**|
|**2024-12-25**|**MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by Real-time MRI**|Neil Shah et.al.|[2412.18836](https://arxiv.org/abs/2412.18836)|null|
|**2024-12-25**|**Structured Speaker-Deficiency Adaptation of Foundation Models for Dysarthric and Elderly Speech Recognition**|Shujie Hu et.al.|[2412.18832](https://arxiv.org/abs/2412.18832)|null|
|**2024-12-25**|**Zema Dataset: A Comprehensive Study of Yaredawi Zema with a Focus on Horologium Chants**|Mequanent Argaw Muluneh et.al.|[2412.18784](https://arxiv.org/abs/2412.18784)|null|
|**2024-12-25**|**Intra- and Inter-modal Context Interaction Modeling for Conversational Speech Synthesis**|Zhenqi Jia et.al.|[2412.18733](https://arxiv.org/abs/2412.18733)|null|
|**2024-12-24**|**Zero-resource Speech Translation and Recognition with LLMs**|Karel Mundnich et.al.|[2412.18566](https://arxiv.org/abs/2412.18566)|null|
|**2024-12-23**|**Trading Devil RL: Backdoor attack via Stock market, Bayesian Optimization and Reinforcement Learning**|Orson Mengara et.al.|[2412.17908](https://arxiv.org/abs/2412.17908)|null|
|**2024-12-23**|**Investigating Prosodic Signatures via Speech Pre-Trained Models for Audio Deepfake Source Attribution**|Orchid Chetia Phukan et.al.|[2412.17796](https://arxiv.org/abs/2412.17796)|null|
|**2024-12-23**|**VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music**|Jiatong Shi et.al.|[2412.17667](https://arxiv.org/abs/2412.17667)|**[link](https://github.com/shinjiwlab/versa)**|
|**2024-12-23**|**UME: Upcycling Mixture-of-Experts for Scalable and Efficient Automatic Speech Recognition**|Li Fu et.al.|[2412.17507](https://arxiv.org/abs/2412.17507)|null|
|**2024-12-23**|**Deep Learning in Proteomics Informatics: Applications, Challenges, and Future Directions**|Yindan Luo et.al.|[2412.17349](https://arxiv.org/abs/2412.17349)|null|
|**2024-12-23**|**Friends-MMC: A Dataset for Multi-modal Multi-party Conversation Understanding**|Yueqian Wang et.al.|[2412.17295](https://arxiv.org/abs/2412.17295)|**[link](https://github.com/yellow-binary-tree/friends-mmc)**|
|**2024-12-22**|**Analysis of Speech Temporal Dynamics in the Context of Speaker Verification and Voice Anonymization**|Natalia Tomashenko et.al.|[2412.17164](https://arxiv.org/abs/2412.17164)|null|
|**2024-12-22**|**Tandem spoofing-robust automatic speaker verification based on time-domain embeddings**|Avishai Weizman et.al.|[2412.17133](https://arxiv.org/abs/2412.17133)|null|
|**2024-12-22**|**Uncovering the Visual Contribution in Audio-Visual Speech Recognition**|Zhaofeng Lin et.al.|[2412.17129](https://arxiv.org/abs/2412.17129)|null|
|**2024-12-22**|**Incremental Disentanglement for Environment-Aware Zero-Shot Text-to-Speech Synthesis**|Ye-Xin Lu et.al.|[2412.16977](https://arxiv.org/abs/2412.16977)|null|
|**2024-12-22**|**Autoregressive Speech Synthesis with Next-Distribution Prediction**|Xinfa Zhu et.al.|[2412.16846](https://arxiv.org/abs/2412.16846)|null|
|**2024-12-20**|**MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula**|Sieun Hyeon et.al.|[2412.15655](https://arxiv.org/abs/2412.15655)|**[link](https://github.com/hyeonsieun/mathspeech)**|
|**2024-12-20**|**TouchASP: Elastic Automatic Speech Perception that Everyone Can Touch**|Xingchen Song et.al.|[2412.15622](https://arxiv.org/abs/2412.15622)|null|
|**2024-12-19**|**Transcribing and Translating, Fast and Slow: Joint Speech Translation and Recognition**|Niko Moritz et.al.|[2412.15415](https://arxiv.org/abs/2412.15415)|null|
|**2024-12-19**|**LAMA-UT: Language Agnostic Multilingual ASR through Orthography Unification and Language-Specific Transliteration**|Sangmin Lee et.al.|[2412.15299](https://arxiv.org/abs/2412.15299)|null|
|**2024-12-17**|**Deep Speech Synthesis from Multimodal Articulatory Representations**|Peter Wu et.al.|[2412.13387](https://arxiv.org/abs/2412.13387)|null|
|**2024-12-17**|**CAMEL: Cross-Attention Enhanced Mixture-of-Experts and Language Bias for Code-Switching Speech Recognition**|He Wang et.al.|[2412.12760](https://arxiv.org/abs/2412.12760)|null|
|**2024-12-17**|**Streaming Keyword Spotting Boosted by Cross-layer Discrimination Consistency**|Yu Xi et.al.|[2412.12635](https://arxiv.org/abs/2412.12635)|null|
|**2024-12-17**|**Hierarchical Control of Emotion Rendering in Speech Synthesis**|Sho Inoue et.al.|[2412.12498](https://arxiv.org/abs/2412.12498)|**[link](https://github.com/shinshoji01/hed-project-page)**|
|**2024-12-17**|**Speak & Improve Corpus 2025: an L2 English Speech Corpus for Language Assessment and Feedback**|Kate Knill et.al.|[2412.11986](https://arxiv.org/abs/2412.11986)|null|
|**2024-12-17**|**Speak & Improve Challenge 2025: Tasks and Baseline Systems**|Mengjie Qian et.al.|[2412.11985](https://arxiv.org/abs/2412.11985)|null|
|**2024-12-19**|**ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible Speech Synthesis**|Xiangheng He et.al.|[2412.11795](https://arxiv.org/abs/2412.11795)|null|
|**2024-12-16**|**Region-Based Optimization in Continual Learning for Audio Deepfake Detection**|Yujie Chen et.al.|[2412.11551](https://arxiv.org/abs/2412.11551)|**[link](https://github.com/cyjie429/rego)**|
|**2024-12-16**|**Towards a Speech Foundation Model for Singapore and Beyond**|Muhammad Huzaifah et.al.|[2412.11538](https://arxiv.org/abs/2412.11538)|null|
|**2024-12-15**|**Transliterated Zero-Shot Domain Adaptation for Automatic Speech Recognition**|Han Zhu et.al.|[2412.11185](https://arxiv.org/abs/2412.11185)|null|
|**2024-12-14**|**MASV: Speaker Verification with Global and Local Context Mamba**|Yang Liu et.al.|[2412.10989](https://arxiv.org/abs/2412.10989)|null|
|**2024-12-14**|**Robust Recognition of Persian Isolated Digits in Speech using Deep Neural Network**|Ali Nasr-Esfahani et.al.|[2412.10857](https://arxiv.org/abs/2412.10857)|null|
|**2024-12-14**|**Efficient Adaptation of Multilingual Models for Japanese ASR**|Mark Bajo et.al.|[2412.10705](https://arxiv.org/abs/2412.10705)|null|
|**2024-12-16**|**Efficient Generative Modeling with Residual Vector Quantization-Based Tokens**|Jaehyeon Kim et.al.|[2412.10208](https://arxiv.org/abs/2412.10208)|null|
|**2024-12-13**|**CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models**|Zhihao Du et.al.|[2412.10117](https://arxiv.org/abs/2412.10117)|null|
|**2024-12-13**|**AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm Detection Incorporating Bi-modal Data Augmentation**|Xiyuan Gao et.al.|[2412.10103](https://arxiv.org/abs/2412.10103)|null|
|**2024-12-13**|**CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls**|Li Chai et.al.|[2412.09887](https://arxiv.org/abs/2412.09887)|null|
|**2024-12-13**|**MERaLiON-AudioLLM: Technical Report**|Yingxu He et.al.|[2412.09818](https://arxiv.org/abs/2412.09818)|null|
|**2024-12-12**|**Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation**|Baisen Wang et.al.|[2412.09428](https://arxiv.org/abs/2412.09428)|**[link](https://github.com/wbs2788/vmb)**|
|**2024-12-12**|**Interpreting Graphic Notation with MusicLDM: An AI Improvisation of Cornelius Cardew's Treatise**|Tornike Karchkhadze et.al.|[2412.08944](https://arxiv.org/abs/2412.08944)|null|
|**2024-12-11**|**Multimodal Latent Language Modeling with Next-Token Diffusion**|Yutao Sun et.al.|[2412.08635](https://arxiv.org/abs/2412.08635)|**[link](https://github.com/microsoft/unilm/tree/master/LatentLM)**|
|**2024-12-12**|**Watermarking Training Data of Music Generation Models**|Pascal Epple et.al.|[2412.08549](https://arxiv.org/abs/2412.08549)|null|
|**2024-12-11**|**Bilevel Joint Unsupervised and Supervised Training for Automatic Speech Recognition**|Xiaodong Cui et.al.|[2412.08548](https://arxiv.org/abs/2412.08548)|null|
|**2024-12-11**|**Zero-Shot Mono-to-Binaural Speech Synthesis**|Alon Levkovitch et.al.|[2412.08356](https://arxiv.org/abs/2412.08356)|null|
|**2024-12-11**|**A Unified Model For Voice and Accent Conversion In Speech and Singing using Self-Supervised Learning and Feature Extraction**|Sowmya Cheripally et.al.|[2412.08312](https://arxiv.org/abs/2412.08312)|null|
|**2024-12-10**|**Frechet Music Distance: A Metric For Generative Symbolic Music Evaluation**|Jan Retkowski et.al.|[2412.07948](https://arxiv.org/abs/2412.07948)|null|
|**2024-12-10**|**Style-agnostic evaluation of ASR using multiple reference transcripts**|Quinten McNamara et.al.|[2412.07937](https://arxiv.org/abs/2412.07937)|null|
|**2024-12-09**|**Effective Text Adaptation for LLM-based ASR through Soft Prompt Fine-Tuning**|Yingyi Ma et.al.|[2412.06967](https://arxiv.org/abs/2412.06967)|null|
|**2024-12-09**|**MuMu-LLaMA: Multi-modal Music Understanding and Generation via Large Language Models**|Shansong Liu et.al.|[2412.06660](https://arxiv.org/abs/2412.06660)|**[link](https://github.com/shansongliu/MuMu-LLaMA)**|
|**2024-12-09**|**Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey**|Tianxin Xie et.al.|[2412.06602](https://arxiv.org/abs/2412.06602)|**[link](https://github.com/imxtx/awesome-controllabe-speech-synthesis)**|
|**2024-12-09**|**Not All Errors Are Equal: Investigation of Speech Recognition Errors in Alzheimer's Disease Detection**|Jiawen Kang et.al.|[2412.06332](https://arxiv.org/abs/2412.06332)|null|
|**2024-12-09**|**VidMusician: Video-to-Music Generation with Semantic-Rhythmic Alignment via Hierarchical Visual Features**|Sifei Li et.al.|[2412.06296](https://arxiv.org/abs/2412.06296)|null|
|**2024-12-09**|**Leveraging Prompt Learning and Pause Encoding for Alzheimer's Disease Detection**|Yin-Long Liu et.al.|[2412.06259](https://arxiv.org/abs/2412.06259)|null|
|**2024-12-07**|**SQ-Whisper: Speaker-Querying based Whisper Model for Target-Speaker ASR**|Pengcheng Guo et.al.|[2412.05589](https://arxiv.org/abs/2412.05589)|null|
|**2024-12-06**|**Adaptive Dropout for Pruning Conformers**|Yotaro Kubo et.al.|[2412.04836](https://arxiv.org/abs/2412.04836)|null|
|**2024-12-10**|**StableVC: Style Controllable Zero-Shot Voice Conversion with Conditional Flow Matching**|Jixun Yao et.al.|[2412.04724](https://arxiv.org/abs/2412.04724)|null|
|**2024-12-05**|**Missing Melodies: AI Music Generation and its "Nearly" Complete Omission of the Global South**|Atharva Mehta et.al.|[2412.04100](https://arxiv.org/abs/2412.04100)|null|
|**2024-12-05**|**Comprehensive Audio Query Handling System with Integrated Expert Models and Contextual Understanding**|Vakada Naveen et.al.|[2412.03980](https://arxiv.org/abs/2412.03980)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784](https://arxiv.org/abs/2412.03784)|null|
|**2024-12-04**|**ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction**|Victor Junqiu Wei et.al.|[2412.03075](https://arxiv.org/abs/2412.03075)|null|
|**2024-12-04**|**Analytic Study of Text-Free Speech Synthesis for Raw Audio using a Self-Supervised Learning Model**|Joonyong Park et.al.|[2412.03074](https://arxiv.org/abs/2412.03074)|null|
|**2024-12-03**|**GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot**|Aohan Zeng et.al.|[2412.02612](https://arxiv.org/abs/2412.02612)|**[link](https://github.com/thudm/glm-4-voice)**|
|**2024-12-01**|**Late fusion ensembles for speech recognition on diverse input audio representations**|Marin Jezidžić et.al.|[2412.01861](https://arxiv.org/abs/2412.01861)|null|
|**2024-12-02**|**Memory-Efficient Training for Deep Speaker Embedding Learning in Speaker Verification**|Bei Liu et.al.|[2412.01195](https://arxiv.org/abs/2412.01195)|null|
|**2024-12-01**|**Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**|Firdavs Nasriddinov et.al.|[2412.00760](https://arxiv.org/abs/2412.00760)|**[link](https://github.com/firdavsn/SurgicalFeedbackAI)**|
|**2024-12-04**|**A Comparative Study of LLM-based ASR and Whisper in Low Resource and Code Switching Scenario**|Zheshu Song et.al.|[2412.00721](https://arxiv.org/abs/2412.00721)|null|
|**2024-11-30**|**From Audio Deepfake Detection to AI-Generated Music Detection -- A Pathway and Overview**|Yupei Li et.al.|[2412.00571](https://arxiv.org/abs/2412.00571)|null|
|**2024-11-30**|**Sample adaptive data augmentation with progressive scheduling**|Hongxuan Lu et.al.|[2412.00415](https://arxiv.org/abs/2412.00415)|null|
|**2024-11-30**|**Empowering the Deaf and Hard of Hearing Community: Enhancing Video Captions Using Large Language Models**|Nadeen Fathallah et.al.|[2412.00342](https://arxiv.org/abs/2412.00342)|null|
|**2024-11-30**|**MusicGen-Chord: Advancing Music Generation through Chord Progressions and Interactive Web-UI**|Jongmin Jung et.al.|[2412.00325](https://arxiv.org/abs/2412.00325)|null|
|**2024-11-30**|**Improving speaker verification robustness with synthetic emotional utterances**|Nikhil Kumar Koditala et.al.|[2412.00319](https://arxiv.org/abs/2412.00319)|null|
|**2024-11-29**|**Noro: A Noise-Robust One-shot Voice Conversion System with Hidden Speaker Representation Capabilities**|Haorui He et.al.|[2411.19770](https://arxiv.org/abs/2411.19770)|null|
|**2024-11-29**|**Memristive Nanowire Network for Energy Efficient Audio Classification: Pre-Processing-Free Reservoir Computing with Reduced Latency**|Akshaya Rajesh et.al.|[2411.19611](https://arxiv.org/abs/2411.19611)|null|
|**2024-12-02**|**CoDiff-VC: A Codec-Assisted Diffusion Model for Zero-shot Voice Conversion**|Yuke Li et.al.|[2411.18918](https://arxiv.org/abs/2411.18918)|null|
|**2024-11-28**|**ArEEG_Words: Dataset for Envisioned Speech Recognition using EEG for Arabic Words**|Hazem Darwish et.al.|[2411.18888](https://arxiv.org/abs/2411.18888)|null|
|**2024-11-27**|**EEG-Based Analysis of Brain Responses in Multi-Modal Human-Robot Interaction: Modulating Engagement**|Suzanne Oliver et.al.|[2411.18587](https://arxiv.org/abs/2411.18587)|null|
|**2024-11-27**|**AMPS: ASR with Multimodal Paraphrase Supervision**|Amruta Parulekar et.al.|[2411.18368](https://arxiv.org/abs/2411.18368)|null|
|**2024-11-27**|**Continual Learning in Machine Speech Chain Using Gradient Episodic Memory**|Geoffrey Tyndall et.al.|[2411.18320](https://arxiv.org/abs/2411.18320)|null|
|**2024-11-27**|**Aligning Pre-trained Models for Spoken Language Translation**|Šimon Sedláček et.al.|[2411.18294](https://arxiv.org/abs/2411.18294)|null|
|**2024-11-27**|**Efficient Nonlinear Function Approximation in Analog Resistive Crossbars for Recurrent Neural Networks**|Junyi Yang et.al.|[2411.18271](https://arxiv.org/abs/2411.18271)|null|
|**2024-11-27**|**How to Learn a New Language? An Efficient Solution for Self-Supervised Learning Models Unseen Languages Adaption in Low-Resource Scenario**|Shih-Heng Wang et.al.|[2411.18217](https://arxiv.org/abs/2411.18217)|null|
|**2024-11-27**|**Machine Unlearning reveals that the Gender-based Violence Victim Condition can be detected from Speech in a Speaker-Agnostic Setting**|Emma Reyner-Fuentes et.al.|[2411.18177](https://arxiv.org/abs/2411.18177)|null|
|**2024-11-27**|**MSA-ASR: Efficient Multilingual Speaker Attribution with frozen ASR Models**|Thai-Binh Nguyen et.al.|[2411.18152](https://arxiv.org/abs/2411.18152)|null|
|**2024-11-27**|**SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation**|Wenyi Yu et.al.|[2411.18138](https://arxiv.org/abs/2411.18138)|null|
|**2024-11-27**|**Fusion of Discrete Representations and Self-Augmented Representations for Multilingual Automatic Speech Recognition**|Shih-heng Wang et.al.|[2411.18107](https://arxiv.org/abs/2411.18107)|null|
|**2024-11-26**|**Visatronic: A Multimodal Decoder-Only Model for Speech Synthesis**|Akshita Gupta et.al.|[2411.17690](https://arxiv.org/abs/2411.17690)|null|
|**2024-11-26**|**Scaling Speech-Text Pre-training with Synthetic Interleaved Data**|Aohan Zeng et.al.|[2411.17607](https://arxiv.org/abs/2411.17607)|null|
|**2024-11-26**|**Towards Maximum Likelihood Training for Transducer-based Streaming Speech Recognition**|Hyeonseung Lee et.al.|[2411.17537](https://arxiv.org/abs/2411.17537)|null|
|**2024-11-26**|**Comparative Analysis of ASR Methods for Speech Deepfake Detection**|Davide Salvi et.al.|[2411.17349](https://arxiv.org/abs/2411.17349)|null|
|**2024-11-26**|**k2SSL: A Faster and Better Framework for Self-Supervised Speech Representation Learning**|Yifan Yang et.al.|[2411.17100](https://arxiv.org/abs/2411.17100)|null|
|**2024-11-25**|**Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**|Elona Shatri et.al.|[2411.16405](https://arxiv.org/abs/2411.16405)|null|
|**2024-11-25**|**The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**|Mohammadreza Molavi et.al.|[2411.16276](https://arxiv.org/abs/2411.16276)|null|
|**2024-11-25**|**SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**|Youngjun Sim et.al.|[2411.16147](https://arxiv.org/abs/2411.16147)|null|
|**2024-11-24**|**A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**|Sooyoung Kim et.al.|[2411.15913](https://arxiv.org/abs/2411.15913)|null|
|**2024-11-22**|**Transforming NLU with Babylon: A Case Study in Development of Real-time, Edge-Efficient, Multi-Intent Translation System for Automated Drive-Thru Ordering**|Mostafa Varzaneh et.al.|[2411.15372](https://arxiv.org/abs/2411.15372)|null|
|**2024-11-22**|**Towards Speaker Identification with Minimal Dataset and Constrained Resources using 1D-Convolution Neural Network**|Irfan Nafiz Shahan et.al.|[2411.15082](https://arxiv.org/abs/2411.15082)|**[link](https://github.com/irfannafiz/recme)**|
|**2024-11-22**|**VQalAttent: a Transparent Speech Generation Pipeline based on Transformer-learned VQ-VAE Latent Space**|Armani Rodriguez et.al.|[2411.14642](https://arxiv.org/abs/2411.14642)|null|
|**2024-11-21**|**Generative AI for Music and Audio**|Hao-Wen Dong et.al.|[2411.14627](https://arxiv.org/abs/2411.14627)|null|
|**2024-11-20**|**From Statistical Methods to Pre-Trained Models; A Survey on Automatic Speech Recognition for Resource Scarce Urdu Language**|Muhammad Sharif et.al.|[2411.14493](https://arxiv.org/abs/2411.14493)|null|
|**2024-11-21**|**Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge**|Ruiyang Qin et.al.|[2411.13766](https://arxiv.org/abs/2411.13766)|null|
|**2024-11-18**|**A Novel Speech Analysis and Correction Tool for Arabic-Speaking Children**|Lamia Berriche et.al.|[2411.13592](https://arxiv.org/abs/2411.13592)|null|
|**2024-11-20**|**CAFE A Novel Code switching Dataset for Algerian Dialect French and English**|Houssam Eddine-Othman Lachemat et.al.|[2411.13424](https://arxiv.org/abs/2411.13424)|null|
|**2024-11-20**|**I2TTS: Image-indicated Immersive Text-to-speech Synthesis with Spatial Perception**|Jiawei Zhang et.al.|[2411.13314](https://arxiv.org/abs/2411.13314)|null|
|**2024-11-20**|**Hard-Synth: Synthesizing Diverse Hard Samples for ASR using Zero-Shot TTS and LLM**|Jiawei Yu et.al.|[2411.13159](https://arxiv.org/abs/2411.13159)|null|
|**2024-11-21**|**Improving Controllability and Editability for Pretrained Text-to-Music Generation Models**|Yixiao Zhang et.al.|[2411.12641](https://arxiv.org/abs/2411.12641)|null|
|**2024-11-19**|**Whisper Finetuning on Nepali Language**|Sanjay Rijal et.al.|[2411.12587](https://arxiv.org/abs/2411.12587)|null|
|**2024-11-18**|**An Investigation of Reprogramming for Cross-Language Adaptation in Speaker Verification Systems**|Jingyu Li et.al.|[2411.11353](https://arxiv.org/abs/2411.11353)|null|
|**2024-11-18**|**Study of the Performance of CEEMDAN in Underdetermined Speech Separation**|Rawad Melhem et.al.|[2411.11312](https://arxiv.org/abs/2411.11312)|null|
|**2024-11-18**|**SAMOS: A Neural MOS Prediction Model Leveraging Semantic Representations and Acoustic Features**|Yu-Fei Shi et.al.|[2411.11232](https://arxiv.org/abs/2411.11232)|null|
|**2024-11-17**|**Inter-linguistic Phonetic Composition (IPC): A Theoretical and Computational Approach to Enhance Second Language Pronunciation**|Jisang Park et.al.|[2411.10927](https://arxiv.org/abs/2411.10927)|null|
|**2024-11-16**|**BanglaDialecto: An End-to-End AI-Powered Regional Speech Standardization**|Md. Nazmus Sadat Samin et.al.|[2411.10879](https://arxiv.org/abs/2411.10879)|**[link](https://github.com/EncryptedBinary/BanglaDialecto)**|
|**2024-11-16**|**Bilingual Text-dependent Speaker Verification with Pre-trained Models for TdSV Challenge 2024**|Seyed Ali Farokh et.al.|[2411.10828](https://arxiv.org/abs/2411.10828)|null|
|**2024-11-15**|**SmoothCache: A Universal Inference Acceleration Technique for Diffusion Transformers**|Joseph Liu et.al.|[2411.10510](https://arxiv.org/abs/2411.10510)|**[link](https://github.com/roblox/smoothcache)**|
|**2024-11-15**|**Interactive Cycle Model -- The Linkage Combination among Automatic Speech Recognition, Large Language Models and Smart Glasses**|Libo Wang et.al.|[2411.10362](https://arxiv.org/abs/2411.10362)|null|
|**2024-11-15**|**Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems**|Pedro Palacios et.al.|[2411.10285](https://arxiv.org/abs/2411.10285)|null|
|**2024-11-15**|**DiMoDif: Discourse Modality-information Differentiation for Audio-visual Deepfake Detection and Localization**|Christos Koutlis et.al.|[2411.10193](https://arxiv.org/abs/2411.10193)|**[link](https://github.com/mever-team/dimodif.)**|
|**2024-11-15**|**XLSR-Mamba: A Dual-Column Bidirectional State Space Model for Spoofing Attack Detection**|Yang Xiao et.al.|[2411.10027](https://arxiv.org/abs/2411.10027)|**[link](https://github.com/swagshaw/XLSR-Mamba.)**|
|**2024-11-15**|**Zero-shot Voice Conversion with Diffusion Transformers**|Songting Liu et.al.|[2411.09943](https://arxiv.org/abs/2411.09943)|null|
|**2024-11-14**|**Everyone deserves their voice to be heard: Analyzing Predictive Gender Bias in ASR Models Applied to Dutch Speech Data**|Rik Raes et.al.|[2411.09431](https://arxiv.org/abs/2411.09431)|null|
|**2024-11-14**|**Transferable Adversarial Attacks against ASR**|Xiaoxue Gao et.al.|[2411.09220](https://arxiv.org/abs/2411.09220)|null|
|**2024-11-14**|**Robust AI-Synthesized Speech Detection Using Feature Decomposition Learning and Synthesizer Feature Augmentation**|Kuiyuan Zhang et.al.|[2411.09167](https://arxiv.org/abs/2411.09167)|null|
|**2024-11-13**|**Language Models for Music Medicine Generation**|Emmanouil Nikolakakis et.al.|[2411.09080](https://arxiv.org/abs/2411.09080)|null|
|**2024-11-14**|**Evaluating Synthetic Command Attacks on Smart Voice Assistants**|Zhengxian He et.al.|[2411.08316](https://arxiv.org/abs/2411.08316)|null|
|**2024-11-13**|**PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation**|Yungang Yi et.al.|[2411.08307](https://arxiv.org/abs/2411.08307)|null|
|**2024-11-11**|**Mamba-based Decoder-Only Approach with Bidirectional Speech Modeling for Speech Recognition**|Yoshiki Masuyama et.al.|[2411.06968](https://arxiv.org/abs/2411.06968)|**[link](https://github.com/YoshikiMas/madeon-asr)**|
|**2024-11-11**|**DCF-DS: Deep Cascade Fusion of Diarization and Separation for Speech Recognition under Realistic Single-Channel Conditions**|Shu-Tong Niu et.al.|[2411.06667](https://arxiv.org/abs/2411.06667)|null|
|**2024-11-10**|**Debatts: Zero-Shot Debating Text-to-Speech Synthesis**|Yiqiao Huang et.al.|[2411.06540](https://arxiv.org/abs/2411.06540)|null|
|**2024-11-10**|**CTC-Assisted LLM-Based Contextual ASR**|Guanrou Yang et.al.|[2411.06437](https://arxiv.org/abs/2411.06437)|**[link](https://github.com/X-LANCE/SLAM-LLM)**|
|**2024-11-07**|**Dialectal Coverage And Generalization in Arabic Speech Recognition**|Amirbek Djanibekov et.al.|[2411.05872](https://arxiv.org/abs/2411.05872)|null|
|**2024-11-07**|**Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models**|Chuqiao Song et.al.|[2411.04862](https://arxiv.org/abs/2411.04862)|null|
|**2024-11-07**|**Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages**|Leena G Pillai et.al.|[2411.04573](https://arxiv.org/abs/2411.04573)|null|
|**2024-11-06**|**Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks**|Felipe Marra et.al.|[2411.03948](https://arxiv.org/abs/2411.03948)|null|
|**2024-11-04**|**Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs**|Alexandros Haliassos et.al.|[2411.02256](https://arxiv.org/abs/2411.02256)|**[link](https://github.com/ahaliassos/usr)**|
|**2024-11-04**|**Complete reconstruction of the tongue contour through acoustic to articulatory inversion using real-time MRI data**|Sofiane Azzouz et.al.|[2411.02037](https://arxiv.org/abs/2411.02037)|null|
|**2024-11-04**|**CTEFM-VC: Zero-Shot Voice Conversion Based on Content-Aware Timbre Ensemble Modeling and Flow Matching**|Yu Pan et.al.|[2411.02026](https://arxiv.org/abs/2411.02026)|null|
|**2024-11-04**|**MoMu-Diffusion: On Learning Long-Term Motion-Music Synchronization and Correspondence**|Fuming You et.al.|[2411.01805](https://arxiv.org/abs/2411.01805)|null|
|**2024-11-03**|**SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation**|Dennis Fucci et.al.|[2411.01710](https://arxiv.org/abs/2411.01710)|null|
|**2024-11-02**|**Leveraging LLM and Text-Queried Separation for Noise-Robust Sound Event Detection**|Han Yin et.al.|[2411.01174](https://arxiv.org/abs/2411.01174)|**[link](https://github.com/apple-yinhan/noise-robust-sed)**|
|**2024-11-02**|**Fish-Speech: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis**|Shijia Liao et.al.|[2411.01156](https://arxiv.org/abs/2411.01156)|**[link](https://github.com/fishaudio/fish-speech)**|
|**2024-11-01**|**Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An Evaluation Using TORGO**|Macarious Hui et.al.|[2411.00980](https://arxiv.org/abs/2411.00980)|null|
|**2024-11-04**|**Optimizing Contextual Speech Recognition Using Vector Quantization for Efficient Retrieval**|Nikolaos Flemotomos et.al.|[2411.00664](https://arxiv.org/abs/2411.00664)|null|
|**2024-10-31**|**IO Transformer: Evaluating SwinV2-Based Reward Models for Computer Vision**|Maxwell Meyer et.al.|[2411.00252](https://arxiv.org/abs/2411.00252)|null|
|**2024-10-31**|**Speech is More Than Words: Do Speech-to-Text Translation Systems Leverage Prosody?**|Ioannis Tsiamas et.al.|[2410.24019](https://arxiv.org/abs/2410.24019)|null|
|**2024-10-31**|**Task-Aware Unified Source Separation**|Kohei Saijo et.al.|[2410.23987](https://arxiv.org/abs/2410.23987)|null|
|**2024-10-30**|**Lina-Speech: Gated Linear Attention is a Fast and Parameter-Efficient Learner for text-to-speech synthesis**|Théodor Lemerle et.al.|[2410.23320](https://arxiv.org/abs/2410.23320)|**[link](https://github.com/theodorblackbird/lina-speech)**|
|**2024-10-30**|**Augmenting Polish Automatic Speech Recognition System With Synthetic Data**|Łukasz Bondaruk et.al.|[2410.22903](https://arxiv.org/abs/2410.22903)|null|
|**2024-10-30**|**Run-Time Adaptation of Neural Beamforming for Robust Speech Dereverberation and Denoising**|Yoto Fujita et.al.|[2410.22805](https://arxiv.org/abs/2410.22805)|null|
|**2024-10-29**|**Emotion-Guided Image to Music Generation**|Souraja Kundu et.al.|[2410.22299](https://arxiv.org/abs/2410.22299)|null|
|**2024-10-29**|**Fast and High-Quality Auto-Regressive Speech Synthesis via Speculative Decoding**|Bohan Li et.al.|[2410.21951](https://arxiv.org/abs/2410.21951)|null|
|**2024-10-29**|**Joint Beamforming and Speaker-Attributed ASR for Real Distant-Microphone Meeting Transcription**|Can Cui et.al.|[2410.21849](https://arxiv.org/abs/2410.21849)|null|
|**2024-10-28**|**Asynchronous Tool Usage for Real-Time Agents**|Antonio A. Ginart et.al.|[2410.21620](https://arxiv.org/abs/2410.21620)|null|
|**2024-10-28**|**Enhancing TTS Stability in Hebrew using Discrete Semantic Units**|Ella Zeldes et.al.|[2410.21502](https://arxiv.org/abs/2410.21502)|null|
|**2024-10-28**|**Mitigating Unauthorized Speech Synthesis for Voice Protection**|Zhisheng Zhang et.al.|[2410.20742](https://arxiv.org/abs/2410.20742)|**[link](https://github.com/wxzyd123/pivotal_objective_perturbation)**|
|**2024-10-27**|**Using Confidence Scores to Improve Eyes-free Detection of Speech Recognition Errors**|Sadia Nowrin et.al.|[2410.20564](https://arxiv.org/abs/2410.20564)|null|
|**2024-10-27**|**Symbotunes: unified hub for symbolic music generative models**|Paweł Skierś et.al.|[2410.20515](https://arxiv.org/abs/2410.20515)|**[link](https://github.com/pskiers/symbotunes)**|
|**2024-10-27**|**MusicFlow: Cascaded Flow Matching for Text Guided Music Generation**|K R Prajwal et.al.|[2410.20478](https://arxiv.org/abs/2410.20478)|null|
|**2024-10-27**|**Get Large Language Models Ready to Speak: A Late-fusion Approach for Speech Generation**|Maohao Shen et.al.|[2410.20336](https://arxiv.org/abs/2410.20336)|null|
|**2024-10-27**|**Improving Speech-based Emotion Recognition with Contextual Utterance Analysis and LLMs**|Enshi Zhang et.al.|[2410.20334](https://arxiv.org/abs/2410.20334)|null|
|**2024-10-26**|**emg2qwerty: A Large Dataset with Baselines for Touch Typing using Surface Electromyography**|Viswanath Sivakumar et.al.|[2410.20081](https://arxiv.org/abs/2410.20081)|**[link](https://github.com/facebookresearch/emg2qwerty)**|
|**2024-10-24**|**Making Social Platforms Accessible: Emotion-Aware Speech Generation with Integrated Text Analysis**|Suparna De et.al.|[2410.19199](https://arxiv.org/abs/2410.19199)|null|
|**2024-10-25**|**A Survey on Speech Large Language Models**|Jing Peng et.al.|[2410.18908](https://arxiv.org/abs/2410.18908)|null|
|**2024-10-24**|**We Augmented Whisper With kNN and You Won't Believe What Came Next**|Maya K. Nachesa et.al.|[2410.18850](https://arxiv.org/abs/2410.18850)|null|
|**2024-10-24**|**STTATTS: Unified Speech-To-Text And Text-To-Speech Model**|Hawau Olamide Toyin et.al.|[2410.18607](https://arxiv.org/abs/2410.18607)|null|
|**2024-10-24**|**Evaluating and Improving Automatic Speech Recognition Systems for Korean Meteorological Experts**|ChaeHun Park et.al.|[2410.18444](https://arxiv.org/abs/2410.18444)|null|
|**2024-10-24**|**Contextual Biasing to Improve Domain-specific Custom Vocabulary Audio Transcription without Explicit Fine-Tuning of Whisper Model**|Vishakha Lall et.al.|[2410.18363](https://arxiv.org/abs/2410.18363)|null|
|**2024-10-23**|**Music102: An $D_{12}$ -equivariant transformer for chord progression accompaniment**|Weiliang Luo et.al.|[2410.18151](https://arxiv.org/abs/2410.18151)|**[link](https://github.com/Benzoin96485/music102)**|
|**2024-10-23**|**ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams**|Srija Anand et.al.|[2410.17901](https://arxiv.org/abs/2410.17901)|null|
|**2024-10-23**|**OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation**|Qinglin Zhang et.al.|[2410.17799](https://arxiv.org/abs/2410.17799)|**[link](https://github.com/karpathy/nanogpt)**|
|**2024-10-23**|**Exploring Tokenization Methods for Multitrack Sheet Music Generation**|Yashan Wang et.al.|[2410.17584](https://arxiv.org/abs/2410.17584)|null|
|**2024-10-23**|**VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning**|Yifan Peng et.al.|[2410.17485](https://arxiv.org/abs/2410.17485)|null|
|**2024-10-22**|**mmWave-Whisper: Phone Call Eavesdropping and Transcription Using Millimeter-Wave Radar**|Suryoday Basak et.al.|[2410.17457](https://arxiv.org/abs/2410.17457)|null|
|**2024-10-22**|**Improving Automatic Speech Recognition with Decoder-Centric Regularisation in Encoder-Decoder Models**|Alexander Polok et.al.|[2410.17437](https://arxiv.org/abs/2410.17437)|null|
|**2024-10-22**|**VoiceBench: Benchmarking LLM-Based Voice Assistants**|Yiming Chen et.al.|[2410.17196](https://arxiv.org/abs/2410.17196)|**[link](https://github.com/matthewcym/voicebench)**|
|**2024-10-22**|**Prototype and Instance Contrastive Learning for Unsupervised Domain Adaptation in Speaker Verification**|Wen Huang et.al.|[2410.17033](https://arxiv.org/abs/2410.17033)|null|
|**2024-10-22**|**Enhancing Low-Resource ASR through Versatile TTS: Bridging the Data Gap**|Guanrou Yang et.al.|[2410.16726](https://arxiv.org/abs/2410.16726)|null|
|**2024-10-22**|**DENOASR: Debiasing ASRs through Selective Denoising**|Anand Kumar Rai et.al.|[2410.16712](https://arxiv.org/abs/2410.16712)|null|
|**2024-10-21**|**AlignVSR: Audio-Visual Cross-Modal Alignment for Visual Speech Recognition**|Zehua Liu et.al.|[2410.16438](https://arxiv.org/abs/2410.16438)|**[link](https://github.com/liu12366262626/alignvsr)**|
|**2024-10-21**|**Neural Scoring, Not Embedding: A Novel Framework for Robust Speaker Verification**|Wan Lin et.al.|[2410.16428](https://arxiv.org/abs/2410.16428)|null|
|**2024-10-21**|**Continuous Speech Synthesis using per-token Latent Diffusion**|Arnon Turetzky et.al.|[2410.16048](https://arxiv.org/abs/2410.16048)|null|
|**2024-10-21**|**LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec**|Yiwei Guo et.al.|[2410.15764](https://arxiv.org/abs/2410.15764)|null|
|**2024-10-21**|**Acoustic Model Optimization over Multiple Data Sources: Merging and Valuation**|Victor Junqiu Wei et.al.|[2410.15620](https://arxiv.org/abs/2410.15620)|null|
|**2024-10-21**|**Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding**|Yeonjoon Jung et.al.|[2410.15609](https://arxiv.org/abs/2410.15609)|null|
|**2024-10-21**|**Moonshine: Speech Recognition for Live Transcription and Voice Commands**|Nat Jeffries et.al.|[2410.15608](https://arxiv.org/abs/2410.15608)|**[link](https://github.com/usefulsensors/moonshine)**|
|**2024-10-20**|**Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example**|Suhita Ghosh et.al.|[2410.15500](https://arxiv.org/abs/2410.15500)|**[link](https://github.com/suhitaghosh10/ddsp-qbe)**|
|**2024-10-20**|**Improving Voice Quality in Speech Anonymization With Just Perception-Informed Losses**|Suhita Ghosh et.al.|[2410.15499](https://arxiv.org/abs/2410.15499)|null|
|**2024-10-20**|**Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant**|Alan Dao et.al.|[2410.15316](https://arxiv.org/abs/2410.15316)|**[link](https://github.com/homebrewltd/ichigo)**|
|**2024-10-19**|**Enhancing Multimodal Sentiment Analysis for Missing Modality through Self-Distillation and Unified Modality Cross-Attention**|Yuzhe Weng et.al.|[2410.15029](https://arxiv.org/abs/2410.15029)|**[link](https://github.com/warmcongee/sdumc)**|
|**2024-10-18**|**AC-Mix: Self-Supervised Adaptation for Low-Resource Automatic Speech Recognition using Agnostic Contrastive Mixup**|Carlos Carvalho et.al.|[2410.14910](https://arxiv.org/abs/2410.14910)|null|
|**2024-10-18**|**A Unified Framework for Collecting Text-to-Speech Synthesis Datasets for 22 Indian Languages**|Sujitha Sathiyamoorthy et.al.|[2410.14197](https://arxiv.org/abs/2410.14197)|null|
|**2024-10-17**|**Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding**|Tan Dat Nguyen et.al.|[2410.13839](https://arxiv.org/abs/2410.13839)|null|
|**2024-10-17**|**Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR**|Abhishek Gupta et.al.|[2410.13445](https://arxiv.org/abs/2410.13445)|null|
|**2024-10-17**|**MeloTrans: A Text to Symbolic Music Generation Model Following Human Composition Habit**|Yutian Wang et.al.|[2410.13419](https://arxiv.org/abs/2410.13419)|null|
|**2024-10-17**|**DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech**|Jan Melechovsky et.al.|[2410.13342](https://arxiv.org/abs/2410.13342)|null|
|**2024-10-17**|**Computational Approaches to Arabic-English Code-Switching**|Caroline Sabty et.al.|[2410.13318](https://arxiv.org/abs/2410.13318)|null|
|**2024-10-17**|**DurIAN-E 2: Duration Informed Attention Network with Adaptive Variational Autoencoder and Adversarial Learning for Expressive Text-to-Speech Synthesis**|Yu Gu et.al.|[2410.13288](https://arxiv.org/abs/2410.13288)|null|
|**2024-10-17**|**Roadmap towards Superhuman Speech Understanding using Large Language Models**|Fan Bu et.al.|[2410.13268](https://arxiv.org/abs/2410.13268)|null|
|**2024-10-17**|**Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation**|Sreyan Ghosh et.al.|[2410.13198](https://arxiv.org/abs/2410.13198)|null|
|**2024-10-17**|**EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning**|Ashish Seth et.al.|[2410.13179](https://arxiv.org/abs/2410.13179)|**[link](https://github.com/cs20s030/ehmam)**|
|**2024-10-17**|**Deep Learning-based Software Engineering: Progress, Challenges, and Opportunities**|Xiangping Chen et.al.|[2410.13110](https://arxiv.org/abs/2410.13110)|null|
|**2024-10-16**|**Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR**|Christoph Minixhofer et.al.|[2410.12279](https://arxiv.org/abs/2410.12279)|null|
|**2024-10-16**|**Guided Speaker Embedding**|Shota Horiguchi et.al.|[2410.12182](https://arxiv.org/abs/2410.12182)|null|
|**2024-10-15**|**A Framework for Adapting Human-Robot Interaction to Diverse User Groups**|Theresa Pekarek Rosin et.al.|[2410.11377](https://arxiv.org/abs/2410.11377)|null|
|**2024-10-15**|**Investigation of Speaker Representation for Target-Speaker Speech Processing**|Takanori Ashihara et.al.|[2410.11243](https://arxiv.org/abs/2410.11243)|null|
|**2024-10-14**|**DMDSpeech: Distilled Diffusion Model Surpassing The Teacher in Zero-shot Speech Synthesis via Direct Metric Optimization**|Yingahao Aaron Li et.al.|[2410.11097](https://arxiv.org/abs/2410.11097)|null|
|**2024-10-14**|**Character-aware audio-visual subtitling in context**|Jaesung Huh et.al.|[2410.11068](https://arxiv.org/abs/2410.11068)|null|
|**2024-10-14**|**Do we need more complex representations for structure? A comparison of note duration representation for Music Transformers**|Gabriel Souza et.al.|[2410.10515](https://arxiv.org/abs/2410.10515)|null|
|**2024-10-14**|**Everyday Speech in the Indian Subcontinent**|Utkarsh Pathak et.al.|[2410.10508](https://arxiv.org/abs/2410.10508)|null|
|**2024-10-14**|**In-Materia Speech Recognition**|Mohamadreza Zolfagharinejad et.al.|[2410.10434](https://arxiv.org/abs/2410.10434)|null|
|**2024-10-13**|**State of NLP in Kenya: A Survey**|Cynthia Jayne Amol et.al.|[2410.09948](https://arxiv.org/abs/2410.09948)|null|
|**2024-10-13**|**M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models**|Megha Sharma et.al.|[2410.09928](https://arxiv.org/abs/2410.09928)|**[link](https://github.com/emanuelevivoli/awesome-comics-understanding)**|
|**2024-10-12**|**SLAM-AAC: Enhancing Audio Captioning with Paraphrasing Augmentation and CLAP-Refine through LLMs**|Wenxi Chen et.al.|[2410.09503](https://arxiv.org/abs/2410.09503)|**[link](https://github.com/X-LANCE/SLAM-LLM)**|
|**2024-10-12**|**Automatic Speech Recognition with BERT and CTC Transformers: A Review**|Noussaiba Djeffal et.al.|[2410.09456](https://arxiv.org/abs/2410.09456)|null|
|**2024-10-11**|**UniGlyph: A Seven-Segment Script for Universal Language Representation**|G. V. Bency Sherin et.al.|[2410.08974](https://arxiv.org/abs/2410.08974)|null|
|**2024-10-14**|**Enhancing Indonesian Automatic Speech Recognition: Evaluating Multilingual Models with Diverse Speech Variabilities**|Aulia Adila et.al.|[2410.08828](https://arxiv.org/abs/2410.08828)|null|
|**2024-10-11**|**Small Tunes Transformer: Exploring Macro & Micro-Level Hierarchies for Skeleton-Conditioned Melody Generation**|Yishan Lv et.al.|[2410.08626](https://arxiv.org/abs/2410.08626)|null|
|**2024-10-11**|**Symbolic Music Generation with Fine-grained Interactive Textural Guidance**|Tingyu Zhu et.al.|[2410.08435](https://arxiv.org/abs/2410.08435)|null|
|**2024-10-10**|**SoundScape: A Human-AI Co-Creation System Making Your Memories Heard**|Chongjun Zhong et.al.|[2410.08136](https://arxiv.org/abs/2410.08136)|null|
|**2024-10-10**|**Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models**|Adriana Fernandez-Lopez et.al.|[2410.07771](https://arxiv.org/abs/2410.07771)|null|
|**2024-10-09**|**The First VoicePrivacy Attacker Challenge Evaluation Plan**|Natalia Tomashenko et.al.|[2410.07428](https://arxiv.org/abs/2410.07428)|**[link](https://github.com/voice-privacy-challenge/voice-privacy-challenge-2024)**|
|**2024-10-09**|**Advocating Character Error Rate for Multilingual ASR Evaluation**|Thennal D K et.al.|[2410.07400](https://arxiv.org/abs/2410.07400)|null|
|**2024-10-09**|**Efficient training strategies for natural sounding speech synthesis and speaker adaptation based on FastPitch**|Teodora Răgman et.al.|[2410.06787](https://arxiv.org/abs/2410.06787)|null|
|**2024-10-09**|**Bahasa Harmony: A Comprehensive Dataset for Bahasa Text-to-Speech Synthesis with Discrete Codec Modeling of EnGen-TTS**|Onkar Kishor Susladkar et.al.|[2410.06608](https://arxiv.org/abs/2410.06608)|null|
|**2024-10-08**|**Diversity-Rewarded CFG Distillation**|Geoffrey Cideron et.al.|[2410.06084](https://arxiv.org/abs/2410.06084)|null|
|**2024-10-08**|**The USTC-NERCSLIP Systems for the CHiME-8 MMCSG Challenge**|Ya Jiang et.al.|[2410.05986](https://arxiv.org/abs/2410.05986)|null|
|**2024-10-08**|**Improving Data Augmentation-based Cross-Speaker Style Transfer for TTS with Singing Voice, Style Filtering, and F0 Matching**|Leonardo B. de M. M. Marques et.al.|[2410.05620](https://arxiv.org/abs/2410.05620)|**[link](https://github.com/olawod/freevc)**|
|**2024-10-07**|**Incorporating Talker Identity Aids With Improving Speech Recognition in Adversarial Environments**|Sagarika Alavilli et.al.|[2410.05423](https://arxiv.org/abs/2410.05423)|null|
|**2024-10-07**|**Presto! Distilling Steps and Layers for Accelerating Music Generation**|Zachary Novack et.al.|[2410.05167](https://arxiv.org/abs/2410.05167)|null|
|**2024-10-07**|**Editing Music with Melody and Text: Using ControlNet for Diffusion Transformer**|Siyuan Hou et.al.|[2410.05151](https://arxiv.org/abs/2410.05151)|null|
|**2024-10-07**|**Enhancing Job Interview Preparation Through Immersive Experiences Using Photorealistic, AI-powered Metahuman Avatars**|Navid Ashrafi et.al.|[2410.05131](https://arxiv.org/abs/2410.05131)|null|
|**2024-10-07**|**CR-CTC: Consistency regularization on CTC for improved speech recognition**|Zengwei Yao et.al.|[2410.05101](https://arxiv.org/abs/2410.05101)|null|
|**2024-10-07**|**Improving Speaker Representations Using Contrastive Losses on Multi-scale Features**|Satvik Dixit et.al.|[2410.05037](https://arxiv.org/abs/2410.05037)|null|
|**2024-10-06**|**Punctuation Prediction for Polish Texts using Transformers**|Jakub Pokrywka et.al.|[2410.04621](https://arxiv.org/abs/2410.04621)|null|
|**2024-10-06**|**Casablanca: Data and Models for Multidialectal Arabic Speech Recognition**|Bashar Talafha et.al.|[2410.04527](https://arxiv.org/abs/2410.04527)|null|
|**2024-10-06**|**HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis**|Yuto Nishimura et.al.|[2410.04380](https://arxiv.org/abs/2410.04380)|null|
|**2024-10-06**|**SONAR: A Synthetic AI-Audio Detection Framework~and Benchmark**|Xiang Li et.al.|[2410.04324](https://arxiv.org/abs/2410.04324)|**[link](https://github.com/jessegator/sonar)**|
|**2024-10-05**|**Efficient and Robust Long-Form Speech Recognition with Hybrid H3-Conformer**|Tomoki Honda et.al.|[2410.04159](https://arxiv.org/abs/2410.04159)|**[link](https://github.com/mirrormouse/hybrid-h3-conformer)**|
|**2024-10-04**|**Generative Semantic Communication for Text-to-Speech Synthesis**|Jiahao Zheng et.al.|[2410.03459](https://arxiv.org/abs/2410.03459)|null|
|**2024-10-04**|**Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges**|Nguyen Van Dinh et.al.|[2410.03458](https://arxiv.org/abs/2410.03458)|null|
|**2024-10-04**|**Team MTS @ AutoMin 2021: An Overview of Existing Summarization Approaches and Comparison to Unsupervised Summarization Techniques**|Olga Iakovenko et.al.|[2410.03412](https://arxiv.org/abs/2410.03412)|null|
|**2024-10-04**|**MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech**|Taejun Bak et.al.|[2410.03192](https://arxiv.org/abs/2410.03192)|null|
|**2024-10-03**|**Disentangling Textual and Acoustic Features of Neural Speech Representations**|Hosein Mohebbi et.al.|[2410.03037](https://arxiv.org/abs/2410.03037)|null|
|**2024-10-03**|**Three-in-One: Fast and Accurate Transducer for Hybrid-Autoregressive ASR**|Hainan Xu et.al.|[2410.02597](https://arxiv.org/abs/2410.02597)|null|
|**2024-10-04**|**Convolutional Variational Autoencoders for Spectrogram Compression in Automatic Speech Recognition**|Olga Iakovenko et.al.|[2410.02560](https://arxiv.org/abs/2410.02560)|null|
|**2024-10-03**|**Algorithms For Automatic Accentuation And Transcription Of Russian Texts In Speech Recognition Systems**|Olga Iakovenko et.al.|[2410.02538](https://arxiv.org/abs/2410.02538)|null|
|**2024-10-03**|**State-of-the-art Embeddings with Video-free Segmentation of the Source VoxCeleb Data**|Sara Barahona et.al.|[2410.02364](https://arxiv.org/abs/2410.02364)|null|
|**2024-10-03**|**A Pilot Study of Applying Sequence-to-Sequence Voice Conversion to Evaluate the Intelligibility of L2 Speech Using a Native Speaker's Shadowings**|Haopeng Geng et.al.|[2410.02239](https://arxiv.org/abs/2410.02239)|null|
|**2024-10-02**|**Generating Symbolic Music from Natural Language Prompts using an LLM-Enhanced Dataset**|Weihan Xu et.al.|[2410.02084](https://arxiv.org/abs/2410.02084)|null|
|**2024-10-02**|**Spoken Grammar Assessment Using LLM**|Sunil Kumar Kopparapu et.al.|[2410.01579](https://arxiv.org/abs/2410.01579)|null|
|**2024-10-02**|**Takin-VC: Zero-shot Voice Conversion via Jointly Hybrid Content and Memory-Augmented Context-Aware Timbre Modeling**|Yuguang Yang et.al.|[2410.01350](https://arxiv.org/abs/2410.01350)|null|
|**2024-10-01**|**MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages**|Marco Gaido et.al.|[2410.01036](https://arxiv.org/abs/2410.01036)|**[link](https://github.com/hlt-mt/mosel)**|
|**2024-10-01**|**Automatic Speech Recognition for the Ika Language**|Uchenna Nzenwata et.al.|[2410.00940](https://arxiv.org/abs/2410.00940)|null|
|**2024-10-01**|**Do Music Generation Models Encode Music Theory?**|Megan Wei et.al.|[2410.00872](https://arxiv.org/abs/2410.00872)|null|
|**2024-10-01**|**VHASR: A Multimodal Speech Recognition System With Vision Hotwords**|Jiliang Hu et.al.|[2410.00822](https://arxiv.org/abs/2410.00822)|**[link](https://github.com/193746/VHASR)**|
|**2024-10-01**|**Improving curriculum learning for target speaker extraction with synthetic speakers**|Yun Liu et.al.|[2410.00811](https://arxiv.org/abs/2410.00811)|null|
|**2024-10-01**|**End-to-End Speech Recognition with Pre-trained Masked Language Model**|Yosuke Higuchi et.al.|[2410.00528](https://arxiv.org/abs/2410.00528)|null|
|**2024-10-02**|**Integrating Text-to-Music Models with Language Models: Composing Long Structured Music Pieces**|Lilac Atassi et.al.|[2410.00344](https://arxiv.org/abs/2410.00344)|null|
|**2024-10-01**|**EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control**|Haozhe Chen et.al.|[2410.00316](https://arxiv.org/abs/2410.00316)|null|
|**2024-09-30**|**Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**|Takafumi Moriya et.al.|[2409.20313](https://arxiv.org/abs/2409.20313)|null|
|**2024-09-30**|**Alignment-Free Training for Transducer-based Multi-Talker ASR**|Takafumi Moriya et.al.|[2409.20301](https://arxiv.org/abs/2409.20301)|null|
|**2024-09-30**|**AfriHuBERT: A self-supervised speech representation model for African languages**|Jesujoba O. Alabi et.al.|[2409.20201](https://arxiv.org/abs/2409.20201)|null|
|**2024-09-30**|**Melody Is All You Need For Music Generation**|Shaopeng Wei et.al.|[2409.20196](https://arxiv.org/abs/2409.20196)|**[link](https://github.com/shaopengw/Awesome-Music-Generation)**|
|**2024-09-30**|**Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**|Oswald Zink et.al.|[2409.19990](https://arxiv.org/abs/2409.19990)|null|
|**2024-09-30**|**HDMoLE: Mixture of LoRA Experts with Hierarchical Routing and Dynamic Thresholds for Fine-Tuning LLM-based ASR Models**|Bingshen Mu et.al.|[2409.19878](https://arxiv.org/abs/2409.19878)|null|
|**2024-09-29**|**Fine-Tuning Automatic Speech Recognition for People with Parkinson's: An Effective Strategy for Enhancing Speech Technology Accessibility**|Xiuwen Zheng et.al.|[2409.19818](https://arxiv.org/abs/2409.19818)|null|
|**2024-09-29**|**Efficient Long-Form Speech Recognition for General Speech In-Context Learning**|Hao Yen et.al.|[2409.19757](https://arxiv.org/abs/2409.19757)|null|
|**2024-09-29**|**Quantitative Analysis of Audio-Visual Tasks: An Information-Theoretic Perspective**|Chen Chen et.al.|[2409.19575](https://arxiv.org/abs/2409.19575)|null|
|**2024-09-29**|**CoT-ST: Enhancing LLM-based Speech Translation with Multimodal Chain-of-Thought**|Yexing Du et.al.|[2409.19510](https://arxiv.org/abs/2409.19510)|**[link](https://github.com/X-LANCE/SLAM-LLM)**|
|**2024-09-27**|**Speech-Mamba: Long-Context Speech Recognition with Selective State Spaces Models**|Xiaoxue Gao et.al.|[2409.18654](https://arxiv.org/abs/2409.18654)|null|
|**2024-09-27**|**ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5**|Jiaming Zhou et.al.|[2409.18584](https://arxiv.org/abs/2409.18584)|null|
|**2024-09-27**|**EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis**|Haoyu Wang et.al.|[2409.18512](https://arxiv.org/abs/2409.18512)|null|
|**2024-09-27**|**Improving Multilingual ASR in the Wild Using Simple N-best Re-ranking**|Brian Yan et.al.|[2409.18428](https://arxiv.org/abs/2409.18428)|null|
|**2024-09-26**|**Unveiling the Role of Pretraining in Direct Speech Translation**|Belen Alastruey et.al.|[2409.18044](https://arxiv.org/abs/2409.18044)|null|
|**2024-09-26**|**Are Transformers in Pre-trained LM A Good ASR Encoder? An Empirical Study**|Keyu An et.al.|[2409.17750](https://arxiv.org/abs/2409.17750)|null|
|**2024-09-26**|**Paraformer-v2: An improved non-autoregressive transformer for noise-robust speech recognition**|Keyu An et.al.|[2409.17746](https://arxiv.org/abs/2409.17746)|null|
|**2024-09-26**|**Deep CLAS: Deep Contextual Listen, Attend and Spell**|Shifu Xiong et.al.|[2409.17603](https://arxiv.org/abs/2409.17603)|null|
|**2024-09-25**|**Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion**|Giuseppe Ruggiero et.al.|[2409.17387](https://arxiv.org/abs/2409.17387)|null|
|**2024-09-25**|**Exploring synthetic data for cross-speaker style transfer in style representation based TTS**|Lucas H. Ueda et.al.|[2409.17364](https://arxiv.org/abs/2409.17364)|null|
|**2024-09-25**|**How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not**|Francesco Verdini et.al.|[2409.17044](https://arxiv.org/abs/2409.17044)|null|
|**2024-09-25**|**MT2KD: Towards A General-Purpose Encoder for Speech, Speaker, and Audio Events**|Xiaoyu Yang et.al.|[2409.17010](https://arxiv.org/abs/2409.17010)|null|
|**2024-09-25**|**Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition**|Andrés Piñeiro-Martín et.al.|[2409.16954](https://arxiv.org/abs/2409.16954)|null|
|**2024-09-25**|**Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling**|Yuanchao Li et.al.|[2409.16937](https://arxiv.org/abs/2409.16937)|**[link](https://github.com/yc-li20/semi-supervised-training)**|
|**2024-09-25**|**Speech Recognition Rescoring with Large Speech-Text Foundation Models**|Prashanth Gurunath Shivakumar et.al.|[2409.16654](https://arxiv.org/abs/2409.16654)|null|
|**2024-09-24**|**Spelling Correction through Rewriting of Non-Autoregressive ASR Lattices**|Leonid Velikovich et.al.|[2409.16469](https://arxiv.org/abs/2409.16469)|null|
|**2024-09-24**|**FastTalker: Jointly Generating Speech and Conversational Gestures from Text**|Zixin Guo et.al.|[2409.16404](https://arxiv.org/abs/2409.16404)|null|
|**2024-09-24**|**Revisiting Acoustic Features for Robust ASR**|Muhammad A. Shah et.al.|[2409.16399](https://arxiv.org/abs/2409.16399)|null|
|**2024-09-24**|**Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech**|Yunji Chu et.al.|[2409.16203](https://arxiv.org/abs/2409.16203)|null|
|**2024-09-24**|**ComiCap: A VLMs pipeline for dense captioning of Comic Panels**|Emanuele Vivoli et.al.|[2409.16159](https://arxiv.org/abs/2409.16159)|**[link](https://github.com/emanuelevivoli/comicap)**|
|**2024-09-24**|**Bridging Speech and Text: Enhancing ASR with Pinyin-to-Character Pre-training in LLMs**|Yang Yuhang et.al.|[2409.16005](https://arxiv.org/abs/2409.16005)|null|
|**2024-09-24**|**Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification**|Fengrun Zhang et.al.|[2409.15974](https://arxiv.org/abs/2409.15974)|null|
|**2024-09-24**|**Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM**|Fengrun Zhang et.al.|[2409.15905](https://arxiv.org/abs/2409.15905)|null|
|**2024-09-24**|**Exploring VQ-VAE with Prosody Parameters for Speaker Anonymization**|Sotheara Leang et.al.|[2409.15882](https://arxiv.org/abs/2409.15882)|null|
|**2024-09-24**|**WeSep: A Scalable and Flexible Toolkit Towards Generalizable Target Speaker Extraction**|Shuai Wang et.al.|[2409.15799](https://arxiv.org/abs/2409.15799)|null|
|**2024-09-24**|**M-Vec: Matryoshka Speaker Embeddings with Flexible Dimensions**|Shuai Wang et.al.|[2409.15782](https://arxiv.org/abs/2409.15782)|null|
|**2024-09-24**|**Enhancing Open-Set Speaker Identification through Rapid Tuning with Speaker Reciprocal Points and Negative Sample**|Zhiyong Chen et.al.|[2409.15742](https://arxiv.org/abs/2409.15742)|null|
|**2024-09-24**|**StyleFusion TTS: Multimodal Style-control and Enhanced Feature Fusion for Zero-shot Text-to-speech Synthesis**|Zhiyong Chen et.al.|[2409.15741](https://arxiv.org/abs/2409.15741)|null|
|**2024-09-19**|**WeHelp: A Shared Autonomy System for Wheelchair Users**|Abulikemu Abuduweili et.al.|[2409.12159](https://arxiv.org/abs/2409.12159)|**[link](https://github.com/walleclipse/wehelp)**|
|**2024-09-18**|**ASR Benchmarking: Need for a More Representative Conversational Dataset**|Gaurav Maheshwari et.al.|[2409.12042](https://arxiv.org/abs/2409.12042)|**[link](https://github.com/diabolocom-research/conversationaldataset)**|
|**2024-09-18**|**Mixture of Experts Fusion for Fake Audio Detection Using Frozen wav2vec 2.0**|Zhiyong Wang et.al.|[2409.11909](https://arxiv.org/abs/2409.11909)|null|
|**2024-09-18**|**M2R-Whisper: Multi-stage and Multi-scale Retrieval Augmentation for Enhancing Whisper**|Jiaming Zhou et.al.|[2409.11889](https://arxiv.org/abs/2409.11889)|null|
|**2024-09-18**|**METEOR: Melody-aware Texture-controllable Symbolic Orchestral Music Generation**|Dinh-Viet-Toan Le et.al.|[2409.11753](https://arxiv.org/abs/2409.11753)|**[link](https://github.com/dinhviettoanle/meteor)**|
|**2024-09-19**|**Simulating Native Speaker Shadowing for Nonnative Speech Assessment with Latent Speech Representations**|Haopeng Geng et.al.|[2409.11742](https://arxiv.org/abs/2409.11742)|null|
|**2024-09-17**|**Discrete Unit based Masking for Improving Disentanglement in Voice Conversion**|Philip H. Lee et.al.|[2409.11560](https://arxiv.org/abs/2409.11560)|null|
|**2024-09-17**|**Chain-of-Thought Prompting for Speech Translation**|Ke Hu et.al.|[2409.11538](https://arxiv.org/abs/2409.11538)|null|
|**2024-09-17**|**M-BEST-RQ: A Multi-Channel Speech Foundation Model for Smart Glasses**|Yufeng Yang et.al.|[2409.11494](https://arxiv.org/abs/2409.11494)|null|
|**2024-09-17**|**Bio-Inspired Mamba: Temporal Locality and Bioplausible Learning in Selective State Space Models**|Jiahao Qin et.al.|[2409.11263](https://arxiv.org/abs/2409.11263)|null|
|**2024-09-17**|**WER We Stand: Benchmarking Urdu ASR Models**|Samee Arif et.al.|[2409.11252](https://arxiv.org/abs/2409.11252)|null|
|**2024-09-17**|**Ideal-LLM: Integrating Dual Encoders and Language-Adapted LLM for Multilingual Speech-to-Text**|Hongfei Xue et.al.|[2409.11214](https://arxiv.org/abs/2409.11214)|null|
|**2024-09-17**|**Zero Shot Text to Speech Augmentation for Automatic Speech Recognition on Low-Resource Accented Speech Corpora**|Francesco Nespoli et.al.|[2409.11107](https://arxiv.org/abs/2409.11107)|null|
|**2024-09-17**|**Single-stage TTS with Masked Audio Token Modeling and Semantic Knowledge Distillation**|Gerard I. Gállego et.al.|[2409.11003](https://arxiv.org/abs/2409.11003)|null|
|**2024-09-17**|**Enhancing Low-Resource Language and Instruction Following Capabilities of Audio Language Models**|Potsawee Manakul et.al.|[2409.10999](https://arxiv.org/abs/2409.10999)|null|
|**2024-09-17**|**Enhancing Multilingual Speech Generation and Recognition Abilities in LLMs with Constructed Code-switched Data**|Jing Xu et.al.|[2409.10969](https://arxiv.org/abs/2409.10969)|null|
|**2024-09-17**|**Speech Recognition for Analysis of Police Radio Communication**|Tejes Srivastava et.al.|[2409.10858](https://arxiv.org/abs/2409.10858)|null|
|**2024-09-17**|**PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music Processing**|Phillip Long et.al.|[2409.10831](https://arxiv.org/abs/2409.10831)|null|
|**2024-09-16**|**Speaker-IPL: Unsupervised Learning of Speaker Characteristics with i-Vector based Pseudo-Labels**|Zakaria Aldeneh et.al.|[2409.10791](https://arxiv.org/abs/2409.10791)|null|
|**2024-09-16**|**An Efficient Self-Learning Framework For Interactive Spoken Dialog Systems**|Hitesh Tulsiani et.al.|[2409.10515](https://arxiv.org/abs/2409.10515)|null|
|**2024-09-16**|**Meta-Whisper: Speech-Based Meta-ICL for ASR on Low-Resource Languages**|Ming-Hao Hsu et.al.|[2409.10429](https://arxiv.org/abs/2409.10429)|null|
|**2024-09-16**|**Voice control interface for surgical robot assistants**|Ana Davila et.al.|[2409.10225](https://arxiv.org/abs/2409.10225)|null|
|**2024-09-16**|**Augmenting Automatic Speech Recognition Models with Disfluency Detection**|Robin Amann et.al.|[2409.10177](https://arxiv.org/abs/2409.10177)|null|
|**2024-09-16**|**Emo-DPO: Controllable Emotional Speech Synthesis through Direct Preference Optimization**|Xiaoxue Gao et.al.|[2409.10157](https://arxiv.org/abs/2409.10157)|null|
|**2024-09-16**|**Optimizing Dysarthria Wake-Up Word Spotting: An End-to-End Approach for SLT 2024 LRDWWS Challenge**|Shuiyun Liu et.al.|[2409.10076](https://arxiv.org/abs/2409.10076)|null|
|**2024-09-16**|**Speaker Contrastive Learning for Source Speaker Tracing**|Qing Wang et.al.|[2409.10072](https://arxiv.org/abs/2409.10072)|null|
|**2024-09-16**|**StyleTTS-ZS: Efficient High-Quality Zero-Shot Text-to-Speech Synthesis with Distilled Time-Varying Style Diffusion**|Yinghao Aaron Li et.al.|[2409.10058](https://arxiv.org/abs/2409.10058)|null|
|**2024-09-16**|**A Study on Zero-shot Non-intrusive Speech Assessment using Large Language Models**|Ryandhimas E. Zezario et.al.|[2409.09914](https://arxiv.org/abs/2409.09914)|null|
|**2024-09-15**|**Large Language Model Based Generative Error Correction: A Challenge and Baselines forSpeech Recognition, Speaker Tagging, and Emotion Recognition**|Chao-Han Huck Yang et.al.|[2409.09785](https://arxiv.org/abs/2409.09785)|null|
|**2024-09-13**|**Clean Label Attacks against SLU Systems**|Henry Li Xinyuan et.al.|[2409.08985](https://arxiv.org/abs/2409.08985)|null|
|**2024-09-13**|**HLTCOE JHU Submission to the Voice Privacy Challenge 2024**|Henry Li Xinyuan et.al.|[2409.08913](https://arxiv.org/abs/2409.08913)|null|
|**2024-09-13**|**Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages**|Yao-Fei Cheng et.al.|[2409.08872](https://arxiv.org/abs/2409.08872)|null|
|**2024-09-13**|**Exploring SSL Discrete Tokens for Multilingual ASR**|Mingyu Cui et.al.|[2409.08805](https://arxiv.org/abs/2409.08805)|null|
|**2024-09-13**|**Text-To-Speech Synthesis In The Wild**|Jee-weon Jung et.al.|[2409.08711](https://arxiv.org/abs/2409.08711)|null|
|**2024-09-13**|**NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training**|Minglun Han et.al.|[2409.08680](https://arxiv.org/abs/2409.08680)|null|
|**2024-09-13**|**LA-RAG:Enhancing LLM-based ASR Accuracy with Retrieval-Augmented Generation**|Shaojun Li et.al.|[2409.08597](https://arxiv.org/abs/2409.08597)|null|
|**2024-09-13**|**Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions**|Lingwei Meng et.al.|[2409.08596](https://arxiv.org/abs/2409.08596)|**[link](https://github.com/cuhealthybrains/mt-llm)**|
|**2024-09-13**|**LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling**|Yubo Huang et.al.|[2409.08583](https://arxiv.org/abs/2409.08583)|null|
|**2024-09-13**|**LLM-Powered Grapheme-to-Phoneme Conversion: Benchmark and Case Study**|Mahta Fetrat Qharabagh et.al.|[2409.08554](https://arxiv.org/abs/2409.08554)|null|
|**2024-09-12**|**Hierarchical Symbolic Pop Music Generation with Graph Neural Networks**|Wen Qing Lim et.al.|[2409.08155](https://arxiv.org/abs/2409.08155)|null|
|**2024-09-12**|**Faster Speech-LLaMA Inference with Multi-token Prediction**|Desh Raj et.al.|[2409.08148](https://arxiv.org/abs/2409.08148)|null|
|**2024-09-12**|**WhisperNER: Unified Open Named Entity and Speech Recognition**|Gil Ayache et.al.|[2409.08107](https://arxiv.org/abs/2409.08107)|null|
|**2024-09-12**|**The Faetar Benchmark: Speech Recognition in a Very Under-Resourced Language**|Michael Ong et.al.|[2409.08103](https://arxiv.org/abs/2409.08103)|null|
|**2024-09-12**|**Zero-Shot Sing Voice Conversion: built upon clustering-based phoneme representations**|Wangjin Zhou et.al.|[2409.08039](https://arxiv.org/abs/2409.08039)|null|
|**2024-09-12**|**Auto-Landmark: Acoustic Landmark Dataset and Open-Source Toolkit for Landmark Extraction**|Xiangyu Zhang et.al.|[2409.07969](https://arxiv.org/abs/2409.07969)|null|
|**2024-09-12**|**Detecting and Defending Against Adversarial Attacks on Automatic Speech Recognition via Diffusion Models**|Nikolai L. Kühne et.al.|[2409.07936](https://arxiv.org/abs/2409.07936)|null|
|**2024-09-12**|**Tidal MerzA: Combining affective modelling and autonomous code generation through Reinforcement Learning**|Elizabeth Wilson et.al.|[2409.07918](https://arxiv.org/abs/2409.07918)|null|
|**2024-09-12**|**Bridging Paintings and Music -- Exploring Emotion based Music Generation through Paintings**|Tanisha Hisariya et.al.|[2409.07827](https://arxiv.org/abs/2409.07827)|null|
|**2024-09-12**|**Full-text Error Correction for Chinese Speech Recognition with Large Language Model**|Zhiyuan Tang et.al.|[2409.07790](https://arxiv.org/abs/2409.07790)|null|
|**2024-09-11**|**VMAS: Video-to-Music Generation via Semantic Alignment in Web Music Videos**|Yan-Bo Lin et.al.|[2409.07450](https://arxiv.org/abs/2409.07450)|null|
|**2024-09-11**|**D-CAPTCHA++: A Study of Resilience of Deepfake CAPTCHA under Transferable Imperceptible Adversarial Attack**|Hong-Hanh Nguyen-Le et.al.|[2409.07390](https://arxiv.org/abs/2409.07390)|null|
|**2024-09-11**|**Rethinking Mamba in Speech Processing by Self-Supervised Models**|Xiangyu Zhang et.al.|[2409.07273](https://arxiv.org/abs/2409.07273)|null|
|**2024-09-11**|**ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages**|Mahta Fetrat Qharabagh et.al.|[2409.07259](https://arxiv.org/abs/2409.07259)|null|
|**2024-09-11**|**Enhancing CTC-Based Visual Speech Recognition**|Hendrik Laux et.al.|[2409.07210](https://arxiv.org/abs/2409.07210)|null|
|**2024-09-11**|**Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition**|Titouan Parcollet et.al.|[2409.07165](https://arxiv.org/abs/2409.07165)|null|
|**2024-09-11**|**The VoiceMOS Challenge 2024: Beyond Speech Quality Prediction**|Wen-Chin Huang et.al.|[2409.07001](https://arxiv.org/abs/2409.07001)|null|
|**2024-09-10**|**An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition**|Yi-Cheng Wang et.al.|[2409.06468](https://arxiv.org/abs/2409.06468)|null|
|**2024-09-10**|**What happens to diffusion model likelihood when your model is conditional?**|Mattias Cross et.al.|[2409.06364](https://arxiv.org/abs/2409.06364)|null|
|**2024-09-10**|**VoiceWukong: Benchmarking Deepfake Voice Detection**|Ziwei Yan et.al.|[2409.06348](https://arxiv.org/abs/2409.06348)|null|
|**2024-09-10**|**Spoofing-Aware Speaker Verification Robust Against Domain and Channel Mismatches**|Chang Zeng et.al.|[2409.06327](https://arxiv.org/abs/2409.06327)|null|
|**2024-09-10**|**Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking**|Jihyun Lee et.al.|[2409.06263](https://arxiv.org/abs/2409.06263)|null|
|**2024-09-10**|**RobustSVC: HuBERT-based Melody Extractor and Adversarial Learning for Robust Singing Voice Conversion**|Wei Chen et.al.|[2409.06237](https://arxiv.org/abs/2409.06237)|null|
|**2024-09-10**|**Advancing Topic Segmentation of Broadcasted Speech with Multilingual Semantic Embeddings**|Sakshi Deo Shukla et.al.|[2409.06222](https://arxiv.org/abs/2409.06222)|null|
|**2024-09-10**|**Multi-Source Music Generation with Latent Diffusion**|Zhongweiyang Xu et.al.|[2409.06190](https://arxiv.org/abs/2409.06190)|**[link](https://github.com/xzwy/msldm)**|
|**2024-09-10**|**VC-ENHANCE: Speech Restoration with Integrated Noise Suppression and Voice Conversion**|Kyungguen Byun et.al.|[2409.06126](https://arxiv.org/abs/2409.06126)|null|
|**2024-09-09**|**Retrieval Augmented Correction of Named Entity Speech Recognition Errors**|Ernest Pusateri et.al.|[2409.06062](https://arxiv.org/abs/2409.06062)|null|
|**2024-09-09**|**PDAF: A Phonetic Debiasing Attention Framework For Speaker Verification**|Massa Baali et.al.|[2409.05799](https://arxiv.org/abs/2409.05799)|null|
|**2024-09-09**|**Consensus-based Distributed Quantum Kernel Learning for Speech Recognition**|Kuan-Cheng Chen et.al.|[2409.05770](https://arxiv.org/abs/2409.05770)|null|
|**2024-09-09**|**A Toolkit for Joint Speaker Diarization and Identification with Application to Speaker-Attributed ASR**|Giovanni Morrone et.al.|[2409.05750](https://arxiv.org/abs/2409.05750)|null|
|**2024-09-09**|**AS-Speech: Adaptive Style For Speech Synthesis**|Zhipeng Li et.al.|[2409.05730](https://arxiv.org/abs/2409.05730)|null|
|**2024-09-09**|**Evaluation of real-time transcriptions using end-to-end ASR models**|Carlos Arriaga et.al.|[2409.05674](https://arxiv.org/abs/2409.05674)|null|
|**2024-09-09**|**Longer is (Not Necessarily) Stronger: Punctuated Long-Sequence Training for Enhanced Speech Recognition and Translation**|Nithin Rao Koluguri et.al.|[2409.05601](https://arxiv.org/abs/2409.05601)|null|
|**2024-09-09**|**An investigation of modularity for noise robustness in conformer-based ASR**|Louise Coppieters de Gibson et.al.|[2409.05589](https://arxiv.org/abs/2409.05589)|null|
|**2024-09-09**|**NTT Multi-Speaker ASR System for the DASR Task of CHiME-8 Challenge**|Naoyuki Kamo et.al.|[2409.05554](https://arxiv.org/abs/2409.05554)|null|
|**2024-09-09**|**Findings of the 2024 Mandarin Stuttering Event Detection and Automatic Speech Recognition Challenge**|Hongfei Xue et.al.|[2409.05430](https://arxiv.org/abs/2409.05430)|null|
|**2024-09-08**|**Exploring WavLM Back-ends for Speech Spoofing and Deepfake Detection**|Theophile Stourbe et.al.|[2409.05032](https://arxiv.org/abs/2409.05032)|null|
|**2024-09-05**|**Privacy versus Emotion Preservation Trade-offs in Emotion-Preserving Speaker Anonymization**|Zexin Cai et.al.|[2409.03655](https://arxiv.org/abs/2409.03655)|null|
|**2024-09-05**|**DiffEVC: Any-to-Any Emotion Voice Conversion with Expressive Guidance**|Hsing-Hang Chou et.al.|[2409.03636](https://arxiv.org/abs/2409.03636)|null|
|**2024-09-05**|**Speaker and Style Disentanglement of Speech Based on Contrastive Predictive Coding Supported Factorized Variational Autoencoder**|Yuying Xie et.al.|[2409.03520](https://arxiv.org/abs/2409.03520)|null|
|**2024-09-04**|**Probing self-attention in self-supervised speech models for cross-linguistic differences**|Sai Gopinath et.al.|[2409.03115](https://arxiv.org/abs/2409.03115)|null|
|**2024-09-04**|**Quantification of stylistic differences in human- and ASR-produced transcripts of African American English**|Annika Heuser et.al.|[2409.03059](https://arxiv.org/abs/2409.03059)|null|
|**2024-09-04**|**SymPAC: Scalable Symbolic Music Generation With Prompts And Constraints**|Haonan Chen et.al.|[2409.03055](https://arxiv.org/abs/2409.03055)|null|
|**2024-09-04**|**Multi-Track MusicLDM: Towards Versatile Music Generation with Latent Diffusion Model**|Tornike Karchkhadze et.al.|[2409.02845](https://arxiv.org/abs/2409.02845)|null|
|**2024-09-04**|**Efficient Extraction of Noise-Robust Discrete Units from Self-Supervised Speech Models**|Jakob Poncelet et.al.|[2409.02565](https://arxiv.org/abs/2409.02565)|null|
|**2024-09-04**|**Parameter estimation of hidden Markov models: comparison of EM and quasi-Newton methods with a new hybrid algorithm**|Sidonie Foulon et.al.|[2409.02477](https://arxiv.org/abs/2409.02477)|null|
|**2024-09-04**|**Fast, High-Quality and Parameter-Efficient Articulatory Synthesis using Differentiable DSP**|Yisi Liu et.al.|[2409.02451](https://arxiv.org/abs/2409.02451)|null|
|**2024-09-04**|**What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations**|Kavya Manohar et.al.|[2409.02449](https://arxiv.org/abs/2409.02449)|null|
|**2024-09-04**|**MusicMamba: A Dual-Feature Modeling Approach for Generating Chinese Traditional Music with Modal Precision**|Jiatao Chen et.al.|[2409.02421](https://arxiv.org/abs/2409.02421)|**[link](https://github.com/Wietc/MusicMamba)**|
|**2024-09-03**|**FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation**|Takuhiro Kaneko et.al.|[2409.02245](https://arxiv.org/abs/2409.02245)|null|
|**2024-09-03**|**Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge Transfer Learning for ASR**|Xugang Lu et.al.|[2409.02239](https://arxiv.org/abs/2409.02239)|null|
|**2024-09-03**|**Enhancing Code-Switching Speech Recognition with LID-Based Collaborative Mixture of Experts Model**|Hukai Huang et.al.|[2409.02050](https://arxiv.org/abs/2409.02050)|null|
|**2024-09-03**|**The USTC-NERCSLIP Systems for the CHiME-8 NOTSOFAR-1 Challenge**|Shutong Niu et.al.|[2409.02041](https://arxiv.org/abs/2409.02041)|null|
|**2024-08-30**|**Advancing Multi-talker ASR Performance with Large Language Models**|Mohan Shi et.al.|[2408.17431](https://arxiv.org/abs/2408.17431)|null|
|**2024-08-30**|**AASIST3: KAN-Enhanced AASIST Speech Deepfake Detection using SSL Features and Additional Regularization for the ASVspoof 2024 Challenge**|Kirill Borodin et.al.|[2408.17352](https://arxiv.org/abs/2408.17352)|null|
|**2024-08-30**|**Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model**|Zhen Ye et.al.|[2408.17175](https://arxiv.org/abs/2408.17175)|**[link](https://github.com/zhenye234/xcodec)**|
|**2024-08-30**|**Recursive Attentive Pooling for Extracting Speaker Embeddings from Multi-Speaker Recordings**|Shota Horiguchi et.al.|[2408.17142](https://arxiv.org/abs/2408.17142)|null|
|**2024-08-30**|**Generative Modeling Perspective for Control and Reasoning in Robotics**|Takuma Yoneda et.al.|[2408.17041](https://arxiv.org/abs/2408.17041)|null|
|**2024-08-30**|**Utilizing Speaker Profiles for Impersonation Audio Detection**|Hao Gu et.al.|[2408.17009](https://arxiv.org/abs/2408.17009)|null|
|**2024-08-30**|**Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming**|Zhifei Xie et.al.|[2408.16725](https://arxiv.org/abs/2408.16725)|**[link](https://github.com/gpt-omni/mini-omni)**|
|**2024-08-29**|**CrisperWhisper: Accurate Timestamps on Verbatim Speech Transcriptions**|Laurin Wagner et.al.|[2408.16589](https://arxiv.org/abs/2408.16589)|**[link](https://github.com/nyrahealth/CrisperWhisper.)**|
|**2024-08-29**|**Human-Inspired Audio-Visual Speech Recognition: Spike Activity, Cueing Interaction and Causal Processing**|Qianhui Liu et.al.|[2408.16564](https://arxiv.org/abs/2408.16564)|null|
|**2024-08-29**|**RAVE for Speech: Efficient Voice Conversion at High Sampling Rates**|Anders R. Bargum et.al.|[2408.16546](https://arxiv.org/abs/2408.16546)|null|
|**2024-08-29**|**Enabling Beam Search for Language Model-Based Text-to-Speech Synthesis**|Zehai Tu et.al.|[2408.16373](https://arxiv.org/abs/2408.16373)|null|
|**2024-08-29**|**Measuring the Accuracy of Automatic Speech Recognition Solutions**|Korbinian Kuhn et.al.|[2408.16287](https://arxiv.org/abs/2408.16287)|**[link](https://github.com/shuffle-project/asr-comparison)**|
|**2024-08-29**|**Revisit Micro-batch Clipping: Adaptive Data Pruning via Gradient Manipulation**|Lun Wang et.al.|[2408.16204](https://arxiv.org/abs/2408.16204)|null|
|**2024-08-29**|**Benchmarking Japanese Speech Recognition on ASR-LLM Setups with Multi-Pass Augmented Generative Error Correction**|Yuka Ko et.al.|[2408.16180](https://arxiv.org/abs/2408.16180)|null|
|**2024-08-28**|**Spoofing-Robust Speaker Verification Using Parallel Embedding Fusion: BTU Speech Group's Approach for ASVspoof5 Challenge**|Oğuzhan Kurnaz et.al.|[2408.15877](https://arxiv.org/abs/2408.15877)|null|
|**2024-08-28**|**VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling**|Yixuan Zhou et.al.|[2408.15676](https://arxiv.org/abs/2408.15676)|**[link](https://github.com/thuhcsi/VoxInstruct.)**|
|**2024-08-28**|**Beyond Levenshtein: Leveraging Multiple Algorithms for Robust Word Error Rate Computations And Granular Error Classifications**|Korbinian Kuhn et.al.|[2408.15616](https://arxiv.org/abs/2408.15616)|**[link](https://github.com/shuffle-project/beyond-levenshtein)**|
|**2024-08-28**|**Whisper-PMFA: Partial Multi-Scale Feature Aggregation for Speaker Verification using Whisper Models**|Yiyang Zhao et.al.|[2408.15585](https://arxiv.org/abs/2408.15585)|null|
|**2024-08-28**|**EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models**|Wenhan Yao et.al.|[2408.15508](https://arxiv.org/abs/2408.15508)|null|
|**2024-08-27**|**Unlocking Potential in Pre-Trained Music Language Models for Versatile Multi-Track Music Arrangement**|Longshen Ou et.al.|[2408.15176](https://arxiv.org/abs/2408.15176)|null|
|**2024-08-27**|**Speech Recognition Transformers: Topological-lingualism Perspective**|Shruti Singh et.al.|[2408.14991](https://arxiv.org/abs/2408.14991)|null|
|**2024-08-27**|**Literary and Colloquial Dialect Identification for Tamil using Acoustic Features**|M. Nanmalar et.al.|[2408.14887](https://arxiv.org/abs/2408.14887)|null|
|**2024-08-27**|**The VoxCeleb Speaker Recognition Challenge: A Retrospective**|Jaesung Huh et.al.|[2408.14886](https://arxiv.org/abs/2408.14886)|null|
|**2024-08-27**|**MaskCycleGAN-based Whisper to Normal Speech Conversion**|K. Rohith Gupta et.al.|[2408.14797](https://arxiv.org/abs/2408.14797)|null|
|**2024-08-26**|**MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues**|Kuluhan Binici et.al.|[2408.14418](https://arxiv.org/abs/2408.14418)|null|
|**2024-08-26**|**Self-supervised Speech Representations Still Struggle with African American Vernacular English**|Kalvin Chang et.al.|[2408.14262](https://arxiv.org/abs/2408.14262)|**[link](https://github.com/cmu-llab/s3m-aave)**|
|**2024-08-26**|**Automatic recognition and detection of aphasic natural speech**|Mara Barberis et.al.|[2408.14082](https://arxiv.org/abs/2408.14082)|null|
|**2024-08-26**|**Research Advances and New Paradigms for Biology-inspired Spiking Neural Networks**|Tianyu Zheng et.al.|[2408.13996](https://arxiv.org/abs/2408.13996)|null|
|**2024-08-26**|**Anonymization of Voices in Spaces for Civic Dialogue: Measuring Impact on Empathy, Trust, and Feeling Heard**|Wonjune Kang et.al.|[2408.13970](https://arxiv.org/abs/2408.13970)|null|
|**2024-08-25**|**Literary and Colloquial Tamil Dialect Identification**|M. Nanmalar et.al.|[2408.13739](https://arxiv.org/abs/2408.13739)|null|
|**2024-08-24**|**Studying the Effect of Audio Filters in Pre-Trained Models for Environmental Sound Classification**|Aditya Dawn et.al.|[2408.13644](https://arxiv.org/abs/2408.13644)|null|
|**2024-08-24**|**As Biased as You Measure: Methodological Pitfalls of Bias Evaluations in Speaker Verification Research**|Wiebke Hutiri et.al.|[2408.13614](https://arxiv.org/abs/2408.13614)|null|
|**2024-08-24**|**SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description**|Zeyu Jin et.al.|[2408.13608](https://arxiv.org/abs/2408.13608)|**[link](https://github.com/thuhcsi/speechcraft)**|
|**2024-08-23**|**Toward Improving Synthetic Audio Spoofing Detection Robustness via Meta-Learning and Disentangled Training With Adversarial Examples**|Zhenyu Wang et.al.|[2408.13341](https://arxiv.org/abs/2408.13341)|null|
|**2024-08-23**|**Which Prosodic Features Matter Most for Pragmatics?**|Nigel G. Ward et.al.|[2408.13240](https://arxiv.org/abs/2408.13240)|null|
|**2024-08-23**|**NEST: Self-supervised Fast Conformer as All-purpose Seasoning to Speech Processing Tasks**|He Huang et.al.|[2408.13106](https://arxiv.org/abs/2408.13106)|null|
|**2024-08-23**|**Focused Discriminative Training For Streaming CTC-Trained Automatic Speech Recognition Models**|Adnan Haider et.al.|[2408.13008](https://arxiv.org/abs/2408.13008)|null|
|**2024-08-22**|**Towards measuring fairness in speech recognition: Fair-Speech dataset**|Irina-Elena Veliche et.al.|[2408.12734](https://arxiv.org/abs/2408.12734)|null|
|**2024-08-22**|**WhisperMask: A Noise Suppressive Mask-Type Microphone for Whisper Speech**|Hirotaka Hiraki et.al.|[2408.12500](https://arxiv.org/abs/2408.12500)|null|
|**2024-08-22**|**Positional Description for Numerical Normalization**|Deepanshu Gupta et.al.|[2408.12430](https://arxiv.org/abs/2408.12430)|null|
|**2024-08-22**|**LCM-SVC: Latent Diffusion Model Based Singing Voice Conversion with Inference Acceleration via Latent Consistency Distillation**|Shihao Chen et.al.|[2408.12354](https://arxiv.org/abs/2408.12354)|null|
|**2024-08-22**|**Developing vocal system impaired patient-aimed voice quality assessment approach using ASR representation-included multiple features**|Shaoxiang Dang et.al.|[2408.12279](https://arxiv.org/abs/2408.12279)|null|
|**2024-08-21**|**The State of Commercial Automatic French Legal Speech Recognition Systems and their Impact on Court Reporters et al**|Nicolad Garneau et.al.|[2408.11940](https://arxiv.org/abs/2408.11940)|null|
|**2024-08-21**|**Approaching Deep Learning through the Spectral Dynamics of Weights**|David Yunis et.al.|[2408.11804](https://arxiv.org/abs/2408.11804)|**[link](https://github.com/dyunis/spectral_dynamics)**|
|**2024-08-22**|**A Joint Noise Disentanglement and Adversarial Training Framework for Robust Speaker Verification**|Xujiang Xing et.al.|[2408.11562](https://arxiv.org/abs/2408.11562)|null|
|**2024-08-21**|**Improvement Speaker Similarity for Zero-Shot Any-to-Any Voice Conversion of Whispered and Regular Speech**|Anastasia Avdeeva et.al.|[2408.11528](https://arxiv.org/abs/2408.11528)|null|
|**2024-08-21**|**Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers**|Prashant Serai et.al.|[2408.11258](https://arxiv.org/abs/2408.11258)|null|
|**2024-08-20**|**BUT Systems and Analyses for the ASVspoof 5 Challenge**|Johan Rohdin et.al.|[2408.11152](https://arxiv.org/abs/2408.11152)|null|
|**2024-08-20**|**AI-Based IVR**|Gassyrbek Kosherbay et.al.|[2408.10549](https://arxiv.org/abs/2408.10549)|null|
|**2024-08-20**|**XCB: an effective contextual biasing approach to bias cross-lingual phrases in speech recognition**|Xucheng Wan et.al.|[2408.10524](https://arxiv.org/abs/2408.10524)|null|
|**2024-08-19**|**ASASVIcomtech: The Vicomtech-UGR Speech Deepfake Detection and SASV Systems for the ASVspoof5 Challenge**|Juan M. Martín-Doñas et.al.|[2408.10361](https://arxiv.org/abs/2408.10361)|null|
|**2024-08-19**|**Hear Your Face: Face-based voice conversion with F0 estimation**|Jaejun Lee et.al.|[2408.09802](https://arxiv.org/abs/2408.09802)|null|
|**2024-08-19**|**Unsupervised Composable Representations for Audio**|Giovanni Bindi et.al.|[2408.09792](https://arxiv.org/abs/2408.09792)|null|
|**2024-08-19**|**Recording for Eyes, Not Echoing to Ears: Contextualized Spoken-to-Written Conversion of ASR Transcripts**|Jiaqing Liu et.al.|[2408.09688](https://arxiv.org/abs/2408.09688)|null|
|**2024-08-18**|**A Transcription Prompt-based Efficient Audio Large Language Model for Robust Speech Recognition**|Yangze Li et.al.|[2408.09491](https://arxiv.org/abs/2408.09491)|null|
|**2024-08-17**|**Malacopula: adversarial automatic speaker verification attacks using a neural-based generalised Hammerstein model**|Massimiliano Todisco et.al.|[2408.09300](https://arxiv.org/abs/2408.09300)|null|
|**2024-08-17**|**Generating Data with Text-to-Speech and Large-Language Models for Conversational Speech Recognition**|Samuele Cornell et.al.|[2408.09215](https://arxiv.org/abs/2408.09215)|null|
|**2024-08-14**|**Supervised and Unsupervised Alignments for Spoofing Behavioral Biometrics**|Thomas Thebaud et.al.|[2408.08918](https://arxiv.org/abs/2408.08918)|null|
|**2024-08-16**|**ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale**|Xin Wang et.al.|[2408.08739](https://arxiv.org/abs/2408.08739)|null|
|**2024-08-15**|**Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words**|Kento Nozawa et.al.|[2408.08027](https://arxiv.org/abs/2408.08027)|null|
|**2024-08-14**|**SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition**|Mohamed Osman et.al.|[2408.07851](https://arxiv.org/abs/2408.07851)|**[link](https://github.com/spaghettiSystems/serval)**|
|**2024-08-14**|**WavLM model ensemble for audio deepfake detection**|David Combei et.al.|[2408.07414](https://arxiv.org/abs/2408.07414)|null|
|**2024-08-14**|**DPSNN: Spiking Neural Network for Low-Latency Streaming Speech Enhancement**|Tao Sun et.al.|[2408.07388](https://arxiv.org/abs/2408.07388)|null|
|**2024-08-13**|**Play Me Something Icy: Practical Challenges, Explainability and the Semantic Gap in Generative AI Music**|Jesse Allison et.al.|[2408.07224](https://arxiv.org/abs/2408.07224)|null|
|**2024-08-13**|**VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders**|Yubing Cao et.al.|[2408.06906](https://arxiv.org/abs/2408.06906)|null|
|**2024-08-13**|**SaSLaW: Dialogue Speech Corpus with Audio-visual Egocentric Information Toward Environment-adaptive Dialogue Speech Synthesis**|Osamu Take et.al.|[2408.06858](https://arxiv.org/abs/2408.06858)|**[link](https://github.com/sarulab-speech/saslaw)**|
|**2024-08-13**|**PRESENT: Zero-Shot Text-to-Prosody Control**|Perry Lam et.al.|[2408.06827](https://arxiv.org/abs/2408.06827)|**[link](https://github.com/iamanigeeit/present)**|
|**2024-08-13**|**Deep Learning for Speaker Identification: Architectural Insights from AB-1 Corpus Analysis and Performance Evaluation**|Matthias Bartolo et.al.|[2408.06804](https://arxiv.org/abs/2408.06804)|**[link](https://github.com/mbar0075/speech-technology)**|
|**2024-08-12**|**Cross-Lingual Conversational Speech Summarization with Large Language Models**|Max Nelson et.al.|[2408.06484](https://arxiv.org/abs/2408.06484)|null|
|**2024-08-12**|**Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance**|Manuel Milling et.al.|[2408.06264](https://arxiv.org/abs/2408.06264)|null|
|**2024-08-12**|**Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning**|Wonjun Lee et.al.|[2408.06043](https://arxiv.org/abs/2408.06043)|null|
|**2024-08-12**|**Controlling Surprisal in Music Generation via Information Content Curve Matching**|Mathias Rose Bjare et.al.|[2408.06022](https://arxiv.org/abs/2408.06022)|**[link](https://github.com/muthissar/iic)**|
|**2024-08-11**|**LI-TTA: Language Informed Test-Time Adaptation for Automatic Speech Recognition**|Eunseop Yoon et.al.|[2408.05769](https://arxiv.org/abs/2408.05769)|null|
|**2024-08-11**|**VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing**|Chunyu Qiang et.al.|[2408.05758](https://arxiv.org/abs/2408.05758)|null|
|**2024-08-10**|**Improving Whisper's Recognition Performance for Under-Represented Language Kazakh Leveraging Unpaired Speech and Text**|Jinpeng Li et.al.|[2408.05554](https://arxiv.org/abs/2408.05554)|null|
|**2024-08-09**|**MooER: LLM-based Speech Recognition and Translation Models from Moore Threads**|Junhao Xu et.al.|[2408.05101](https://arxiv.org/abs/2408.05101)|null|
|**2024-08-09**|**TEAdapter: Supply abundant guidance for controllable text-to-music generation**|Jialing Zou et.al.|[2408.04865](https://arxiv.org/abs/2408.04865)|null|
|**2024-08-08**|**MulliVC: Multi-lingual Voice Conversion With Cycle Consistency**|Jiawei Huang et.al.|[2408.04708](https://arxiv.org/abs/2408.04708)|null|
|**2024-08-08**|**NeuralMultiling: A Novel Neural Architecture Search for Smartphone based Multilingual Speaker Verification**|Aravinda Reddy PN et.al.|[2408.04362](https://arxiv.org/abs/2408.04362)|null|
|**2024-08-08**|**HydraFormer: One Encoder For All Subsampling Rates**|Yaoxun Xu et.al.|[2408.04325](https://arxiv.org/abs/2408.04325)|**[link](https://github.com/hydraformer/hydraformer)**|
|**2024-08-08**|**Preserving spoken content in voice anonymisation with character-level vocoder conditioning**|Michele Panariello et.al.|[2408.04306](https://arxiv.org/abs/2408.04306)|null|
|**2024-08-08**|**wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**|Khai Le-Duc et.al.|[2408.04174](https://arxiv.org/abs/2408.04174)|null|
|**2024-08-07**|**Speaker Adaptation for Quantised End-to-End ASR Models**|Qiuming Zhao et.al.|[2408.03979](https://arxiv.org/abs/2408.03979)|null|
|**2024-08-06**|**Central Kurdish Text-to-Speech Synthesis with Novel End-to-End Transformer Training**|Hawraz A. Ahmad et.al.|[2408.03887](https://arxiv.org/abs/2408.03887)|null|
|**2024-08-07**|**Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation**|Karn N. Watcharasupat et.al.|[2408.03588](https://arxiv.org/abs/2408.03588)|null|
|**2024-08-06**|**ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval**|Ruixiang Zhao et.al.|[2408.02978](https://arxiv.org/abs/2408.02978)|null|
|**2024-08-06**|**Self-Supervised Learning for Multi-Channel Neural Transducer**|Atsushi Kojima et.al.|[2408.02945](https://arxiv.org/abs/2408.02945)|null|
|**2024-08-05**|**Automatic Voice Identification after Speech Resynthesis using PPG**|Thibault Gaudier et.al.|[2408.02712](https://arxiv.org/abs/2408.02712)|null|
|**2024-08-05**|**Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition**|Jaeyoung Kim et.al.|[2408.02582](https://arxiv.org/abs/2408.02582)|null|
|**2024-08-05**|**The NPU-ASLP System Description for Visual Speech Recognition in CNVSRC 2024**|He Wang et.al.|[2408.02369](https://arxiv.org/abs/2408.02369)|null|
|**2024-08-05**|**StreamVoice+: Evolving into End-to-end Streaming Zero-shot Voice Conversion**|Zhichao Wang et.al.|[2408.02178](https://arxiv.org/abs/2408.02178)|null|
|**2024-08-04**|**Why Perturbing Symbolic Music is Necessary: Fitting the Distribution of Never-used Notes through a Joint Probabilistic Diffusion Model**|Shipei Liu et.al.|[2408.01950](https://arxiv.org/abs/2408.01950)|null|
|**2024-08-03**|**ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features**|Peng Cheng et.al.|[2408.01808](https://arxiv.org/abs/2408.01808)|null|
|**2024-08-03**|**Generating High-quality Symbolic Music Using Fine-grained Discriminators**|Zhedong Zhang et.al.|[2408.01696](https://arxiv.org/abs/2408.01696)|null|
|**2024-08-02**|**EmoBack: Backdoor Attacks Against Speaker Identification Using Emotional Prosody**|Coen Schoof et.al.|[2408.01178](https://arxiv.org/abs/2408.01178)|null|
|**2024-08-01**|**Expressive MIDI-format Piano Performance Generation**|Jingwei Liu et.al.|[2408.00900](https://arxiv.org/abs/2408.00900)|null|
|**2024-08-01**|**SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data**|Yichen Lu et.al.|[2408.00624](https://arxiv.org/abs/2408.00624)|null|
|**2024-08-01**|**Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation**|Xinhan Di et.al.|[2408.00284](https://arxiv.org/abs/2408.00284)|null|
|**2024-08-01**|**Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation**|Kohei Matsuura et.al.|[2408.00205](https://arxiv.org/abs/2408.00205)|null|
|**2024-07-31**|**Combining audio control and style transfer using latent diffusion**|Nils Demerlé et.al.|[2408.00196](https://arxiv.org/abs/2408.00196)|null|
|**2024-07-31**|**The Llama 3 Herd of Models**|Abhimanyu Dubey et.al.|[2407.21783](https://arxiv.org/abs/2407.21783)|null|
|**2024-07-31**|**Between the AI and Me: Analysing Listeners' Perspectives on AI- and Human-Composed Progressive Metal Music**|Pedro Sarmento et.al.|[2407.21615](https://arxiv.org/abs/2407.21615)|null|
|**2024-08-01**|**Generative Expressive Conversational Speech Synthesis**|Rui Liu et.al.|[2407.21491](https://arxiv.org/abs/2407.21491)|null|
|**2024-07-31**|**On the Problem of Text-To-Speech Model Selection for Synthetic Data Generation in Automatic Speech Recognition**|Nick Rossenbach et.al.|[2407.21476](https://arxiv.org/abs/2407.21476)|null|
|**2024-07-31**|**Towards interfacing large language models with ASR systems using confidence measures and prompting**|Maryam Naderi et.al.|[2407.21414](https://arxiv.org/abs/2407.21414)|null|
|**2024-07-30**|**Self-Supervised Models in Automatic Whispered Speech Recognition**|Aref Farhadipour et.al.|[2407.21211](https://arxiv.org/abs/2407.21211)|null|
|**2024-07-28**|**ELP-Adapters: Parameter Efficient Adapter Tuning for Various Speech Processing Tasks**|Nakamasa Inoue et.al.|[2407.21066](https://arxiv.org/abs/2407.21066)|null|
|**2024-07-30**|**Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation**|Jingyue Huang et.al.|[2407.20955](https://arxiv.org/abs/2407.20955)|**[link](https://github.com/yuer867/emo-disentanger)**|
|**2024-07-29**|**Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation**|Junda Wu et.al.|[2407.20445](https://arxiv.org/abs/2407.20445)|null|
|**2024-07-29**|**Practical and Reproducible Symbolic Music Generation by Large Language Models with Structural Embeddings**|Seungyeon Rhyu et.al.|[2407.19900](https://arxiv.org/abs/2407.19900)|null|
|**2024-07-26**|**Dynamic Language Group-Based MoE: Enhancing Efficiency and Flexibility for Code-Switching Speech Recognition**|Hukai Huang et.al.|[2407.18581](https://arxiv.org/abs/2407.18581)|null|
|**2024-07-29**|**Speech Bandwidth Expansion Via High Fidelity Generative Adversarial Networks**|Mahmoud Salhab et.al.|[2407.18571](https://arxiv.org/abs/2407.18571)|null|
|**2024-07-26**|**Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models**|Neil Shah et.al.|[2407.18541](https://arxiv.org/abs/2407.18541)|null|
|**2024-07-26**|**VoxSim: A perceptual voice similarity dataset**|Junseok Ahn et.al.|[2407.18505](https://arxiv.org/abs/2407.18505)|null|
|**2024-07-26**|**Enhancing Dysarthric Speech Recognition for Unseen Speakers via Prototype-Based Adaptation**|Shiyao Wang et.al.|[2407.18461](https://arxiv.org/abs/2407.18461)|**[link](https://github.com/nku-hlt/pb-dsr)**|
|**2024-07-25**|**On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**|Nick Rossenbach et.al.|[2407.17997](https://arxiv.org/abs/2407.17997)|null|
|**2024-07-25**|**Multi-Stage Face-Voice Association Learning with Keynote Speaker Diarization**|Ruijie Tao et.al.|[2407.17902](https://arxiv.org/abs/2407.17902)|**[link](https://github.com/taoruijie/mfv-ksd)**|
|**2024-07-25**|**Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions**|Jiwon Suh et.al.|[2407.17874](https://arxiv.org/abs/2407.17874)|null|
|**2024-07-25**|**Scaling A Simple Approach to Zero-Shot Speech Recognition**|Jinming Zhao et.al.|[2407.17852](https://arxiv.org/abs/2407.17852)|**[link](https://github.com/facebookresearch/fairseq)**|
|**2024-07-24**|**Coupling Speech Encoders with Downstream Text Models**|Ciprian Chelba et.al.|[2407.17605](https://arxiv.org/abs/2407.17605)|null|
|**2024-07-24**|**A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives**|Jan Lehečka et.al.|[2407.17160](https://arxiv.org/abs/2407.17160)|null|
|**2024-07-24**|**Long-Term, Store-Front Robotics: Interactive Music for Robotic Arm, Caxixi and Frame Drums**|Richard Savery et.al.|[2407.16956](https://arxiv.org/abs/2407.16956)|null|
|**2024-07-23**|**Quantifying the Role of Textual Predictability in Automatic Speech Recognition**|Sean Robertson et.al.|[2407.16537](https://arxiv.org/abs/2407.16537)|null|
|**2024-07-23**|**The CHiME-8 DASR Challenge for Generalizable and Array Agnostic Distant Automatic Speech Recognition and Diarization**|Samuele Cornell et.al.|[2407.16447](https://arxiv.org/abs/2407.16447)|null|
|**2024-07-23**|**Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction**|Rithik Sachdev et.al.|[2407.16370](https://arxiv.org/abs/2407.16370)|**[link](https://github.com/rithiksachdev/PostASR-Correction-SLT2024)**|
|**2024-07-22**|**dMel: Speech Tokenization made Simple**|He Bai et.al.|[2407.15835](https://arxiv.org/abs/2407.15835)|null|
|**2024-07-22**|**Robustness of Speech Separation Models for Similar-pitch Speakers**|Bunlong Lay et.al.|[2407.15749](https://arxiv.org/abs/2407.15749)|null|
|**2024-07-22**|**SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios**|Hazim Bukhari et.al.|[2407.15300](https://arxiv.org/abs/2407.15300)|null|
|**2024-07-21**|**Overview of Speaker Modeling and Its Applications: From the Lens of Deep Speaker Representation Learning**|Shuai Wang et.al.|[2407.15188](https://arxiv.org/abs/2407.15188)|null|
|**2024-07-21**|**MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music Generation**|Yun-Han Lan et.al.|[2407.15060](https://arxiv.org/abs/2407.15060)|null|
|**2024-07-20**|**Towards Realistic Emotional Voice Conversion using Controllable Emotional Intensity**|Tianhua Qi et.al.|[2407.14800](https://arxiv.org/abs/2407.14800)|null|
|**2024-07-21**|**Trading Devil Final: Backdoor attack via Stock market and Bayesian Optimization**|Orson Mengara et.al.|[2407.14573](https://arxiv.org/abs/2407.14573)|null|
|**2024-07-19**|**Towards Assessing Data Replication in Music Generation with Music Similarity Metrics on Raw Audio**|Roser Batlle-Roca et.al.|[2407.14364](https://arxiv.org/abs/2407.14364)|**[link](https://github.com/roserbatlleroca/mira)**|
|**2024-07-19**|**Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings**|Praveen Srinivasa Varadhan et.al.|[2407.14056](https://arxiv.org/abs/2407.14056)|**[link](https://github.com/AI4Bharat/Rasa)**|
|**2024-07-19**|**GE2E-AC: Generalized End-to-End Loss Training for Accent Classification**|Chihiro Watanabe et.al.|[2407.14021](https://arxiv.org/abs/2407.14021)|null|
|**2024-07-19**|**MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech Synthesis**|Qian Yang et.al.|[2407.14006](https://arxiv.org/abs/2407.14006)|null|
|**2024-07-19**|**Reexamining Racial Disparities in Automatic Speech Recognition Performance: The Role of Confounding by Provenance**|Changye Li et.al.|[2407.13982](https://arxiv.org/abs/2407.13982)|**[link](https://github.com/LinguisticAnomalies/confounding-ASR)**|
|**2024-07-18**|**Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models**|Weiqin Li et.al.|[2407.13509](https://arxiv.org/abs/2407.13509)|null|
|**2024-07-18**|**Reducing Barriers to the Use of Marginalised Music Genres in AI**|Nick Bryan-Kinns et.al.|[2407.13439](https://arxiv.org/abs/2407.13439)|null|
|**2024-07-18**|**Robust ASR Error Correction with Conservative Data Filtering**|Takuma Udagawa et.al.|[2407.13300](https://arxiv.org/abs/2407.13300)|null|
|**2024-07-18**|**Low-Resourced Speech Recognition for Iu Mien Language via Weakly-Supervised Phoneme-based Multilingual Pre-training**|Lukuan Dong et.al.|[2407.13292](https://arxiv.org/abs/2407.13292)|null|
|**2024-07-18**|**How Private is Low-Frequency Speech Audio in the Wild? An Analysis of Verbal Intelligibility by Humans and Machines**|Ailin Liu et.al.|[2407.13266](https://arxiv.org/abs/2407.13266)|null|
|**2024-07-18**|**A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR**|Jian You et.al.|[2407.13142](https://arxiv.org/abs/2407.13142)|null|
|**2024-07-17**|**Audio Conditioning for Music Generation via Discrete Bottleneck Features**|Simon Rouard et.al.|[2407.12563](https://arxiv.org/abs/2407.12563)|null|
|**2024-07-17**|**Morphosyntactic Analysis for CHILDES**|Houjun Liu et.al.|[2407.12389](https://arxiv.org/abs/2407.12389)|null|
|**2024-07-17**|**Adaptive Cascading Network for Continual Test-Time Adaptation**|Kien X. Nguyen et.al.|[2407.12240](https://arxiv.org/abs/2407.12240)|null|
|**2024-07-16**|**Identifying Speakers in Dialogue Transcripts: A Text-based Approach Using Pretrained Language Models**|Minh Nguyen et.al.|[2407.12094](https://arxiv.org/abs/2407.12094)|**[link](https://github.com/adobe-research/speaker-identification)**|
|**2024-07-17**|**Vibravox: A Dataset of French Speech Captured with Body-conduction Audio Sensors**|Julien Hauret et.al.|[2407.11828](https://arxiv.org/abs/2407.11828)|**[link](https://github.com/jhauret/vibravox)**|
|**2024-07-16**|**Investigating the Effect of Label Topology and Training Criterion on ASR Performance and Alignment Quality**|Tina Raissi et.al.|[2407.11641](https://arxiv.org/abs/2407.11641)|null|
|**2024-07-16**|**The VoicePrivacy 2022 Challenge: Progress and Perspectives in Voice Anonymisation**|Michele Panariello et.al.|[2407.11516](https://arxiv.org/abs/2407.11516)|null|
|**2024-07-16**|**VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark**|Yuke Lin et.al.|[2407.11510](https://arxiv.org/abs/2407.11510)|null|
|**2024-07-16**|**Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models**|Matthew Perez et.al.|[2407.11345](https://arxiv.org/abs/2407.11345)|null|
|**2024-07-15**|**Leave No Knowledge Behind During Knowledge Distillation: Towards Practical and Effective Knowledge Distillation for Code-Switching ASR Using Realistic Data**|Liang-Hsuan Tseng et.al.|[2407.10603](https://arxiv.org/abs/2407.10603)|null|
|**2024-07-15**|**BandControlNet: Parallel Transformers-based Steerable Popular Music Generation with Fine-Grained Spatiotemporal Features**|Jing Luo et.al.|[2407.10462](https://arxiv.org/abs/2407.10462)|**[link](https://github.com/Chinglohsiu/BandCondiNet)**|
|**2024-07-14**|**The Interpretation Gap in Text-to-Music Generation Models**|Yongyi Zang et.al.|[2407.10328](https://arxiv.org/abs/2407.10328)|null|
|**2024-07-14**|**Improving Neural Biasing for Contextual Speech Recognition by Early Context Injection and Text Perturbation**|Ruizhe Huang et.al.|[2407.10303](https://arxiv.org/abs/2407.10303)|null|
|**2024-07-14**|**CUSIDE-T: Chunking, Simulating Future and Decoding for Transducer based Streaming ASR**|Wenbo Zhao et.al.|[2407.10255](https://arxiv.org/abs/2407.10255)|null|
|**2024-07-14**|**Textless Dependency Parsing by Labeled Sequence Prediction**|Shunsuke Kando et.al.|[2407.10118](https://arxiv.org/abs/2407.10118)|**[link](https://github.com/mynlp/speechparser)**|
|**2024-07-14**|**Whisper-SV: Adapting Whisper for Low-data-resource Speaker Verification**|Li Zhang et.al.|[2407.10048](https://arxiv.org/abs/2407.10048)|null|
|**2024-07-13**|**Text-Based Detection of On-Hold Scripts in Contact Center Calls**|Dmitrii Galimzianov et.al.|[2407.09849](https://arxiv.org/abs/2407.09849)|**[link](https://github.com/gal-dmitry/HOLD_DETECTION_PUBLIC)**|
|**2024-07-13**|**Empowering Whisper as a Joint Multi-Talker and Target-Talker Speech Recognition System**|Lingwei Meng et.al.|[2407.09817](https://arxiv.org/abs/2407.09817)|null|
|**2024-07-13**|**A Streaming Multi-Channel End-to-End Speech Recognition System with Realistic Evaluations**|Xiangzhu Kong et.al.|[2407.09807](https://arxiv.org/abs/2407.09807)|null|
|**2024-07-12**|**Music Proofreading with RefinPaint: Where and How to Modify Compositions given Context**|Pedro Ramoneda et.al.|[2407.09099](https://arxiv.org/abs/2407.09099)|**[link](https://github.com/ta603/refinpaint)**|
|**2024-07-12**|**Optimization of DNN-based speaker verification model through efficient quantization technique**|Yeona Hong et.al.|[2407.08991](https://arxiv.org/abs/2407.08991)|null|
|**2024-07-10**|**Evaluating Voice Command Pipelines for Drone Control: From STT and LLM to Direct Classification and Siamese Networks**|Lucca Emmanuel Pineli Simões et.al.|[2407.08658](https://arxiv.org/abs/2407.08658)|null|
|**2024-07-11**|**Tamil Language Computing: the Present and the Future**|Kengatharaiyer Sarveswaran et.al.|[2407.08618](https://arxiv.org/abs/2407.08618)|null|
|**2024-07-11**|**Autoregressive Speech Synthesis without Vector Quantization**|Lingwei Meng et.al.|[2407.08551](https://arxiv.org/abs/2407.08551)|null|
|**2024-07-11**|**Toward accessible comics for blind and low vision readers**|Christophe Rigaud et.al.|[2407.08248](https://arxiv.org/abs/2407.08248)|null|
|**2024-07-10**|**Phonetic Richness for Improved Automatic Speaker Verification**|Nicholas Klein et.al.|[2407.08017](https://arxiv.org/abs/2407.08017)|null|
|**2024-07-10**|**Source Tracing of Audio Deepfake Systems**|Nicholas Klein et.al.|[2407.08016](https://arxiv.org/abs/2407.08016)|null|
|**2024-07-11**|**SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis**|Zihao Wang et.al.|[2407.07728](https://arxiv.org/abs/2407.07728)|**[link](https://github.com/carlwangchina/samoye-svc)**|
|**2024-07-10**|**HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing**|Arnon Turetzky et.al.|[2407.07566](https://arxiv.org/abs/2407.07566)|null|
|**2024-07-09**|**Remastering Divide and Remaster: A Cinematic Audio Source Separation Dataset with Multilingual Support**|Karn N. Watcharasupat et.al.|[2407.07275](https://arxiv.org/abs/2407.07275)|null|
|**2024-07-09**|**Speech After Gender: A Trans-Feminine Perspective on Next Steps for Speech Science and Technology**|Robin Netzorg et.al.|[2407.07235](https://arxiv.org/abs/2407.07235)|null|
|**2024-07-09**|**Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models**|Yi-Cheng Lin et.al.|[2407.06957](https://arxiv.org/abs/2407.06957)|**[link](https://github.com/dlion168/Listen-and-Speak-Fairly)**|
|**2024-07-09**|**Tailored Design of Audio-Visual Speech Recognition Models using Branchformers**|David Gimeno-Gómez et.al.|[2407.06606](https://arxiv.org/abs/2407.06606)|**[link](https://github.com/david-gimeno/tailored-avsr)**|
|**2024-07-08**|**Homogeneous Speaker Features for On-the-Fly Dysarthric and Elderly Speaker Adaptation**|Mengzhe Geng et.al.|[2407.06310](https://arxiv.org/abs/2407.06310)|null|
|**2024-07-08**|**Two-Path GMM-ResNet and GMM-SENet for ASV Spoofing Detection**|Zhenchun Lei et.al.|[2407.05605](https://arxiv.org/abs/2407.05605)|null|
|**2024-07-07**|**Differentiable Modal Synthesis for Physical Modeling of Planar String Sound and Motion Simulation**|Jin Woo Lee et.al.|[2407.05516](https://arxiv.org/abs/2407.05516)|null|
|**2024-07-07**|**Fine-Grained and Interpretable Neural Speech Editing**|Max Morrison et.al.|[2407.05471](https://arxiv.org/abs/2407.05471)|null|
|**2024-07-09**|**CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens**|Zhihao Du et.al.|[2407.05407](https://arxiv.org/abs/2407.05407)|null|
|**2024-07-06**|**A Reference-free Metric for Language-Queried Audio Source Separation using Contrastive Language-Audio Pretraining**|Feiyang Xiao et.al.|[2407.04936](https://arxiv.org/abs/2407.04936)|null|
|**2024-07-05**|**MUSIC-lite: Efficient MUSIC using Approximate Computing: An OFDM Radar Case Study**|Rajat Bhattacharjya et.al.|[2407.04849](https://arxiv.org/abs/2407.04849)|null|
|**2024-07-05**|**Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition**|Ye Bai et.al.|[2407.04675](https://arxiv.org/abs/2407.04675)|null|
|**2024-07-05**|**Multitaper mel-spectrograms for keyword spotting**|Douglas Baptista de Souza et.al.|[2407.04662](https://arxiv.org/abs/2407.04662)|null|
|**2024-07-05**|**Pretraining End-to-End Keyword Search with Automatically Discovered Acoustic Units**|Bolaji Yusuf et.al.|[2407.04652](https://arxiv.org/abs/2407.04652)|**[link](https://github.com/beer-asr/beer)**|
|**2024-07-05**|**Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models**|Bolaji Yusuf et.al.|[2407.04641](https://arxiv.org/abs/2407.04641)|null|
|**2024-07-05**|**Written Term Detection Improves Spoken Term Detection**|Bolaji Yusuf et.al.|[2407.04601](https://arxiv.org/abs/2407.04601)|**[link](https://github.com/bolajiy/golden-retriever)**|
|**2024-07-05**|**FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-based Vocoder**|Rubing Shen et.al.|[2407.04575](https://arxiv.org/abs/2407.04575)|null|
|**2024-07-05**|**Performance Analysis of Speech Encoders for Low-Resource SLU and ASR in Tunisian Dialect**|Salima Mdhaffar et.al.|[2407.04533](https://arxiv.org/abs/2407.04533)|null|
|**2024-07-05**|**Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models**|Vyas Raina et.al.|[2407.04482](https://arxiv.org/abs/2407.04482)|null|
|**2024-07-05**|**XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models**|Shashi Kumar et.al.|[2407.04439](https://arxiv.org/abs/2407.04439)|null|
|**2024-07-05**|**Romanization Encoding For Multilingual ASR**|Wen Ding et.al.|[2407.04368](https://arxiv.org/abs/2407.04368)|null|
|**2024-07-03**|**GMM-ResNext: Combining Generative and Discriminative Models for Speaker Verification**|Hui Yan et.al.|[2407.03135](https://arxiv.org/abs/2407.03135)|null|
|**2024-07-03**|**Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition**|Jinming Chen et.al.|[2407.03026](https://arxiv.org/abs/2407.03026)|null|
|**2024-07-03**|**Probing the Feasibility of Multilingual Speaker Anonymization**|Sarina Meyer et.al.|[2407.02937](https://arxiv.org/abs/2407.02937)|**[link](https://github.com/digitalphonetics/speaker-anonymization)**|
|**2024-07-02**|**Towards the Next Frontier in Speech Representation Learning Using Disentanglement**|Varun Krishna et.al.|[2407.02543](https://arxiv.org/abs/2407.02543)|null|
|**2024-07-02**|**Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference Optimization**|Yuchen Hu et.al.|[2407.02243](https://arxiv.org/abs/2407.02243)|null|
|**2024-07-02**|**The USTC-NERCSLIP Systems for The ICMC-ASR Challenge**|Minghui Wu et.al.|[2407.02052](https://arxiv.org/abs/2407.02052)|null|
|**2024-07-02**|**Accompanied Singing Voice Synthesis with Fully Text-controlled Melody**|Ruiqi Li et.al.|[2407.02049](https://arxiv.org/abs/2407.02049)|null|
|**2024-07-02**|**Pinyin Regularization in Error Correction for Chinese Speech Recognition with Large Language Models**|Zhiyuan Tang et.al.|[2407.01909](https://arxiv.org/abs/2407.01909)|**[link](https://github.com/tzyll/ChineseHP)**|
|**2024-07-01**|**Pictures Of MIDI: Controlled Music Generation via Graphical Prompts for Image-Based Diffusion Inpainting**|Scott H. Hawley et.al.|[2407.01499](https://arxiv.org/abs/2407.01499)|null|
|**2024-07-01**|**Lightweight Zero-shot Text-to-Speech with Mixture of Adapters**|Kenichi Fujita et.al.|[2407.01291](https://arxiv.org/abs/2407.01291)|null|
|**2024-06-30**|**An Attribute Interpolation Method in Speech Synthesis by Model Merging**|Masato Murata et.al.|[2407.00766](https://arxiv.org/abs/2407.00766)|null|
|**2024-06-30**|**Less Forgetting for Better Generalization: Exploring Continual-learning Fine-tuning Methods for Speech Self-supervised Representations**|Salah Zaiem et.al.|[2407.00756](https://arxiv.org/abs/2407.00756)|null|
|**2024-06-30**|**FLY-TTS: Fast, Lightweight and High-Quality End-to-End Text-to-Speech Synthesis**|Yinlin Guo et.al.|[2407.00753](https://arxiv.org/abs/2407.00753)|null|
|**2024-06-29**|**When Robots Get Chatty: Grounding Multimodal Human-Robot Conversation and Collaboration**|Philipp Allgeuer et.al.|[2407.00518](https://arxiv.org/abs/2407.00518)|null|
|**2024-06-28**|**SAML: Speaker Adaptive Mixture of LoRA Experts for End-to-End ASR**|Qiuming Zhao et.al.|[2406.19706](https://arxiv.org/abs/2406.19706)|null|
|**2024-06-28**|**Less is More: Accurate Speech Recognition & Translation without Web-Scale Data**|Krishna C. Puvvada et.al.|[2406.19674](https://arxiv.org/abs/2406.19674)|null|
|**2024-06-27**|**Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects**|Orevaoghene Ahia et.al.|[2406.19564](https://arxiv.org/abs/2406.19564)|null|
|**2024-06-27**|**Tradition or Innovation: A Comparison of Modern ASR Methods for Forced Alignment**|Rotem Rousso et.al.|[2406.19363](https://arxiv.org/abs/2406.19363)|null|
|**2024-06-27**|**Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems**|Zheng Fang et.al.|[2406.19311](https://arxiv.org/abs/2406.19311)|null|
|**2024-06-27**|**Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models**|Borodin Kirill Nikolayevich et.al.|[2406.19243](https://arxiv.org/abs/2406.19243)|null|
|**2024-06-27**|**DEX-TTS: Diffusion-based EXpressive Text-to-Speech with Style Modeling on Time Variability**|Hyun Joon Park et.al.|[2406.19135](https://arxiv.org/abs/2406.19135)|**[link](https://github.com/winddori2002/dex-tts)**|
|**2024-06-27**|**Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over**|Atsunori Ogawa et.al.|[2406.18972](https://arxiv.org/abs/2406.18972)|null|
|**2024-06-27**|**Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network**|Yehoshua Dissen et.al.|[2406.18928](https://arxiv.org/abs/2406.18928)|null|
|**2024-06-27**|**Streaming Decoder-Only Automatic Speech Recognition with Discrete Speech Units: A Pilot Study**|Peikun Chen et.al.|[2406.18862](https://arxiv.org/abs/2406.18862)|null|
|**2024-06-26**|**A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond Four Stems**|Karn N. Watcharasupat et.al.|[2406.18747](https://arxiv.org/abs/2406.18747)|**[link](https://github.com/kwatcharasupat/query-bandit)**|
|**2024-06-26**|**Dynamic Data Pruning for Automatic Speech Recognition**|Qiao Xiao et.al.|[2406.18373](https://arxiv.org/abs/2406.18373)|null|
|**2024-06-26**|**MSR-86K: An Evolving, Multilingual Corpus with 86,300 Hours of Transcribed Audio for Speech Recognition Research**|Song Li et.al.|[2406.18301](https://arxiv.org/abs/2406.18301)|null|
|**2024-06-26**|**Automatic Speech Recognition for Hindi**|Anish Saha et.al.|[2406.18135](https://arxiv.org/abs/2406.18135)|null|
|**2024-06-26**|**ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs**|Ahmed Heakl et.al.|[2406.18120](https://arxiv.org/abs/2406.18120)|**[link](https://github.com/ahmedheakl/arazn-llm)**|
|**2024-06-26**|**SC-MoE: Switch Conformer Mixture of Experts for Unified Streaming and Non-streaming Code-Switching ASR**|Shuaishuai Ye et.al.|[2406.18021](https://arxiv.org/abs/2406.18021)|null|
|**2024-06-25**|**Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment**|Paarth Neekhara et.al.|[2406.17957](https://arxiv.org/abs/2406.17957)|null|
|**2024-06-25**|**Sequential Editing for Lifelong Training of Speech Recognition Models**|Devang Kulshreshtha et.al.|[2406.17935](https://arxiv.org/abs/2406.17935)|null|
|**2024-06-25**|**FASA: a Flexible and Automatic Speech Aligner for Extracting High-quality Aligned Children Speech Data**|Dancheng Liu et.al.|[2406.17926](https://arxiv.org/abs/2406.17926)|**[link](https://github.com/DanchengLiu/FASA)**|
|**2024-06-25**|**Spatial Voice Conversion: Voice Conversion Preserving Spatial Information and Non-target Signals**|Kentaro Seki et.al.|[2406.17722](https://arxiv.org/abs/2406.17722)|null|
|**2024-06-25**|**Towards Building an End-to-End Multilingual Automatic Lyrics Transcription Model**|Jiawen Huang et.al.|[2406.17618](https://arxiv.org/abs/2406.17618)|**[link](https://github.com/jhuang448/MultilingualALT)**|
|**2024-06-25**|**MSRS: Training Multimodal Speech Recognition Models from Scratch with Sparse Mask Optimization**|Adriana Fernandez-Lopez et.al.|[2406.17614](https://arxiv.org/abs/2406.17614)|null|
|**2024-06-25**|**High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model**|Joun Yeop Lee et.al.|[2406.17310](https://arxiv.org/abs/2406.17310)|null|
|**2024-06-25**|**A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR**|Van Tung Pham et.al.|[2406.17272](https://arxiv.org/abs/2406.17272)|null|
|**2024-06-25**|**Leveraging Parameter-Efficient Transfer Learning for Multi-Lingual Text-to-Speech Adaptation**|Yingting Li et.al.|[2406.17257](https://arxiv.org/abs/2406.17257)|null|
|**2024-06-24**|**Investigating Confidence Estimation Measures for Speaker Diarization**|Anurag Chowdhury et.al.|[2406.17124](https://arxiv.org/abs/2406.17124)|null|
|**2024-06-24**|**Exploring the Capability of Mamba in Speech Applications**|Koichi Miyazaki et.al.|[2406.16808](https://arxiv.org/abs/2406.16808)|null|
|**2024-06-24**|**Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024**|Sai Koneru et.al.|[2406.16777](https://arxiv.org/abs/2406.16777)|null|
|**2024-06-25**|**Towards Zero-Shot Text-To-Speech for Arabic Dialects**|Khai Duy Doan et.al.|[2406.16751](https://arxiv.org/abs/2406.16751)|null|
|**2024-06-24**|**One-Class Learning with Adaptive Centroid Shift for Audio Deepfake Detection**|Hyun Myung Kim et.al.|[2406.16716](https://arxiv.org/abs/2406.16716)|null|
|**2024-06-24**|**RefXVC: Cross-Lingual Voice Conversion with Enhanced Reference Leveraging**|Mingyang Zhang et.al.|[2406.16326](https://arxiv.org/abs/2406.16326)|null|
|**2024-06-24**|**DreamVoice: Text-Guided Voice Conversion**|Jiarui Hai et.al.|[2406.16314](https://arxiv.org/abs/2406.16314)|null|
|**2024-06-23**|**Contextualized End-to-end Automatic Speech Recognition with Intermediate Biasing Loss**|Muhammad Shakeel et.al.|[2406.16120](https://arxiv.org/abs/2406.16120)|null|
|**2024-06-23**|**Decoder-only Architecture for Streaming End-to-end Speech Recognition**|Emiru Tsunoo et.al.|[2406.16107](https://arxiv.org/abs/2406.16107)|null|
|**2024-06-22**|**Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation Assessment**|Heejin Do et.al.|[2406.15723](https://arxiv.org/abs/2406.15723)|null|
|**2024-06-21**|**PI-Whisper: An Adaptive and Incremental ASR Framework for Diverse and Evolving Speaker Characteristics**|Amir Nassereldine et.al.|[2406.15668](https://arxiv.org/abs/2406.15668)|null|
|**2024-06-21**|**Perception of Phonological Assimilation by Neural Speech Recognition Models**|Charlotte Pouw et.al.|[2406.15265](https://arxiv.org/abs/2406.15265)|null|
|**2024-06-21**|**InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate Predictions**|Yu Nakagome et.al.|[2406.14890](https://arxiv.org/abs/2406.14890)|null|
|**2024-06-20**|**An Adapter-Based Unified Model for Multiple Spoken Language Processing Tasks**|Varsha Suresh et.al.|[2406.14747](https://arxiv.org/abs/2406.14747)|null|
|**2024-06-21**|**DASB -- Discrete Audio and Speech Benchmark**|Pooneh Mousavi et.al.|[2406.14294](https://arxiv.org/abs/2406.14294)|null|
|**2024-06-20**|**Intelligent Interface: Enhancing Lecture Engagement with Didactic Activity Summaries**|Anna Wróblewska et.al.|[2406.14266](https://arxiv.org/abs/2406.14266)|null|
|**2024-06-19**|**Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control**|Alexander Blatt et.al.|[2406.13842](https://arxiv.org/abs/2406.13842)|null|
|**2024-06-19**|**ManWav: The First Manchu ASR Model**|Jean Seo et.al.|[2406.13502](https://arxiv.org/abs/2406.13502)|null|
|**2024-06-19**|**Children's Speech Recognition through Discrete Token Enhancement**|Vrunda N. Sukhadia et.al.|[2406.13431](https://arxiv.org/abs/2406.13431)|null|
|**2024-06-19**|**CEC: A Noisy Label Detection Method for Speaker Recognition**|Yao Shen et.al.|[2406.13268](https://arxiv.org/abs/2406.13268)|null|
|**2024-06-18**|**Articulatory Encodec: Vocal Tract Kinematics as a Codec for Speech**|Cheol Jun Cho et.al.|[2406.12998](https://arxiv.org/abs/2406.12998)|null|
|**2024-06-18**|**Bridging the Gap: Integrating Pre-trained Speech Enhancement and Recognition Models for Robust Speech Recognition**|Kuan-Chen Wang et.al.|[2406.12699](https://arxiv.org/abs/2406.12699)|null|
|**2024-06-18**|**Transcribe, Align and Segment: Creating speech datasets for low-resource languages**|Taras Sereda et.al.|[2406.12674](https://arxiv.org/abs/2406.12674)|null|
|**2024-06-18**|**Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech**|Adrien Pupier et.al.|[2406.12621](https://arxiv.org/abs/2406.12621)|null|
|**2024-06-18**|**Rapid Language Adaptation for Multilingual E2E Speech Recognition Using Encoder Prompting**|Yosuke Kashiwagi et.al.|[2406.12611](https://arxiv.org/abs/2406.12611)|null|
|**2024-06-18**|**Unsupervised Online Continual Learning for Automatic Speech Recognition**|Steven Vander Eeckt et.al.|[2406.12503](https://arxiv.org/abs/2406.12503)|null|
|**2024-06-18**|**Performant ASR Models for Medical Entities in Accented Speech**|Tejumade Afonja et.al.|[2406.12387](https://arxiv.org/abs/2406.12387)|null|
|**2024-06-18**|**Finding Task-specific Subnetworks in Multi-task Spoken Language Understanding Model**|Hayato Futami et.al.|[2406.12317](https://arxiv.org/abs/2406.12317)|null|
|**2024-06-18**|**JEN-1 DreamStyler: Customized Musical Concept Learning via Pivotal Parameters Tuning**|Boyu Chen et.al.|[2406.12292](https://arxiv.org/abs/2406.12292)|null|
|**2024-06-18**|**SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization**|Young Jin Ahn et.al.|[2406.12233](https://arxiv.org/abs/2406.12233)|null|
|**2024-06-18**|**A Mel Spectrogram Enhancement Paradigm Based on CWT in Speech Synthesis**|Guoqiang Hu et.al.|[2406.12164](https://arxiv.org/abs/2406.12164)|null|
|**2024-06-17**|**1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis**|Sewade Ogun et.al.|[2406.11727](https://arxiv.org/abs/2406.11727)|null|
|**2024-06-17**|**GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement**|Yifan Yang et.al.|[2406.11546](https://arxiv.org/abs/2406.11546)|**[link](https://github.com/SpeechColab/GigaSpeech2)**|
|**2024-06-17**|**Performance Improvement of Language-Queried Audio Source Separation Based on Caption Augmentation From Large Language Models for DCASE Challenge 2024 Task 9**|Do Hyun Lee et.al.|[2406.11248](https://arxiv.org/abs/2406.11248)|null|
|**2024-06-17**|**Self-Distillation Prototypes Network: Learning Robust Speaker Representations without Supervision**|Yafeng Chen et.al.|[2406.11169](https://arxiv.org/abs/2406.11169)|null|
|**2024-06-16**|**Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech**|Guan-Ting Lin et.al.|[2406.11064](https://arxiv.org/abs/2406.11064)|null|
|**2024-06-16**|**NAST: Noise Aware Speech Tokenization for Speech Language Models**|Shoval Messica et.al.|[2406.11037](https://arxiv.org/abs/2406.11037)|**[link](https://github.com/ShovalMessica/NAST.)**|
|**2024-06-16**|**Large Language Models for Dysfluency Detection in Stuttered Speech**|Dominik Wagner et.al.|[2406.11025](https://arxiv.org/abs/2406.11025)|null|
|**2024-06-16**|**Outlier Reduction with Gated Attention for Improved Post-training Quantization in Large Sequence-to-sequence Speech Foundation Models**|Dominik Wagner et.al.|[2406.11022](https://arxiv.org/abs/2406.11022)|null|
|**2024-06-16**|**Optimized Speculative Sampling for GPU Hardware Accelerators**|Dominik Wagner et.al.|[2406.11016](https://arxiv.org/abs/2406.11016)|null|
|**2024-06-16**|**CoSTA: Code-Switched Speech Translation using Aligned Speech-Text Interleaving**|Bhavani Shankar et.al.|[2406.10993](https://arxiv.org/abs/2406.10993)|null|
|**2024-06-14**|**Inclusive ASR for Disfluent Speech: Cascaded Large-Scale Self-Supervised Learning with Targeted Fine-Tuning and Data Augmentation**|Dena Mujtaba et.al.|[2406.10177](https://arxiv.org/abs/2406.10177)|null|
|**2024-06-14**|**On the Evaluation of Speech Foundation Models for Spoken Language Understanding**|Siddhant Arora et.al.|[2406.10083](https://arxiv.org/abs/2406.10083)|null|
|**2024-06-14**|**Whisper-Flamingo: Integrating Visual Features into Whisper for Audio-Visual Speech Recognition and Translation**|Andrew Rouditchenko et.al.|[2406.10082](https://arxiv.org/abs/2406.10082)|**[link](https://github.com/roudimit/whisper-flamingo)**|
|**2024-06-14**|**Simul-Whisper: Attention-Guided Streaming Whisper with Truncation Detection**|Haoyu Wang et.al.|[2406.10052](https://arxiv.org/abs/2406.10052)|**[link](https://github.com/backspacetg/simul_whisper)**|
|**2024-06-14**|**ROAR: Reinforcing Original to Augmented Data Ratio Dynamics for Wav2Vec2.0 Based ASR**|Vishwanath Pratap Singh et.al.|[2406.09999](https://arxiv.org/abs/2406.09999)|null|
|**2024-06-14**|**An efficient text augmentation approach for contextualized Mandarin speech recognition**|Naijun Zheng et.al.|[2406.09950](https://arxiv.org/abs/2406.09950)|null|
|**2024-06-14**|**Perceiver-Prompt: Flexible Speaker Adaptation in Whisper for Chinese Disordered Speech Recognition**|Yicong Jiang et.al.|[2406.09873](https://arxiv.org/abs/2406.09873)|null|
|**2024-06-14**|**MMM: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model**|Jiatong Shi et.al.|[2406.09869](https://arxiv.org/abs/2406.09869)|null|
|**2024-06-14**|**Vec-Tok-VC+: Residual-enhanced Robust Zero-shot Voice Conversion with Progressive Constraints in a Dual-mode Training Strategy**|Linhan Ma et.al.|[2406.09844](https://arxiv.org/abs/2406.09844)|null|
|**2024-06-14**|**Low algorithmic delay implementation of convolutional beamformer for online joint source separation and dereverberation**|Kaien Mo et.al.|[2406.09821](https://arxiv.org/abs/2406.09821)|null|
|**2024-06-13**|**Exploring Spoken Language Identification Strategies for Automatic Transcription of Multilingual Broadcast and Institutional Speech**|Martina Valente et.al.|[2406.09290](https://arxiv.org/abs/2406.09290)|null|
|**2024-06-13**|**Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn't**|Chihiro Taguchi et.al.|[2406.09202](https://arxiv.org/abs/2406.09202)|null|
|**2024-06-13**|**LASER: Learning by Aligning Self-supervised Representations of Speech for Improving Content-related Tasks**|Amit Meghanani et.al.|[2406.09153](https://arxiv.org/abs/2406.09153)|null|
|**2024-06-13**|**ToneUnit: A Speech Discretization Approach for Tonal Language Speech Synthesis**|Dehua Tao et.al.|[2406.08989](https://arxiv.org/abs/2406.08989)|null|
|**2024-06-13**|**Transcription-Free Fine-Tuning of Speech Separation Models for Noisy and Reverberant Multi-Speaker Automatic Speech Recognition**|William Ravenscroft et.al.|[2406.08914](https://arxiv.org/abs/2406.08914)|null|
|**2024-06-13**|**AdaPTwin: Low-Cost Adaptive Compression of Product Twins in Transformers**|Emil Biju et.al.|[2406.08904](https://arxiv.org/abs/2406.08904)|null|
|**2024-06-13**|**A Single-Step Non-Autoregressive Automatic Speech Recognition Architecture with High Accuracy and Inference Speed**|Ziyang Zhuang et.al.|[2406.08835](https://arxiv.org/abs/2406.08835)|null|
|**2024-06-13**|**Generating Speakers by Prompting Listener Impressions for Pre-trained Multi-Speaker Text-to-Speech Systems**|Zhengyang Chen et.al.|[2406.08812](https://arxiv.org/abs/2406.08812)|null|
|**2024-06-12**|**ML-SUPERB 2.0: Benchmarking Multilingual Speech Models Across Modeling Constraints, Languages, and Datasets**|Jiatong Shi et.al.|[2406.08641](https://arxiv.org/abs/2406.08641)|null|
|**2024-06-12**|**Emotion Manipulation Through Music -- A Deep Learning Interactive Visual Approach**|Adel N. Abdalla et.al.|[2406.08623](https://arxiv.org/abs/2406.08623)|null|
|**2024-06-12**|**SVSNet+: Enhancing Speaker Voice Similarity Assessment Models with Representations from Speech Foundation Models**|Chun Yin et.al.|[2406.08445](https://arxiv.org/abs/2406.08445)|null|
|**2024-06-12**|**TokSing: Singing Voice Synthesis based on Discrete Tokens**|Yuning Wu et.al.|[2406.08416](https://arxiv.org/abs/2406.08416)|null|
|**2024-06-12**|**Neural Blind Source Separation and Diarization for Distant Speech Recognition**|Yoshiaki Bando et.al.|[2406.08396](https://arxiv.org/abs/2406.08396)|null|
|**2024-06-12**|**Towards Unsupervised Speech Recognition Without Pronunciation Models**|Junrui Ni et.al.|[2406.08380](https://arxiv.org/abs/2406.08380)|null|
|**2024-06-12**|**Speech Emotion Recognition with ASR Transcripts: A Comprehensive Study on Word Error Rate and Fusion Techniques**|Yuanchao Li et.al.|[2406.08353](https://arxiv.org/abs/2406.08353)|**[link](https://github.com/yc-li20/SER-on-WER-and-Fusion)**|
|**2024-06-12**|**Refining Self-Supervised Learnt Speech Representation using Brain Activations**|Hengyu Li et.al.|[2406.08266](https://arxiv.org/abs/2406.08266)|null|
|**2024-06-12**|**Transformer-based Model for ASR N-Best Rescoring and Rewriting**|Iwen E. Kang et.al.|[2406.08207](https://arxiv.org/abs/2406.08207)|null|
|**2024-06-12**|**FreeV: Free Lunch For Vocoders Through Pseudo Inversed Mel Filter**|Yuanjun Lv et.al.|[2406.08196](https://arxiv.org/abs/2406.08196)|**[link](https://github.com/BakerBunker/FreeV)**|
|**2024-06-12**|**Audio-conditioned phonemic and prosodic annotation for building text-to-speech models from unlabeled speech data**|Yuma Shirahata et.al.|[2406.08111](https://arxiv.org/abs/2406.08111)|null|
|**2024-06-12**|**Can Large Language Models Understand Spatial Audio?**|Changli Tang et.al.|[2406.07914](https://arxiv.org/abs/2406.07914)|null|
|**2024-06-11**|**Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?**|Qingkai Fang et.al.|[2406.07289](https://arxiv.org/abs/2406.07289)|null|
|**2024-06-11**|**Noise-Robust Voice Conversion by Conditional Denoising Training Using Latent Variables of Recording Quality and Environment**|Takuto Igarashi et.al.|[2406.07280](https://arxiv.org/abs/2406.07280)|null|
|**2024-06-11**|**AS-70: A Mandarin stuttered speech dataset for automatic speech recognition and stuttering event detection**|Rong Gong et.al.|[2406.07256](https://arxiv.org/abs/2406.07256)|null|
|**2024-06-11**|**SRC4VC: Smartphone-Recorded Corpus for Voice Conversion Benchmark**|Yuki Saito et.al.|[2406.07254](https://arxiv.org/abs/2406.07254)|null|
|**2024-06-11**|**CodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems**|Haibin Wu et.al.|[2406.07237](https://arxiv.org/abs/2406.07237)|null|
|**2024-06-11**|**MR-RawNet: Speaker verification system with multiple temporal resolutions for variable duration utterances using raw waveforms**|Seung-bin Kim et.al.|[2406.07103](https://arxiv.org/abs/2406.07103)|**[link](https://github.com/kimho1wq/mr-rawnet)**|
|**2024-06-11**|**Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter**|Andrei Andrusenko et.al.|[2406.07096](https://arxiv.org/abs/2406.07096)|null|
|**2024-06-11**|**Spoken Language Corpora Augmentation with Domain-Specific Voice-Cloned Speech**|Mateusz Czyżnikiewicz et.al.|[2406.07090](https://arxiv.org/abs/2406.07090)|null|
|**2024-06-11**|**Reading Miscue Detection in Primary School through Automatic Speech Recognition**|Lingyun Gao et.al.|[2406.07060](https://arxiv.org/abs/2406.07060)|null|
|**2024-06-10**|**Synthetic Query Generation using Large Language Models for Virtual Assistants**|Sonal Sannigrahi et.al.|[2406.06729](https://arxiv.org/abs/2406.06729)|null|
|**2024-06-10**|**Meta Learning Text-to-Speech Synthesis in over 7000 Languages**|Florian Lux et.al.|[2406.06403](https://arxiv.org/abs/2406.06403)|**[link](https://github.com/digitalphonetics/ims-toucan)**|
|**2024-06-10**|**A Parameter-efficient Language Extension Framework for Multilingual ASR**|Wei Liu et.al.|[2406.06329](https://arxiv.org/abs/2406.06329)|null|
|**2024-06-10**|**Quantifying the effect of speech pathology on automatic and human speaker verification**|Bence Mark Halpern et.al.|[2406.06208](https://arxiv.org/abs/2406.06208)|null|
|**2024-06-10**|**JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis**|Hyunjae Cho et.al.|[2406.06111](https://arxiv.org/abs/2406.06111)|null|
|**2024-06-10**|**Prompting Large Language Models with Audio for General-Purpose Speech Summarization**|Wonjune Kang et.al.|[2406.05968](https://arxiv.org/abs/2406.05968)|**[link](https://github.com/wonjune-kang/llm-speech-summarization)**|
|**2024-06-09**|**Conserving Human Creativity with Evolutionary Generative Algorithms: A Case Study in Music Generation**|Justin Kilb et.al.|[2406.05873](https://arxiv.org/abs/2406.05873)|null|
|**2024-06-09**|**Source -Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels**|Shlomo Salo Elia et.al.|[2406.05863](https://arxiv.org/abs/2406.05863)|null|
|**2024-06-09**|**Do Prompts Really Prompt? Exploring the Prompt Understanding Capability of Whisper**|Chih-Kai Yang et.al.|[2406.05806](https://arxiv.org/abs/2406.05806)|null|
|**2024-06-09**|**Optimizing Multi-Stuttered Speech Classification: Leveraging Whisper's Encoder for Efficient Parameter Reduction in Automated Assessment**|Huma Ameer et.al.|[2406.05784](https://arxiv.org/abs/2406.05784)|null|
|**2024-06-09**|**SPA-SVC: Self-supervised Pitch Augmentation for Singing Voice Conversion**|Bingsong Bai et.al.|[2406.05692](https://arxiv.org/abs/2406.05692)|null|
|**2024-06-07**|**The Database and Benchmark for Source Speaker Verification Against Voice Conversion**|Ze Li et.al.|[2406.04951](https://arxiv.org/abs/2406.04951)|null|
|**2024-06-07**|**LLM-based speaker diarization correction: A generalizable approach**|Georgios Efstathiadis et.al.|[2406.04927](https://arxiv.org/abs/2406.04927)|**[link](https://github.com/GeorgeEfstathiadis/LLM-Diarize-ASR-Agnostic)**|
|**2024-06-07**|**Speaker-Smoothed kNN Speaker Adaptation for End-to-End ASR**|Shaojun Li et.al.|[2406.04791](https://arxiv.org/abs/2406.04791)|null|
|**2024-06-07**|**Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and Diagnosis**|Xintong Wang et.al.|[2406.04595](https://arxiv.org/abs/2406.04595)|null|
|**2024-06-07**|**Neural Codec-based Adversarial Sample Detection for Speaker Verification**|Xuanjun Chen et.al.|[2406.04582](https://arxiv.org/abs/2406.04582)|null|
|**2024-06-06**|**Flexible Multichannel Speech Enhancement for Noise-Robust Frontend**|Ante Jukić et.al.|[2406.04552](https://arxiv.org/abs/2406.04552)|null|
|**2024-06-06**|**Label-Synchronous Neural Transducer for E2E Simultaneous Speech Translation**|Keqi Deng et.al.|[2406.04541](https://arxiv.org/abs/2406.04541)|null|
|**2024-06-06**|**To Distill or Not to Distill? On the Robustness of Robust Knowledge Distillation**|Abdul Waheed et.al.|[2406.04512](https://arxiv.org/abs/2406.04512)|**[link](https://github.com/UBC-NLP/distill-whisper-ar.)**|
|**2024-06-06**|**Towards Naturalistic Voice Conversion: NaturalVoices Dataset with an Automatic Processing Pipeline**|Ali N. Salman et.al.|[2406.04494](https://arxiv.org/abs/2406.04494)|null|
|**2024-06-06**|**Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis**|Théodor Lemerle et.al.|[2406.04467](https://arxiv.org/abs/2406.04467)|**[link](https://github.com/theodorblackbird/lina-speech.)**|
|**2024-06-06**|**VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling**|Zeyue Tian et.al.|[2406.04321](https://arxiv.org/abs/2406.04321)|**[link](https://github.com/zeyuet/vidmuse)**|
|**2024-06-06**|**Beyond Performance Plateaus: A Comprehensive Study on Scalability in Speech Enhancement**|Wangyou Zhang et.al.|[2406.04269](https://arxiv.org/abs/2406.04269)|null|
|**2024-06-06**|**Hypernetworks for Personalizing ASR to Atypical Speech**|Max Mueller-Eberstein et.al.|[2406.04240](https://arxiv.org/abs/2406.04240)|null|
|**2024-06-06**|**Helsinki Speech Challenge 2024**|Martin Ludvigsen et.al.|[2406.04123](https://arxiv.org/abs/2406.04123)|null|
|**2024-06-06**|**BLSP-Emo: Towards Empathetic Large Speech-Language Models**|Chen Wang et.al.|[2406.03872](https://arxiv.org/abs/2406.03872)|**[link](https://github.com/cwang621/blsp-emo)**|
|**2024-06-06**|**Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores**|Jiaming Zhou et.al.|[2406.03814](https://arxiv.org/abs/2406.03814)|null|
|**2024-06-06**|**Speed of Light Exact Greedy Decoding for RNN-T Speech Recognition Models on GPU**|Daniel Galvez et.al.|[2406.03791](https://arxiv.org/abs/2406.03791)|null|
|**2024-06-06**|**Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining**|Jinlong Xue et.al.|[2406.03714](https://arxiv.org/abs/2406.03714)|null|
|**2024-06-06**|**Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model**|Jinlong Xue et.al.|[2406.03706](https://arxiv.org/abs/2406.03706)|null|
|**2024-06-05**|**Style Mixture of Experts for Expressive Text-To-Speech Synthesis**|Ahad Jawaid et.al.|[2406.03637](https://arxiv.org/abs/2406.03637)|null|
|**2024-06-05**|**Enhancing CTC-based speech recognition with diverse modeling units**|Shiyi Han et.al.|[2406.03274](https://arxiv.org/abs/2406.03274)|null|
|**2024-06-05**|**Error-preserving Automatic Speech Recognition of Young English Learners' Language**|Janick Michot et.al.|[2406.03235](https://arxiv.org/abs/2406.03235)|**[link](https://github.com/mict-zhaw/chall_e2e_stt)**|
|**2024-06-05**|**StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning**|Shaolei Zhang et.al.|[2406.03049](https://arxiv.org/abs/2406.03049)|**[link](https://github.com/ictnlp/streamspeech)**|
|**2024-06-05**|**4D ASR: Joint Beam Search Integrating CTC, Attention, Transducer, and Mask Predict Decoders**|Yui Sudo et.al.|[2406.02950](https://arxiv.org/abs/2406.02950)|null|
|**2024-06-05**|**SYN2REAL: Leveraging Task Arithmetic for Mitigating Synthetic-Real Discrepancies in ASR Domain Adaptation**|Hsuan Su et.al.|[2406.02925](https://arxiv.org/abs/2406.02925)|null|
|**2024-06-05**|**Text Injection for Neural Contextual Biasing**|Zhong Meng et.al.|[2406.02921](https://arxiv.org/abs/2406.02921)|null|
|**2024-06-04**|**Keyword-Guided Adaptation of Automatic Speech Recognition**|Aviv Shamsian et.al.|[2406.02649](https://arxiv.org/abs/2406.02649)|null|
|**2024-06-04**|**Self-Supervised Singing Voice Pre-Training towards Speech-to-Singing Conversion**|Ruiqi Li et.al.|[2406.02429](https://arxiv.org/abs/2406.02429)|null|
|**2024-06-04**|**An Independence-promoting Loss for Music Generation with Language Models**|Jean-Marie Lemercier et.al.|[2406.02315](https://arxiv.org/abs/2406.02315)|null|
|**2024-06-04**|**Towards Supervised Performance on Speaker Verification with Self-Supervised Learning by Leveraging Large-Scale ASR Models**|Victor Miara et.al.|[2406.02285](https://arxiv.org/abs/2406.02285)|**[link](https://github.com/theolepage/wavlm_ssl_sv)**|
|**2024-06-04**|**ERes2NetV2: Boosting Short-Duration Speaker Verification Performance with Computational Efficiency**|Yafeng Chen et.al.|[2406.02167](https://arxiv.org/abs/2406.02167)|null|
|**2024-06-04**|**Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision**|Saierdaer Yusuyin et.al.|[2406.02166](https://arxiv.org/abs/2406.02166)|**[link](https://github.com/thu-spmi/cat)**|
|**2024-06-04**|**Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis**|Kun Zhou et.al.|[2406.02009](https://arxiv.org/abs/2406.02009)|null|
|**2024-06-04**|**Efficiently Train ASR Models that Memorize Less and Perform Better with Per-core Clipping**|Lun Wang et.al.|[2406.02004](https://arxiv.org/abs/2406.02004)|null|
|**2024-06-03**|**TinySV: Speaker Verification in TinyML with On-device Learning**|Massimo Pavan et.al.|[2406.01655](https://arxiv.org/abs/2406.01655)|null|
|**2024-06-03**|**Enabling ASR for Low-Resource Languages: A Comprehensive Dataset Creation Approach**|Ara Yeroyan et.al.|[2406.01446](https://arxiv.org/abs/2406.01446)|null|
|**2024-06-03**|**Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization**|Firas Khader et.al.|[2406.01314](https://arxiv.org/abs/2406.01314)|null|
|**2024-05-31**|**Very Low Complexity Speech Synthesis Using Framewise Autoregressive GAN (FARGAN) with Pitch Prediction**|Jean-Marc Valin et.al.|[2405.21069](https://arxiv.org/abs/2405.21069)|null|
|**2024-05-30**|**DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation**|Zachary Novack et.al.|[2405.20289](https://arxiv.org/abs/2405.20289)|null|
|**2024-05-30**|**Spectral Mapping of Singing Voices: U-Net-Assisted Vocal Segmentation**|Adam Sorrenti et.al.|[2405.20059](https://arxiv.org/abs/2405.20059)|**[link](https://github.com/mbrotos/soundseg)**|
|**2024-05-30**|**Explainable Attribute-Based Speaker Verification**|Xiaoliang Wu et.al.|[2405.19796](https://arxiv.org/abs/2405.19796)|null|
|**2024-05-31**|**Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities**|Vicky Zayats et.al.|[2405.18669](https://arxiv.org/abs/2405.18669)|null|
|**2024-05-28**|**Augmented Conversation with Embedded Speech-Driven On-the-Fly Referencing in AR**|Shivesh Jadon et.al.|[2405.18537](https://arxiv.org/abs/2405.18537)|null|
|**2024-05-28**|**Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**|Anjanava Biswas et.al.|[2405.18346](https://arxiv.org/abs/2405.18346)|null|
|**2024-05-28**|**NUTS, NARS, and Speech**|D. van der Sluis et.al.|[2405.17874](https://arxiv.org/abs/2405.17874)|null|
|**2024-05-28**|**TransVIP: Speech to Speech Translation System with Voice and Isochrony Preservation**|Chenyang Le et.al.|[2405.17809](https://arxiv.org/abs/2405.17809)|null|
|**2024-05-27**|**Federating Dynamic Models using Early-Exit Architectures for Automatic Speech Recognition on Heterogeneous Clients**|Mohamed Nabih Ali et.al.|[2405.17376](https://arxiv.org/abs/2405.17376)|**[link](https://github.com/mnabihali/ASR-FL)**|
|**2024-05-27**|**"Pass the butter": A study on desktop-classic multitasking robotic arm based on advanced YOLOv7 and BERT**|Haohua Que et.al.|[2405.17250](https://arxiv.org/abs/2405.17250)|null|
|**2024-05-27**|**RSET: Remapping-based Sorting Method for Emotion Transfer Speech Synthesis**|Haoxiang Shi et.al.|[2405.17028](https://arxiv.org/abs/2405.17028)|null|
|**2024-05-27**|**A Variance-Preserving Interpolation Approach for Diffusion Models with Applications to Single Channel Speech Enhancement and Recognition**|Zilu Guo et.al.|[2405.16952](https://arxiv.org/abs/2405.16952)|null|
|**2024-05-24**|**Quality-aware Masked Diffusion Transformer for Enhanced Music Generation**|Chang Li et.al.|[2405.15863](https://arxiv.org/abs/2405.15863)|null|
|**2024-05-27**|**HiddenSpeaker: Generate Imperceptible Unlearnable Audios for Speaker Verification System**|Zhisheng Zhang et.al.|[2405.15655](https://arxiv.org/abs/2405.15655)|null|
|**2024-05-24**|**Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition**|Zijin Gu et.al.|[2405.15216](https://arxiv.org/abs/2405.15216)|null|
|**2024-05-23**|**Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding**|Suyoung Kim et.al.|[2405.15097](https://arxiv.org/abs/2405.15097)|null|
|**2024-05-23**|**Real-Time and Accurate: Zero-shot High-Fidelity Singing Voice Conversion with Multi-Condition Flow Synthesis**|Hui Li et.al.|[2405.15093](https://arxiv.org/abs/2405.15093)|null|
|**2024-05-23**|**Reinforcement Learning for Fine-tuning Text-to-speech Diffusion Models**|Jingyi Chen et.al.|[2405.14632](https://arxiv.org/abs/2405.14632)|null|
|**2024-05-23**|**Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Multi-modal Text Recognition**|Chan-Jan Hsu et.al.|[2405.14259](https://arxiv.org/abs/2405.14259)|**[link](https://github.com/mtkresearch/generative-fusion-decoding)**|
|**2024-05-23**|**Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models**|Yuchen Hu et.al.|[2405.14161](https://arxiv.org/abs/2405.14161)|null|
|**2024-05-23**|**A Survey on Vision-Language-Action Models for Embodied AI**|Yueen Ma et.al.|[2405.14093](https://arxiv.org/abs/2405.14093)|**[link](https://github.com/yueen-ma/Awesome-VLA.)**|
|**2024-05-22**|**ST-Gait++: Leveraging spatio-temporal convolutions for gait-based emotion recognition on videos**|Maria Luísa Lima et.al.|[2405.13903](https://arxiv.org/abs/2405.13903)|null|
|**2024-05-22**|**Joint Optimization of Streaming and Non-Streaming Automatic Speech Recognition with Multi-Decoder and Knowledge Distillation**|Muhammad Shakeel et.al.|[2405.13514](https://arxiv.org/abs/2405.13514)|null|
|**2024-05-22**|**A Near-Real-Time Processing Ego Speech Filtering Pipeline Designed for Speech Interruption During Human-Robot Interaction**|Yue Li et.al.|[2405.13477](https://arxiv.org/abs/2405.13477)|null|
|**2024-05-22**|**You don't understand me!: Comparing ASR results for L1 and L2 speakers of Swedish**|Ronald Cumbal et.al.|[2405.13379](https://arxiv.org/abs/2405.13379)|null|
|**2024-05-22**|**Contextualized Automatic Speech Recognition with Dynamic Vocabulary**|Yui Sudo et.al.|[2405.13344](https://arxiv.org/abs/2405.13344)|null|
|**2024-05-21**|**FairLENS: Assessing Fairness in Law Enforcement Speech Recognition**|Yicheng Wang et.al.|[2405.13166](https://arxiv.org/abs/2405.13166)|null|
|**2024-05-21**|**Could a Computer Architect Understand our Brain?**|Valentin Puente-Varona et.al.|[2405.12815](https://arxiv.org/abs/2405.12815)|null|
|**2024-05-21**|**SYMPLEX: Controllable Symbolic Music Generation using Simplex Diffusion with Vocabulary Priors**|Nicolas Jonason et.al.|[2405.12666](https://arxiv.org/abs/2405.12666)|null|
|**2024-05-21**|**Mamba in Speech: Towards an Alternative to Self-Attention**|Xiangyu Zhang et.al.|[2405.12609](https://arxiv.org/abs/2405.12609)|**[link](https://github.com/tonyyouyou/mamba-in-speech)**|
|**2024-05-20**|**Neighborhood Attention Transformer with Progressive Channel Fusion for Speaker Verification**|Nian Li et.al.|[2405.12031](https://arxiv.org/abs/2405.12031)|null|
|**2024-05-20**|**Continuous Sign Language Recognition with Adapted Conformer via Unsupervised Pretraining**|Neena Aloysius et.al.|[2405.12018](https://arxiv.org/abs/2405.12018)|null|
|**2024-05-20**|**Diff-BGM: A Diffusion Model for Video Background Music Generation**|Sizhe Li et.al.|[2405.11913](https://arxiv.org/abs/2405.11913)|null|
|**2024-05-20**|**SSAMBA: Self-Supervised Audio Representation Learning with Mamba State Space Model**|Siavash Shams et.al.|[2405.11831](https://arxiv.org/abs/2405.11831)|**[link](https://github.com/siavashshams/ssamba)**|
|**2024-05-17**|**Acoustic modeling for Overlapping Speech Recognition: JHU Chime-5 Challenge System**|Vimal Manohar et.al.|[2405.11078](https://arxiv.org/abs/2405.11078)|null|
|**2024-05-17**|**Distinctive and Natural Speaker Anonymization via Singular Value Transformation-assisted Matrix**|Jixun Yao et.al.|[2405.10786](https://arxiv.org/abs/2405.10786)|null|
|**2024-05-16**|**Speaker Verification in Agent-Generated Conversations**|Yizhe Yang et.al.|[2405.10150](https://arxiv.org/abs/2405.10150)|null|
|**2024-05-16**|**Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models**|Yuchen Hu et.al.|[2405.10025](https://arxiv.org/abs/2405.10025)|null|
|**2024-05-16**|**Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models**|Ziyu Wang et.al.|[2405.09901](https://arxiv.org/abs/2405.09901)|**[link](https://github.com/zzwaang/melody-reduction-algo)**|
|**2024-05-16**|**Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model**|Siyang Wang et.al.|[2405.09768](https://arxiv.org/abs/2405.09768)|null|
|**2024-05-15**|**No More Mumbles: Enhancing Robot Intelligibility through Speech Adaptation**|Qiaoqiao Ren et.al.|[2405.09708](https://arxiv.org/abs/2405.09708)|**[link](https://github.com/qiaoqiao2323/robot-speech-intelligibility)**|
|**2024-05-15**|**Towards Evaluating the Robustness of Automatic Speech Recognition Systems via Audio Style Transfer**|Weifei Jin et.al.|[2405.09470](https://arxiv.org/abs/2405.09470)|null|
|**2024-05-15**|**Hierarchical Emotion Prediction and Control in Text-to-Speech Synthesis**|Sho Inoue et.al.|[2405.09171](https://arxiv.org/abs/2405.09171)|null|
|**2024-05-15**|**Speaker Embeddings With Weakly Supervised Voice Activity Detection For Efficient Speaker Diarization**|Jenthe Thienpondt et.al.|[2405.09142](https://arxiv.org/abs/2405.09142)|null|
|**2024-05-14**|**Investigating the 'Autoencoder Behavior' in Speech Self-Supervised Models: a focus on HuBERT's Pretraining**|Valentin Vielzeuf et.al.|[2405.08402](https://arxiv.org/abs/2405.08402)|null|
|**2024-05-14**|**SpeechVerse: A Large-scale Generalizable Audio Language Model**|Nilaksh Das et.al.|[2405.08295](https://arxiv.org/abs/2405.08295)|null|
|**2024-05-13**|**Rene: A Pre-trained Multi-modal Architecture for Auscultation of Respiratory Diseases**|Pengfei Zhang et.al.|[2405.07442](https://arxiv.org/abs/2405.07442)|null|
|**2024-05-12**|**SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset**|Sushant Gautam et.al.|[2405.07354](https://arxiv.org/abs/2405.07354)|**[link](https://github.com/SoccerNet/sn-echoes)**|
|**2024-05-11**|**Towards an Accessible and Rapidly Trainable Rhythm Sequencer Using a Generative Stacked Autoencoder**|Alex Wastnidge et.al.|[2405.07034](https://arxiv.org/abs/2405.07034)|null|
|**2024-05-11**|**A framework of text-dependent speaker verification for chinese numerical string corpus**|Litong Zheng et.al.|[2405.07029](https://arxiv.org/abs/2405.07029)|null|
|**2024-05-10**|**DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under Differentially Private Federated Learning using Dynamic Low-Rank Adaptation**|Jie Xu et.al.|[2405.06368](https://arxiv.org/abs/2405.06368)|null|
|**2024-05-10**|**Lost in Transcription: Identifying and Quantifying the Accuracy Biases of Automatic Speech Recognition Systems Against Disfluent Speech**|Dena Mujtaba et.al.|[2405.06150](https://arxiv.org/abs/2405.06150)|null|
|**2024-05-09**|**Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models**|Vyas Raina et.al.|[2405.06134](https://arxiv.org/abs/2405.06134)|**[link](https://github.com/rainavyas/prepend_acoustic_attack)**|
|**2024-05-09**|**The RoyalFlush Automatic Speech Diarization and Recognition System for In-Car Multi-Channel Automatic Speech Recognition Challenge**|Jingguang Tian et.al.|[2405.05498](https://arxiv.org/abs/2405.05498)|null|
|**2024-05-07**|**Open Implementation and Study of BEST-RQ for Speech Processing**|Ryan Whetten et.al.|[2405.04296](https://arxiv.org/abs/2405.04296)|**[link](https://github.com/speechbrain/speechbrain)**|
|**2024-05-07**|**Speaker Characterization by means of Attention Pooling**|Federico Costa et.al.|[2405.04096](https://arxiv.org/abs/2405.04096)|null|
|**2024-05-06**|**Whispy: Adapting STT Whisper Models to Real-Time Environments**|Antonio Bevilacqua et.al.|[2405.03484](https://arxiv.org/abs/2405.03484)|null|
|**2024-05-06**|**MMGER: Multi-modal and Multi-granularity Generative Error Correction with LLM for Joint Accent and Speech Recognition**|Bingshen Mu et.al.|[2405.03152](https://arxiv.org/abs/2405.03152)|null|
|**2024-05-06**|**Determined Multichannel Blind Source Separation with Clustered Source Model**|Jianyu Wang et.al.|[2405.03118](https://arxiv.org/abs/2405.03118)|null|
|**2024-05-11**|**Analysis about Theoretical Foundations for Method to Enhancing ASR Performance using OCR Word Frequency Differences**|Kyudan Jung et.al.|[2405.02995](https://arxiv.org/abs/2405.02995)|null|
|**2024-05-07**|**Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models**|Tianze Xu et.al.|[2405.02801](https://arxiv.org/abs/2405.02801)|**[link](https://github.com/wangtoonaive/mozartstouch)**|
|**2024-05-04**|**Mixat: A Data Set of Bilingual Emirati-English Speech**|Maryam Al Ali et.al.|[2405.02578](https://arxiv.org/abs/2405.02578)|**[link](https://github.com/mbzuai-nlp/mixat)**|
|**2024-05-06**|**Training-Free Deepfake Voice Recognition by Leveraging Large-Scale Pre-Trained Models**|Alessandro Pianese et.al.|[2405.02179](https://arxiv.org/abs/2405.02179)|null|
|**2024-05-06**|**Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets**|Xuelong Geng et.al.|[2405.02132](https://arxiv.org/abs/2405.02132)|null|
|**2024-05-02**|**Converting Anyone's Voice: End-to-End Expressive Voice Conversion with a Conditional Diffusion Model**|Zongyang Du et.al.|[2405.01730](https://arxiv.org/abs/2405.01730)|null|
|**2024-05-01**|**Efficient Sample-Specific Encoder Perturbations**|Yassir Fathullah et.al.|[2405.01601](https://arxiv.org/abs/2405.01601)|null|
|**2024-05-02**|**Low-resource speech recognition and dialect identification of Irish in a multi-task framework**|Liam Lonergan et.al.|[2405.01293](https://arxiv.org/abs/2405.01293)|null|
|**2024-05-02**|**Improving Membership Inference in ASR Model Auditing with Perturbed Loss Features**|Francisco Teixeira et.al.|[2405.01207](https://arxiv.org/abs/2405.01207)|null|
|**2024-05-02**|**Deep Learning Models in Speech Recognition: Measuring GPU Energy Consumption, Impact of Noise and Model Quantization for Edge Deployment**|Aditya Chakravarty et.al.|[2405.01004](https://arxiv.org/abs/2405.01004)|**[link](https://github.com/zzadiues3338/asr-energy-jetson)**|
|**2024-05-02**|**Efficient Compression of Multitask Multilingual Speech Models**|Thomas Palmeira Ferraz et.al.|[2405.00966](https://arxiv.org/abs/2405.00966)|null|
|**2024-05-02**|**MAIN-VC: Lightweight Speech Representation Disentanglement for One-shot Voice Conversion**|Pengcheng Li et.al.|[2405.00930](https://arxiv.org/abs/2405.00930)|null|
|**2024-05-01**|**Learning Expressive Disentangled Speech Representations with Soft Speech Units and Adversarial Style Augmentation**|Yimin Deng et.al.|[2405.00603](https://arxiv.org/abs/2405.00603)|null|
|**2024-05-01**|**Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition**|Dongyuan Li et.al.|[2405.00307](https://arxiv.org/abs/2405.00307)|**[link](https://github.com/clearloveyuan/after)**|
|**2024-04-30**|**Who is Authentic Speaker**|Qiang Huang et.al.|[2405.00248](https://arxiv.org/abs/2405.00248)|null|
|**2024-04-30**|**ConFides: A Visual Analytics Solution for Automated Speech Recognition Analysis and Exploration**|Sunwoo Ha et.al.|[2405.00223](https://arxiv.org/abs/2405.00223)|null|
|**2024-04-30**|**Expressivity and Speech Synthesis**|Andreas Triantafyllopoulos et.al.|[2404.19363](https://arxiv.org/abs/2404.19363)|null|
|**2024-04-30**|**Does Whisper understand Swiss German? An automatic, qualitative, and human evaluation**|Eyal Liron Dolev et.al.|[2404.19310](https://arxiv.org/abs/2404.19310)|null|
|**2024-04-30**|**EfficientASR: Speech Recognition Network Compression via Attention Redundancy and Chunk-Level FFN Optimization**|Jianzong Wang et.al.|[2404.19214](https://arxiv.org/abs/2404.19214)|null|
|**2024-04-30**|**EAD-VC: Enhancing Speech Auto-Disentanglement for Voice Conversion with IFUB Estimator and Joint Text-Guided Consistent Learning**|Ziqi Liang et.al.|[2404.19212](https://arxiv.org/abs/2404.19212)|null|
|**2024-04-29**|**Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**|Artem Abzaliev et.al.|[2404.18739](https://arxiv.org/abs/2404.18739)|null|
|**2024-04-29**|**MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**|Xiang Li et.al.|[2404.18398](https://arxiv.org/abs/2404.18398)|**[link](https://github.com/kttrcdl/umetts)**|
|**2024-04-30**|**ComposerX: Multi-Agent Symbolic Music Composition with LLMs**|Qixin Deng et.al.|[2404.18081](https://arxiv.org/abs/2404.18081)|**[link](https://github.com/lllindsey0615/composerx)**|
|**2024-04-27**|**A Comparison of Differential Performance Metrics for the Evaluation of Automatic Speaker Verification Fairness**|Oubaida Chouchane et.al.|[2404.17810](https://arxiv.org/abs/2404.17810)|null|
|**2024-04-26**|**An RFP dataset for Real, Fake, and Partially fake audio detection**|Abdulazeez AlAli et.al.|[2404.17721](https://arxiv.org/abs/2404.17721)|null|
|**2024-04-26**|**A Semi-Automatic Approach to Create Large Gender- and Age-Balanced Speaker Corpora: Usefulness of Speaker Diarization & Identification**|Rémi Uro et.al.|[2404.17552](https://arxiv.org/abs/2404.17552)|null|
|**2024-04-26**|**Child Speech Recognition in Human-Robot Interaction: Problem Solved?**|Ruben Janssens et.al.|[2404.17394](https://arxiv.org/abs/2404.17394)|null|
|**2024-04-26**|**Device Feature based on Graph Fourier Transformation with Logarithmic Processing For Detection of Replay Speech Attacks**|Mingrui He et.al.|[2404.17280](https://arxiv.org/abs/2404.17280)|null|
|**2024-04-29**|**COCOLA: Coherence-Oriented Contrastive Learning of Musical Audio Representations**|Ruben Ciranni et.al.|[2404.16969](https://arxiv.org/abs/2404.16969)|null|
|**2024-04-26**|**Automatic Speech Recognition System-Independent Word Error Rate Estimation**|Chanho Park et.al.|[2404.16743](https://arxiv.org/abs/2404.16743)|null|
|**2024-04-25**|**Developing Acoustic Models for Automatic Speech Recognition in Swedish**|Giampiero Salvi et.al.|[2404.16547](https://arxiv.org/abs/2404.16547)|null|
|**2024-04-25**|**U2++ MoE: Scaling 4.7x parameters with minimal impact on RTF**|Xingchen Song et.al.|[2404.16407](https://arxiv.org/abs/2404.16407)|null|
|**2024-04-24**|**Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**|Badri Narayana Patro et.al.|[2404.16112](https://arxiv.org/abs/2404.16112)|**[link](https://github.com/badripatro/mamba360)**|
|**2024-04-24**|**Efficient Multi-Model Fusion with Adversarial Complementary Representation Learning**|Zuheng Kang et.al.|[2404.15704](https://arxiv.org/abs/2404.15704)|null|
|**2024-04-24**|**HybridVC: Efficient Voice Style Conversion with Text and Audio Prompts**|Xinlei Niu et.al.|[2404.15637](https://arxiv.org/abs/2404.15637)|null|
|**2024-04-23**|**Killkan: The Automatic Speech Recognition Dataset for Kichwa with Morphosyntactic Information**|Chihiro Taguchi et.al.|[2404.15501](https://arxiv.org/abs/2404.15501)|**[link](https://github.com/ctaguchi/killkan)**|
|**2024-04-23**|**Additive Margin in Contrastive Self-Supervised Frameworks to Learn Discriminative Speaker Representations**|Theo Lepage et.al.|[2404.14913](https://arxiv.org/abs/2404.14913)|null|
|**2024-04-23**|**Rethinking Processing Distortions: Disentangling the Impact of Speech Enhancement Errors on Speech Recognition Performance**|Tsubasa Ochiai et.al.|[2404.14860](https://arxiv.org/abs/2404.14860)|null|
|**2024-04-25**|**FlashSpeech: Efficient Zero-Shot Speech Synthesis**|Zhen Ye et.al.|[2404.14700](https://arxiv.org/abs/2404.14700)|null|
|**2024-04-22**|**Assessment of Sign Language-Based versus Touch-Based Input for Deaf Users Interacting with Intelligent Personal Assistants**|Nina Tran et.al.|[2404.14605](https://arxiv.org/abs/2404.14605)|null|
|**2024-04-22**|**Exploring neural oscillations during speech perception via surrogate gradient spiking neural networks**|Alexandre Bittar et.al.|[2404.14024](https://arxiv.org/abs/2404.14024)|null|
|**2024-04-23**|**Retrieval-Augmented Audio Deepfake Detection**|Zuheng Kang et.al.|[2404.13892](https://arxiv.org/abs/2404.13892)|null|
|**2024-04-23**|**Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**|Charith Chandra Sai Balne et.al.|[2404.13506](https://arxiv.org/abs/2404.13506)|null|
|**2024-04-20**|**Text-dependent Speaker Verification (TdSV) Challenge 2024: Challenge Evaluation Plan**|Zeinali Hossein et.al.|[2404.13428](https://arxiv.org/abs/2404.13428)|null|
|**2024-04-20**|**Semantically Corrected Amharic Automatic Speech Recognition**|Samuael Adnew et.al.|[2404.13362](https://arxiv.org/abs/2404.13362)|**[link](https://github.com/samuael/postprocessed_geez_asr)**|
|**2024-04-20**|**Music Consistency Models**|Zhengcong Fei et.al.|[2404.13358](https://arxiv.org/abs/2404.13358)|null|
|**2024-04-20**|**Track Role Prediction of Single-Instrumental Sequences**|Changheon Han et.al.|[2404.13286](https://arxiv.org/abs/2404.13286)|null|
|**2024-04-19**|**Learn2Talk: 3D Talking Face Learns from 2D Talking Face**|Yixiang Zhuang et.al.|[2404.12888](https://arxiv.org/abs/2404.12888)|null|
|**2024-04-19**|**Efficient infusion of self-supervised representations in Automatic Speech Recognition**|Darshan Prabhu et.al.|[2404.12628](https://arxiv.org/abs/2404.12628)|null|
|**2024-04-18**|**TIMIT Speaker Profiling: A Comparison of Multi-task learning and Single-task learning Approaches**|Rong Wang et.al.|[2404.12077](https://arxiv.org/abs/2404.12077)|null|
|**2024-04-18**|**Large Language Models: From Notes to Musical Form**|Lilac Atassi et.al.|[2404.11976](https://arxiv.org/abs/2404.11976)|null|
|**2024-04-17**|**Jointly Recognizing Speech and Singing Voices Based on Multi-Task Audio Source Separation**|Ye Bai et.al.|[2404.11275](https://arxiv.org/abs/2404.11275)|null|
|**2024-04-16**|**Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training**|Pavel Denisov et.al.|[2404.10922](https://arxiv.org/abs/2404.10922)|**[link](https://github.com/akreal/bloomzmms)**|
|**2024-04-16**|**Long-form music generation with latent diffusion**|Zach Evans et.al.|[2404.10301](https://arxiv.org/abs/2404.10301)|null|
|**2024-04-16**|**Anatomy of Industrial Scale Multilingual ASR**|Francis McCann Ramirez et.al.|[2404.09841](https://arxiv.org/abs/2404.09841)|null|
|**2024-04-15**|**Resilience of Large Language Models for Noisy Instructions**|Bin Wang et.al.|[2404.09754](https://arxiv.org/abs/2404.09754)|null|
|**2024-04-16**|**Text-to-Song: Towards Controllable Music Generation Incorporating Vocals and Accompaniment**|Zhiqing Hong et.al.|[2404.09313](https://arxiv.org/abs/2404.09313)|null|
|**2024-04-12**|**Comparing Apples to Oranges: LLM-powered Multimodal Intention Prediction in an Object Categorization Task**|Hassan Ali et.al.|[2404.08424](https://arxiv.org/abs/2404.08424)|null|
|**2024-04-12**|**ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa'ikhana**|Monica Romero et.al.|[2404.08368](https://arxiv.org/abs/2404.08368)|null|
|**2024-04-10**|**An inclusive review on deep learning techniques and their scope in handwriting recognition**|Sukhdeep Singh et.al.|[2404.08011](https://arxiv.org/abs/2404.08011)|null|
|**2024-04-12**|**An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution**|Tien-Hong Lo et.al.|[2404.07575](https://arxiv.org/abs/2404.07575)|null|
|**2024-04-12**|**Conformer-1: Robust ASR via Large-Scale Semisupervised Bootstrapping**|Kevin Zhang et.al.|[2404.07341](https://arxiv.org/abs/2404.07341)|null|
|**2024-04-12**|**Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness**|Xincan Feng et.al.|[2404.06714](https://arxiv.org/abs/2404.06714)|**[link](https://github.com/xincanfeng/vitsgpt)**|
|**2024-04-10**|**MuPT: A Generative Symbolic Music Pretrained Transformer**|Xingwei Qu et.al.|[2404.06393](https://arxiv.org/abs/2404.06393)|null|
|**2024-04-10**|**The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge**|Yiwei Guo et.al.|[2404.06079](https://arxiv.org/abs/2404.06079)|null|
|**2024-04-06**|**A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music**|Roopa Mayya et.al.|[2404.05765](https://arxiv.org/abs/2404.05765)|null|
|**2024-04-08**|**VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain**|Khai Le-Duc et.al.|[2404.05659](https://arxiv.org/abs/2404.05659)|**[link](https://github.com/leduckhai/multimed)**|
|**2024-04-07**|**Gull: A Generative Multifunctional Audio Codec**|Yi Luo et.al.|[2404.04947](https://arxiv.org/abs/2404.04947)|null|
|**2024-04-07**|**Safeguarding Voice Privacy: Harnessing Near-Ultrasonic Interference To Protect Against Unauthorized Audio Recording**|Forrest McKee et.al.|[2404.04769](https://arxiv.org/abs/2404.04769)|null|
|**2024-04-06**|**HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks**|Yingting Li et.al.|[2404.04645](https://arxiv.org/abs/2404.04645)|**[link](https://github.com/declare-lab/hypertts)**|
|**2024-04-05**|**The NES Video-Music Database: A Dataset of Symbolic Video Game Music Paired with Gameplay Videos**|Igor Cardoso et.al.|[2404.04420](https://arxiv.org/abs/2404.04420)|null|
|**2024-04-04**|**Transducers with Pronunciation-aware Embeddings for Automatic Speech Recognition**|Hainan Xu et.al.|[2404.04295](https://arxiv.org/abs/2404.04295)|null|
|**2024-04-05**|**Open vocabulary keyword spotting through transfer learning from speech synthesis**|Kesavaraj V et.al.|[2404.03914](https://arxiv.org/abs/2404.03914)|null|
|**2024-04-06**|**RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis**|Detai Xin et.al.|[2404.03204](https://arxiv.org/abs/2404.03204)|null|
|**2024-04-03**|**Mai Ho'omāuna i ka 'Ai: Language Models Improve Automatic Speech Recognition in Hawaiian**|Kaavya Chaparala et.al.|[2404.03073](https://arxiv.org/abs/2404.03073)|null|
|**2024-04-03**|**PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders**|Yu Pan et.al.|[2404.02702](https://arxiv.org/abs/2404.02702)|null|
|**2024-04-03**|**Leveraging the Interplay Between Syntactic and Acoustic Cues for Optimizing Korean TTS Pause Formation**|Yejin Jeon et.al.|[2404.02592](https://arxiv.org/abs/2404.02592)|null|
|**2024-04-03**|**CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models**|Zaid Sheikh et.al.|[2404.02408](https://arxiv.org/abs/2404.02408)|**[link](https://github.com/neulab/cmulab)**|
|**2024-04-02**|**BRAVEn: Improving Self-Supervised Pre-training for Visual and Auditory Speech Recognition**|Alexandros Haliassos et.al.|[2404.02098](https://arxiv.org/abs/2404.02098)|**[link](https://github.com/ahaliassos/raven)**|
|**2024-04-02**|**Noise Masking Attacks and Defenses for Pretrained Speech Models**|Matthew Jagielski et.al.|[2404.02052](https://arxiv.org/abs/2404.02052)|null|
|**2024-04-02**|**Kallaama: A Transcribed Speech Dataset about Agriculture in the Three Most Widely Spoken Languages in Senegal**|Elodie Gauthier et.al.|[2404.01991](https://arxiv.org/abs/2404.01991)|**[link](https://github.com/gauthelo/kallaama-speech-dataset)**|
|**2024-04-05**|**Zero-Shot Multi-Lingual Speaker Verification in Clinical Trials**|Ali Akram et.al.|[2404.01981](https://arxiv.org/abs/2404.01981)|null|
|**2024-04-02**|**Transfer Learning from Whisper for Microscopic Intelligibility Prediction**|Paul Best et.al.|[2404.01737](https://arxiv.org/abs/2404.01737)|null|
|**2024-03-31**|**Humane Speech Synthesis through Zero-Shot Emotion and Disfluency Generation**|Rohan Chaudhury et.al.|[2404.01339](https://arxiv.org/abs/2404.01339)|**[link](https://github.com/rohan-chaudhury/humane-speech-synthesis-through-zero-shot-emotion-and-disfluency-generation)**|
|**2024-04-01**|**KazEmoTTS: A Dataset for Kazakh Emotional Text-to-Speech Synthesis**|Adal Abilbekov et.al.|[2404.01033](https://arxiv.org/abs/2404.01033)|null|
|**2024-04-01**|**Voice Conversion Augmentation for Speaker Recognition on Defective Datasets**|Ruijie Tao et.al.|[2404.00863](https://arxiv.org/abs/2404.00863)|null|
|**2024-04-01**|**Removing Speaker Information from Speech Representation using Variable-Length Soft Pooling**|Injune Hwang et.al.|[2404.00856](https://arxiv.org/abs/2404.00856)|null|
|**2024-03-31**|**CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models**|Xiang Li et.al.|[2404.00569](https://arxiv.org/abs/2404.00569)|**[link](https://github.com/xiangli2022/cm-tts)**|
|**2024-03-29**|**ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models**|Thibaut Thonet et.al.|[2403.20262](https://arxiv.org/abs/2403.20262)|null|
|**2024-03-29**|**3D-Speaker-Toolkit: An Open Source Toolkit for Multi-modal Speaker Verification and Diarization**|Yafeng Chen et.al.|[2403.19971](https://arxiv.org/abs/2403.19971)|**[link](https://github.com/alibaba-damo-academy/3D-Speaker)**|
|**2024-03-28**|**Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition**|Yash Jain et.al.|[2403.19822](https://arxiv.org/abs/2403.19822)|null|
|**2024-03-28**|**Asymmetric and trial-dependent modeling: the contribution of LIA to SdSV Challenge Task 2**|Pierre-Michel Bousquet et.al.|[2403.19634](https://arxiv.org/abs/2403.19634)|null|
|**2024-03-28**|**Emotion Neural Transducer for Fine-Grained Speech Emotion Recognition**|Siyuan Shen et.al.|[2403.19224](https://arxiv.org/abs/2403.19224)|**[link](https://github.com/ecnu-cross-innovation-lab/ent)**|
|**2024-03-28**|**LV-CTC: Non-autoregressive ASR with CTC and latent variable models**|Yuya Fujita et.al.|[2403.19207](https://arxiv.org/abs/2403.19207)|null|
|**2024-03-27**|**PhysicsAssistant: An LLM-Powered Interactive Learning Robot for Physics Lab Investigations**|Ehsan Latif et.al.|[2403.18721](https://arxiv.org/abs/2403.18721)|null|
|**2024-03-27**|**ZAEBUC-Spoken: A Multilingual Multidialectal Arabic-English Speech Corpus**|Injy Hamed et.al.|[2403.18182](https://arxiv.org/abs/2403.18182)|null|
|**2024-03-28**|**DANCER: Entity Description Augmented Named Entity Corrector for Automatic Speech Recognition**|Yi-Cheng Wang et.al.|[2403.17645](https://arxiv.org/abs/2403.17645)|null|
|**2024-03-26**|**Extracting Biomedical Entities from Noisy Audio Transcripts**|Nima Ebadi et.al.|[2403.17363](https://arxiv.org/abs/2403.17363)|null|
|**2024-03-25**|**Grammatical vs Spelling Error Correction: An Investigation into the Responsiveness of Transformer-based Language Models using BART and MarianMT**|Rohit Raju et.al.|[2403.16655](https://arxiv.org/abs/2403.16655)|null|
|**2024-03-25**|**Training Generative Adversarial Network-Based Vocoder with Limited Data Using Augmentation-Conditional Discriminator**|Takuhiro Kaneko et.al.|[2403.16464](https://arxiv.org/abs/2403.16464)|null|
|**2024-03-22**|**Privacy-Preserving End-to-End Spoken Language Understanding**|Yinggui Wang et.al.|[2403.15510](https://arxiv.org/abs/2403.15510)|null|
|**2024-03-26**|**A Multimodal Approach to Device-Directed Speech Detection with Large Language Models**|Dominik Wagner et.al.|[2403.14438](https://arxiv.org/abs/2403.14438)|null|
|**2024-03-21**|**XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception**|HyoJung Han et.al.|[2403.14402](https://arxiv.org/abs/2403.14402)|null|
|**2024-03-21**|**M $^3$ AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset**|Zhe Chen et.al.|[2403.14168](https://arxiv.org/abs/2403.14168)|null|
|**2024-03-21**|**The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio Benchmarks and Novel Data**|Alice Baird et.al.|[2403.14048](https://arxiv.org/abs/2403.14048)|null|
|**2024-03-20**|**Open Access NAO (OAN): a ROS2-based software framework for HRI applications with the NAO robot**|Antonio Bono et.al.|[2403.13960](https://arxiv.org/abs/2403.13960)|null|
|**2024-03-20**|**BanglaNum -- A Public Dataset for Bengali Digit Recognition from Speech**|Mir Sayeed Mohammad et.al.|[2403.13465](https://arxiv.org/abs/2403.13465)|null|
|**2024-03-20**|**Advanced Long-Content Speech Recognition With Factorized Neural Transducer**|Xun Gong et.al.|[2403.13423](https://arxiv.org/abs/2403.13423)|null|
|**2024-03-20**|**KunquDB: An Attempt for Speaker Verification in the Chinese Opera Scenario**|Huali Zhou et.al.|[2403.13356](https://arxiv.org/abs/2403.13356)|null|
|**2024-03-20**|**Building speech corpus with diverse voice characteristics for its prompt-based representation**|Aya Watanabe et.al.|[2403.13353](https://arxiv.org/abs/2403.13353)|null|
|**2024-03-20**|**Polaris: A Safety-focused LLM Constellation Architecture for Healthcare**|Subhabrata Mukherjee et.al.|[2403.13313](https://arxiv.org/abs/2403.13313)|null|
|**2024-03-19**|**FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer**|Dongyeong Hwang et.al.|[2403.12821](https://arxiv.org/abs/2403.12821)|**[link](https://github.com/y0ngjaenius/cvpr2024_flowerformer)**|
|**2024-03-19**|**Real-time Speech Extraction Using Spatially Regularized Independent Low-rank Matrix Analysis and Rank-constrained Spatial Covariance Matrix Estimation**|Yuto Ishikawa et.al.|[2403.12477](https://arxiv.org/abs/2403.12477)|null|
|**2024-03-19**|**An Empirical Study of Speech Language Models for Prompt-Conditioned Speech Synthesis**|Yifan Peng et.al.|[2403.12402](https://arxiv.org/abs/2403.12402)|null|
|**2024-03-18**|**Multimodal Human-Autonomous Agents Interaction Using Pre-Trained Language and Visual Foundation Models**|Linus Nwankwo et.al.|[2403.12273](https://arxiv.org/abs/2403.12273)|null|
|**2024-03-18**|**Generalized Multi-Source Inference for Text Conditioned Music Diffusion Models**|Emilian Postolache et.al.|[2403.11706](https://arxiv.org/abs/2403.11706)|**[link](https://github.com/gladia-research-group/gmsdi)**|
|**2024-03-18**|**QEAN: Quaternion-Enhanced Attention Network for Visual Dance Generation**|Zhizhen Zhou et.al.|[2403.11626](https://arxiv.org/abs/2403.11626)|null|
|**2024-03-18**|**AdaMER-CTC: Connectionist Temporal Classification with Adaptive Maximum Entropy Regularization for Automatic Speech Recognition**|SooHwan Eom et.al.|[2403.11578](https://arxiv.org/abs/2403.11578)|null|
|**2024-03-16**|**Energy-Based Models with Applications to Speech and Language Processing**|Zhijian Ou et.al.|[2403.10961](https://arxiv.org/abs/2403.10961)|null|
|**2024-03-16**|**Initial Decoding with Minimally Augmented Language Model for Improved Lattice Rescoring in Low Resource ASR**|Savitha Murthy et.al.|[2403.10937](https://arxiv.org/abs/2403.10937)|null|
|**2024-03-15**|**MusicHiFi: Fast High-Fidelity Stereo Vocoding**|Ge Zhu et.al.|[2403.10493](https://arxiv.org/abs/2403.10493)|null|
|**2024-03-15**|**Neural Networks Hear You Loud And Clear: Hearing Loss Compensation Using Deep Neural Networks**|Peter Leer et.al.|[2403.10420](https://arxiv.org/abs/2403.10420)|null|
|**2024-03-14**|**SpokeN-100: A Cross-Lingual Benchmarking Dataset for The Classification of Spoken Numbers in Different Languages**|René Groh et.al.|[2403.09753](https://arxiv.org/abs/2403.09753)|**[link](https://github.com/ankilab/spoken-100)**|
|**2024-03-14**|**More than words: Advancements and challenges in speech recognition for singing**|Anna Kruspe et.al.|[2403.09298](https://arxiv.org/abs/2403.09298)|null|
|**2024-03-13**|**Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition**|Wenjing Zhu et.al.|[2403.08258](https://arxiv.org/abs/2403.08258)|null|
|**2024-03-13**|**SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech Recognition Evaluation**|Jiayu Du et.al.|[2403.08196](https://arxiv.org/abs/2403.08196)|**[link](https://github.com/speechcolab/leaderboard)**|
|**2024-03-13**|**Automatic Speech Recognition (ASR) for the Diagnosis of pronunciation of Speech Sound Disorders in Korean children**|Taekyung Ahn et.al.|[2403.08187](https://arxiv.org/abs/2403.08187)|null|
|**2024-03-13**|**EM-TTS: Efficiently Trained Low-Resource Mongolian Lightweight Text-to-Speech**|Ziqi Liang et.al.|[2403.08164](https://arxiv.org/abs/2403.08164)|null|
|**2024-03-12**|**Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language**|Yash Sharma et.al.|[2403.08011](https://arxiv.org/abs/2403.08011)|null|
|**2024-03-12**|**Motifs, Phrases, and Beyond: The Modelling of Structure in Symbolic Music Generation**|Keshav Bhandari et.al.|[2403.07995](https://arxiv.org/abs/2403.07995)|null|
|**2024-03-11**|**The evaluation of a code-switched Sepedi-English automatic speech recognition system**|Amanda Phaladi et.al.|[2403.07947](https://arxiv.org/abs/2403.07947)|null|
|**2024-03-12**|**Beyond the Labels: Unveiling Text-Dependency in Paralinguistic Speech Recognition Datasets**|Jan Pešán et.al.|[2403.07767](https://arxiv.org/abs/2403.07767)|null|
|**2024-03-11**|**Real-Time Multimodal Cognitive Assistant for Emergency Medical Services**|Keshara Weerasinghe et.al.|[2403.06734](https://arxiv.org/abs/2403.06734)|null|
|**2024-03-11**|**Towards Decoupling Frontend Enhancement and Backend Recognition in Monaural Robust ASR**|Yufeng Yang et.al.|[2403.06387](https://arxiv.org/abs/2403.06387)|null|
|**2024-03-10**|**SCORE: Self-supervised Correspondence Fine-tuning for Improved Content Representations**|Amit Meghanani et.al.|[2403.06260](https://arxiv.org/abs/2403.06260)|null|
|**2024-03-09**|**HAM-TTS: Hierarchical Acoustic Modeling for Token-Based Zero-Shot Text-to-Speech with Model and Data Scaling**|Chunhui Wang et.al.|[2403.05989](https://arxiv.org/abs/2403.05989)|null|
|**2024-03-09**|**Aligning Speech to Languages to Enhance Code-switching Speech Recognition**|Hexin Liu et.al.|[2403.05887](https://arxiv.org/abs/2403.05887)|null|
|**2024-03-07**|**Classist Tools: Social Class Correlates with Performance in NLP**|Amanda Cercas Curry et.al.|[2403.04445](https://arxiv.org/abs/2403.04445)|null|
|**2024-03-07**|**A New Benchmark for Evaluating Automatic Speech Recognition in the Arabic Call Domain**|Qusai Abo Obaidah et.al.|[2403.04280](https://arxiv.org/abs/2403.04280)|null|
|**2024-03-07**|**A Study of Dropout-Induced Modality Bias on Robustness to Missing Video Frames for Audio-Visual Speech Recognition**|Yusheng Dai et.al.|[2403.04245](https://arxiv.org/abs/2403.04245)|**[link](https://github.com/dalision/modalbiasavsr)**|
|**2024-03-06**|**RADIA -- Radio Advertisement Detection with Intelligent Analytics**|Jorge Álvarez et.al.|[2403.03538](https://arxiv.org/abs/2403.03538)|null|
|**2024-03-06**|**Non-verbal information in spontaneous speech -- towards a new framework of analysis**|Tirza Biron et.al.|[2403.03522](https://arxiv.org/abs/2403.03522)|null|
|**2024-03-05**|**NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models**|Zeqian Ju et.al.|[2403.03100](https://arxiv.org/abs/2403.03100)|null|
|**2024-03-05**|**AIx Speed: Playback Speed Optimization Using Listening Comprehension of Speech Recognition Models**|Kazuki Kawamura et.al.|[2403.02938](https://arxiv.org/abs/2403.02938)|null|
|**2024-03-05**|**Single-Channel Robot Ego-Speech Filtering during Human-Robot Interaction**|Yue Li et.al.|[2403.02918](https://arxiv.org/abs/2403.02918)|null|
|**2024-03-04**|**PixIT: Joint Training of Speaker Diarization and Speech Separation from Real-world Multi-speaker Recordings**|Joonas Kalda et.al.|[2403.02288](https://arxiv.org/abs/2403.02288)|null|
|**2024-03-04**|**What has LeBenchmark Learnt about French Syntax?**|Zdravko Dugonjić et.al.|[2403.02173](https://arxiv.org/abs/2403.02173)|null|
|**2024-03-04**|**SA-SOT: Speaker-Aware Serialized Output Training for Multi-Talker ASR**|Zhiyun Fan et.al.|[2403.02010](https://arxiv.org/abs/2403.02010)|null|
|**2024-03-04**|**Language and Speech Technology for Central Kurdish Varieties**|Sina Ahmadi et.al.|[2403.01983](https://arxiv.org/abs/2403.01983)|**[link](https://github.com/sinaahmadi/cordi)**|
|**2024-03-03**|**PAVITS: Exploring Prosody-aware VITS for End-to-End Emotional Voice Conversion**|Tianhua Qi et.al.|[2403.01494](https://arxiv.org/abs/2403.01494)|null|
|**2024-03-03**|**A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement**|Ravi Shankar et.al.|[2403.01369](https://arxiv.org/abs/2403.01369)|null|
|**2024-03-03**|**a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification**|Hye-jin Shim et.al.|[2403.01355](https://arxiv.org/abs/2403.01355)|**[link](https://github.com/shimhz/a_dcf)**|
|**2024-03-02**|**Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey**|Hamza Kheddar et.al.|[2403.01255](https://arxiv.org/abs/2403.01255)|null|
|**2024-03-02**|**Towards Accurate Lip-to-Speech Synthesis in-the-Wild**|Sindhu Hegde et.al.|[2403.01087](https://arxiv.org/abs/2403.01087)|null|
|**2024-03-01**|**VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis**|Weiwei Lin et.al.|[2403.00529](https://arxiv.org/abs/2403.00529)|null|
|**2024-03-01**|**Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview**|Heyang Liu et.al.|[2403.00370](https://arxiv.org/abs/2403.00370)|null|
|**2024-03-01**|**Efficient Adapter Tuning of Pre-trained Speech Models for Automatic Speaker Verification**|Mufan Sang et.al.|[2403.00293](https://arxiv.org/abs/2403.00293)|null|
|**2024-03-01**|**Transcription and translation of videos using fine-tuned XLSR Wav2Vec2 on custom dataset and mBART**|Aniket Tathe et.al.|[2403.00212](https://arxiv.org/abs/2403.00212)|null|
|**2024-02-29**|**Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems**|Quentin Raymondaud et.al.|[2402.19443](https://arxiv.org/abs/2402.19443)|null|
|**2024-02-29**|**Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification**|Sonal Joshi et.al.|[2402.19355](https://arxiv.org/abs/2402.19355)|null|
|**2024-02-29**|**Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data**|Takaaki Saeki et.al.|[2402.18932](https://arxiv.org/abs/2402.18932)|null|
|**2024-02-29**|**Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition**|Jeehyun Lee et.al.|[2402.18923](https://arxiv.org/abs/2402.18923)|null|
|**2024-02-29**|**Investigation of Adapter for Automatic Speech Recognition in Noisy Environment**|Hao Shi et.al.|[2402.18275](https://arxiv.org/abs/2402.18275)|null|
|**2024-02-28**|**Multilingual Speech Models for Automatic Speech Recognition Exhibit Gender Performance Gaps**|Giuseppe Attanasio et.al.|[2402.17954](https://arxiv.org/abs/2402.17954)|**[link](https://github.com/g8a9/multilingual-asr-gender-gap)**|
|**2024-02-24**|**ByteComposer: a Human-like Melody Composition Method based on Language Model Agent**|Xia Liang et.al.|[2402.17785](https://arxiv.org/abs/2402.17785)|null|
|**2024-02-27**|**High-Fidelity Neural Phonetic Posteriorgrams**|Cameron Churchwell et.al.|[2402.17735](https://arxiv.org/abs/2402.17735)|**[link](https://github.com/interactiveaudiolab/ppgs)**|
|**2024-02-27**|**Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey**|Dinh-Viet-Toan Le et.al.|[2402.17467](https://arxiv.org/abs/2402.17467)|null|
|**2024-02-27**|**An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement**|Tzu-Ting Yang et.al.|[2402.17189](https://arxiv.org/abs/2402.17189)|null|
|**2024-02-27**|**Extreme Encoder Output Frame Rate Reduction: Improving Computational Latencies of Large End-to-End Models**|Rohit Prabhavalkar et.al.|[2402.17184](https://arxiv.org/abs/2402.17184)|null|
|**2024-02-26**|**Towards Decoding Brain Activity During Passive Listening of Speech**|Milán András Fodor et.al.|[2402.16996](https://arxiv.org/abs/2402.16996)|**[link](https://github.com/milaniusz/speech2brain2speech)**|
|**2024-02-26**|**Effect of utterance duration and phonetic content on speaker identification using second-order statistical methods**|Ivan Magrin-Chagnolleau et.al.|[2402.16429](https://arxiv.org/abs/2402.16429)|null|
|**2024-02-24**|**ArEEG_Chars: Dataset for Envisioned Speech Recognition using EEG for Arabic Characters**|Hazem Darwish et.al.|[2402.15733](https://arxiv.org/abs/2402.15733)|null|

<p align=right>(<a href=../README.md>back to main</a>)</p>

